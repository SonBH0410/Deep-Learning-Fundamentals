{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ–¼ï¸ OpenCV Review for Computer Vision\n",
    "\n",
    "**Má»¥c tiÃªu:** Ã”n táº­p OpenCV cho image preprocessing vÃ  CV tasks\n",
    "\n",
    "**Ná»™i dung:**\n",
    "- Image I/O & basic operations\n",
    "- Color spaces & conversions\n",
    "- Geometric transformations\n",
    "- Image filtering\n",
    "- Edge detection\n",
    "- Contours & shapes\n",
    "- Basic object detection\n",
    "\n",
    "**Level:** Intermediate\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "\n",
    "# Helper function to display images\n",
    "def show_image(img, title='Image', cmap=None):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if len(img.shape) == 3:\n",
    "        # BGR to RGB for matplotlib\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img, cmap=cmap)\n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def show_images(images, titles, cmap=None):\n",
    "    n = len(images)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(5*n, 5))\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    for img, title, ax in zip(images, titles, axes):\n",
    "        if len(img.shape) == 3:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(img, cmap=cmap)\n",
    "        ax.set_title(title, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Image I/O & Basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic image (since we don't have actual image files)\n",
    "# In practice: img = cv2.imread('image.jpg')\n",
    "\n",
    "# Create color image (H, W, 3)\n",
    "h, w = 300, 400\n",
    "img = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "# Draw some shapes\n",
    "cv2.rectangle(img, (50, 50), (150, 150), (0, 255, 0), -1)  # Green square\n",
    "cv2.circle(img, (300, 150), 50, (255, 0, 0), -1)  # Blue circle\n",
    "cv2.line(img, (0, 250), (400, 250), (0, 0, 255), 2)  # Red line\n",
    "cv2.putText(img, 'OpenCV', (150, 280), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "print(f\"Image shape: {img.shape} (H, W, C)\")\n",
    "print(f\"Image dtype: {img.dtype}\")\n",
    "print(f\"Value range: [{img.min()}, {img.max()}]\")\n",
    "\n",
    "# Basic info\n",
    "height, width, channels = img.shape\n",
    "print(f\"\\nDimensions: {width}x{height}, Channels: {channels}\")\n",
    "\n",
    "show_image(img, 'Original Image')\n",
    "\n",
    "# Save image\n",
    "# cv2.imwrite('output.jpg', img)\n",
    "\n",
    "print(\"\\nðŸ’¡ OpenCV uses BGR, not RGB!\")\n",
    "print(\"   When displaying with matplotlib, convert to RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Color Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert between color spaces\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "print(f\"Gray shape: {gray.shape}\")\n",
    "print(f\"HSV shape: {hsv.shape}\")\n",
    "\n",
    "show_images([img, gray], ['Original (BGR)', 'Grayscale'], cmap='gray')\n",
    "\n",
    "# Split channels\n",
    "b, g, r = cv2.split(img)\n",
    "h, s, v = cv2.split(hsv)\n",
    "\n",
    "print(\"\\nChannel info:\")\n",
    "print(f\"  Blue channel: {b.shape}\")\n",
    "print(f\"  Hue channel: {h.shape}\")\n",
    "\n",
    "# Merge channels\n",
    "merged = cv2.merge([b, g, r])\n",
    "print(f\"  Merged: {merged.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Common Color Spaces\n",
    "\n",
    "- **BGR**: OpenCV default (Blue, Green, Red)\n",
    "- **RGB**: Standard (Red, Green, Blue)\n",
    "- **Grayscale**: Single channel intensity\n",
    "- **HSV**: Hue, Saturation, Value (good for color-based segmentation)\n",
    "- **LAB**: Lightness, A, B (perceptually uniform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Geometric Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize\n",
    "resized = cv2.resize(img, (200, 150))  # (width, height)\n",
    "print(f\"Resized: {img.shape} -> {resized.shape}\")\n",
    "\n",
    "# Resize with interpolation\n",
    "upscaled = cv2.resize(img, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_LINEAR)\n",
    "downscaled = cv2.resize(img, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Rotation\n",
    "center = (width // 2, height // 2)\n",
    "M = cv2.getRotationMatrix2D(center, 45, 1.0)  # 45 degrees, scale=1\n",
    "rotated = cv2.warpAffine(img, M, (width, height))\n",
    "\n",
    "# Flip\n",
    "flipped_h = cv2.flip(img, 1)  # Horizontal\n",
    "flipped_v = cv2.flip(img, 0)  # Vertical\n",
    "\n",
    "# Translation\n",
    "M_translate = np.float32([[1, 0, 50], [0, 1, 30]])  # Shift by (50, 30)\n",
    "translated = cv2.warpAffine(img, M_translate, (width, height))\n",
    "\n",
    "show_images([img, rotated, flipped_h], \n",
    "            ['Original', 'Rotated 45Â°', 'Flipped Horizontal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop using array slicing\n",
    "cropped = img[50:200, 100:300]  # [y1:y2, x1:x2]\n",
    "\n",
    "print(f\"Cropped: {cropped.shape}\")\n",
    "show_image(cropped, 'Cropped Region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise to demonstrate filtering\n",
    "noisy = img.copy()\n",
    "noise = np.random.randn(*img.shape) * 25\n",
    "noisy = np.clip(noisy + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Gaussian blur (remove noise)\n",
    "blurred = cv2.GaussianBlur(noisy, (5, 5), 0)\n",
    "\n",
    "# Median blur (good for salt-and-pepper noise)\n",
    "median = cv2.medianBlur(noisy, 5)\n",
    "\n",
    "# Bilateral filter (edge-preserving)\n",
    "bilateral = cv2.bilateralFilter(noisy, 9, 75, 75)\n",
    "\n",
    "show_images([img, noisy, blurred, median], \n",
    "            ['Original', 'Noisy', 'Gaussian Blur', 'Median Filter'])\n",
    "\n",
    "print(\"Filter comparison:\")\n",
    "print(\"  Gaussian: Fast, smooths everything\")\n",
    "print(\"  Median: Good for salt-and-pepper noise\")\n",
    "print(\"  Bilateral: Preserves edges (slower)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharpening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sharpen kernel\n",
    "kernel_sharpen = np.array([[-1,-1,-1],\n",
    "                            [-1, 9,-1],\n",
    "                            [-1,-1,-1]])\n",
    "\n",
    "sharpened = cv2.filter2D(img, -1, kernel_sharpen)\n",
    "\n",
    "show_images([img, sharpened], ['Original', 'Sharpened'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny edge detection\n",
    "edges_canny = cv2.Canny(gray, 50, 150)  # threshold1=50, threshold2=150\n",
    "\n",
    "# Sobel edge detection\n",
    "sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)  # X gradient\n",
    "sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)  # Y gradient\n",
    "sobel_combined = np.sqrt(sobelx**2 + sobely**2)\n",
    "sobel_combined = np.uint8(np.clip(sobel_combined, 0, 255))\n",
    "\n",
    "# Laplacian\n",
    "laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "laplacian = np.uint8(np.abs(laplacian))\n",
    "\n",
    "show_images([gray, edges_canny, sobel_combined, laplacian],\n",
    "            ['Original', 'Canny', 'Sobel', 'Laplacian'],\n",
    "            cmap='gray')\n",
    "\n",
    "print(\"Edge detection methods:\")\n",
    "print(\"  Canny: Multi-stage, best overall\")\n",
    "print(\"  Sobel: Gradient-based, directional\")\n",
    "print(\"  Laplacian: Second derivative, sensitive to noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Thresholding & Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary threshold\n",
    "_, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Adaptive threshold (local)\n",
    "adaptive = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                 cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "# Otsu's threshold (automatic)\n",
    "_, otsu = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "show_images([gray, binary, adaptive, otsu],\n",
    "            ['Original', 'Binary', 'Adaptive', 'Otsu'],\n",
    "            cmap='gray')\n",
    "\n",
    "print(\"Thresholding:\")\n",
    "print(\"  Binary: Fixed threshold\")\n",
    "print(\"  Adaptive: Local threshold (good for varying illumination)\")\n",
    "print(\"  Otsu: Automatic threshold selection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Contours & Shape Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find contours\n",
    "contours, hierarchy = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "print(f\"Found {len(contours)} contours\")\n",
    "\n",
    "# Draw contours\n",
    "img_contours = img.copy()\n",
    "cv2.drawContours(img_contours, contours, -1, (0, 255, 0), 2)  # Draw all in green\n",
    "\n",
    "# Analyze largest contour\n",
    "if len(contours) > 0:\n",
    "    largest = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Contour properties\n",
    "    area = cv2.contourArea(largest)\n",
    "    perimeter = cv2.arcLength(largest, True)\n",
    "    \n",
    "    # Bounding box\n",
    "    x, y, w_box, h_box = cv2.boundingRect(largest)\n",
    "    cv2.rectangle(img_contours, (x, y), (x+w_box, y+h_box), (255, 0, 0), 2)\n",
    "    \n",
    "    # Moments (for centroid)\n",
    "    M = cv2.moments(largest)\n",
    "    if M['m00'] != 0:\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        cv2.circle(img_contours, (cx, cy), 5, (0, 0, 255), -1)\n",
    "    \n",
    "    print(f\"\\nLargest contour:\")\n",
    "    print(f\"  Area: {area:.0f}\")\n",
    "    print(f\"  Perimeter: {perimeter:.1f}\")\n",
    "    print(f\"  Centroid: ({cx}, {cy})\")\n",
    "\n",
    "show_images([binary, img_contours], ['Binary', 'Contours'], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Morphological Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel for morphology\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# Erosion (shrink white regions)\n",
    "erosion = cv2.erode(binary, kernel, iterations=1)\n",
    "\n",
    "# Dilation (expand white regions)\n",
    "dilation = cv2.dilate(binary, kernel, iterations=1)\n",
    "\n",
    "# Opening (erosion then dilation, removes noise)\n",
    "opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# Closing (dilation then erosion, fills holes)\n",
    "closing = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "show_images([binary, erosion, dilation, opening],\n",
    "            ['Original', 'Erosion', 'Dilation', 'Opening'],\n",
    "            cmap='gray')\n",
    "\n",
    "print(\"Morphological ops:\")\n",
    "print(\"  Erosion: Shrink objects, remove noise\")\n",
    "print(\"  Dilation: Expand objects, fill gaps\")\n",
    "print(\"  Opening: Remove small objects\")\n",
    "print(\"  Closing: Fill small holes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Detection (Bonus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harris corner detection\n",
    "gray_float = np.float32(gray)\n",
    "corners = cv2.cornerHarris(gray_float, 2, 3, 0.04)\n",
    "\n",
    "# Dilate to mark corners\n",
    "corners = cv2.dilate(corners, None)\n",
    "\n",
    "# Mark corners in red\n",
    "img_corners = img.copy()\n",
    "img_corners[corners > 0.01 * corners.max()] = [0, 0, 255]\n",
    "\n",
    "show_image(img_corners, 'Harris Corners')\n",
    "\n",
    "print(\"âœ… Corner detection useful for:\")\n",
    "print(\"  - Feature matching\")\n",
    "print(\"  - Object tracking\")\n",
    "print(\"  - Image stitching\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ Key Takeaways\n",
    "\n",
    "### Essential OpenCV Operations\n",
    "\n",
    "#### Image I/O\n",
    "```python\n",
    "img = cv2.imread('image.jpg')  # Load\n",
    "cv2.imwrite('output.jpg', img)  # Save\n",
    "```\n",
    "\n",
    "#### Color Conversion\n",
    "```python\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # For matplotlib\n",
    "```\n",
    "\n",
    "#### Transformations\n",
    "```python\n",
    "resized = cv2.resize(img, (width, height))\n",
    "rotated = cv2.warpAffine(img, M, (width, height))\n",
    "cropped = img[y1:y2, x1:x2]\n",
    "```\n",
    "\n",
    "#### Filtering\n",
    "```python\n",
    "blurred = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "edges = cv2.Canny(gray, 50, 150)\n",
    "```\n",
    "\n",
    "#### Contours\n",
    "```python\n",
    "contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(img, contours, -1, (0, 255, 0), 2)\n",
    "```\n",
    "\n",
    "### Common Preprocessing for DL\n",
    "\n",
    "```python\n",
    "# Typical preprocessing pipeline\n",
    "img = cv2.imread('image.jpg')\n",
    "\n",
    "# 1. Resize to model input size\n",
    "img = cv2.resize(img, (224, 224))\n",
    "\n",
    "# 2. Convert to RGB (if needed)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 3. Normalize to [0, 1]\n",
    "img = img.astype(np.float32) / 255.0\n",
    "\n",
    "# 4. Add batch dimension\n",
    "img = np.expand_dims(img, axis=0)\n",
    "```\n",
    "\n",
    "### Important Notes\n",
    "\n",
    "1. **OpenCV uses BGR**, not RGB!\n",
    "2. **Image shape**: (H, W, C) not (C, H, W)\n",
    "3. **Dtype matters**: uint8 [0, 255] vs float32 [0, 1]\n",
    "4. **Coordinate system**: (x, y) = (column, row)\n",
    "5. **Array indexing**: img[y, x] or img[y1:y2, x1:x2]\n",
    "\n",
    "### Use Cases in DL\n",
    "\n",
    "- **Data augmentation**: Resize, rotate, flip\n",
    "- **Preprocessing**: Normalize, grayscale\n",
    "- **Feature extraction**: Edges, corners\n",
    "- **Segmentation**: Thresholding, contours\n",
    "- **Object detection**: Contours, bounding boxes\n",
    "\n",
    "---\n",
    "\n",
    "**Complete!** You now have a comprehensive review of ML/DL libraries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
