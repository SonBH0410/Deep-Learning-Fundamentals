{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤– Scikit-learn Review for ML/DL\n",
    "\n",
    "**Má»¥c tiÃªu:** Ã”n táº­p ML pipeline vá»›i Scikit-learn\n",
    "\n",
    "**Ná»™i dung:**\n",
    "- Data preprocessing\n",
    "- Train-test split & cross-validation\n",
    "- ML algorithms (classification, regression)\n",
    "- Model evaluation metrics\n",
    "- Hyperparameter tuning\n",
    "- Pipelines\n",
    "\n",
    "**Level:** Intermediate\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import __version__ as sklearn_version\n",
    "\n",
    "print(f\"Scikit-learn: {sklearn_version}\")\n",
    "\n",
    "# Sample data\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "\n",
    "X_cls, y_cls = make_classification(n_samples=1000, n_features=20, n_informative=15, \n",
    "                                     n_redundant=5, random_state=42)\n",
    "X_reg, y_reg = make_regression(n_samples=1000, n_features=10, noise=10, random_state=42)\n",
    "\n",
    "print(f\"Classification: X={X_cls.shape}, y={y_cls.shape}\")\n",
    "print(f\"Regression: X={X_reg.shape}, y={y_reg.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Data Preprocessing\n",
    "\n",
    "### Scaling & Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# StandardScaler: (x - mean) / std\n",
    "scaler_std = StandardScaler()\n",
    "X_scaled = scaler_std.fit_transform(X_cls)\n",
    "\n",
    "# MinMaxScaler: (x - min) / (max - min)\n",
    "scaler_minmax = MinMaxScaler()\n",
    "X_minmax = scaler_minmax.fit_transform(X_cls)\n",
    "\n",
    "# Imputation (missing values)\n",
    "X_with_missing = X_cls.copy()\n",
    "X_with_missing[np.random.rand(*X_with_missing.shape) < 0.1] = np.nan\n",
    "imputer = SimpleImputer(strategy='mean')  # or 'median', 'most_frequent'\n",
    "X_imputed = imputer.fit_transform(X_with_missing)\n",
    "\n",
    "# Label encoding (categorical -> numeric)\n",
    "categories = np.array(['A', 'B', 'C', 'A', 'B'])\n",
    "le = LabelEncoder()\n",
    "categories_encoded = le.fit_transform(categories)\n",
    "\n",
    "# One-hot encoding\n",
    "categories_2d = categories.reshape(-1, 1)\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "categories_onehot = ohe.fit_transform(categories_2d)\n",
    "\n",
    "print(f\"Scaled mean: {X_scaled.mean(axis=0)[:3]}\")\n",
    "print(f\"Scaled std: {X_scaled.std(axis=0)[:3]}\")\n",
    "print(f\"MinMax range: [{X_minmax.min()}, {X_minmax.max()}]\")\n",
    "print(f\"Label encoded: {categories_encoded}\")\n",
    "print(f\"One-hot shape: {categories_onehot.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ When to Use\n",
    "\n",
    "- **StandardScaler**: Most algorithms (SVM, Neural Networks, Logistic Regression)\n",
    "- **MinMaxScaler**: When bounded range needed [0, 1]\n",
    "- **No scaling**: Tree-based models (Random Forest, XGBoost) - they're scale-invariant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train-Test Split & Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "\n",
    "# Basic split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_cls, y_cls, test_size=0.2, random_state=42, stratify=y_cls  # stratify maintains class balance\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "print(f\"Train class balance: {np.bincount(y_train) / len(y_train)}\")\n",
    "print(f\"Test class balance: {np.bincount(y_test) / len(y_test)}\")\n",
    "\n",
    "# Cross-validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"\\nCV Scores: {scores}\")\n",
    "print(f\"Mean: {scores.mean():.3f} (+/- {scores.std():.3f})\")\n",
    "\n",
    "# Stratified K-Fold (for imbalanced data)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "    print(f\"Fold {fold+1}: Train={len(train_idx)}, Val={len(val_idx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# Train and evaluate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Model Comparison:\\n\")\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='binary')\n",
    "    rec = recall_score(y_test, y_pred, average='binary')\n",
    "    f1 = f1_score(y_test, y_pred, average='binary')\n",
    "    \n",
    "    results.append({'Model': name, 'Accuracy': acc, 'Precision': prec, 'Recall': rec, 'F1': f1})\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values('F1', ascending=False)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Split regression data\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Models\n",
    "reg_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge (L2)': Ridge(alpha=1.0),\n",
    "    'Lasso (L1)': Lasso(alpha=1.0),\n",
    "    'Decision Tree': DecisionTreeRegressor(max_depth=5, random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "print(\"Regression Model Comparison:\\n\")\n",
    "reg_results = []\n",
    "\n",
    "for name, model in reg_models.items():\n",
    "    model.fit(X_train_r, y_train_r)\n",
    "    y_pred = model.predict(X_test_r)\n",
    "    \n",
    "    mse = mean_squared_error(y_test_r, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test_r, y_pred)\n",
    "    r2 = r2_score(y_test_r, y_pred)\n",
    "    \n",
    "    reg_results.append({'Model': name, 'RMSE': rmse, 'MAE': mae, 'RÂ²': r2})\n",
    "\n",
    "reg_results_df = pd.DataFrame(reg_results).sort_values('RÂ²', ascending=False)\n",
    "print(reg_results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation\n",
    "\n",
    "### Classification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Best model from previous comparison\n",
    "best_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "print(f\"  TN: {cm[0,0]}, FP: {cm[0,1]}\")\n",
    "print(f\"  FN: {cm[1,0]}, TP: {cm[1,1]}\")\n",
    "\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"\\nROC AUC: {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Grid Search (exhaustive)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=3, scoring='f1', n_jobs=-1, verbose=0)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Grid Search Results:\")\n",
    "print(f\"  Best params: {grid_search.best_params_}\")\n",
    "print(f\"  Best score: {grid_search.best_score_:.3f}\")\n",
    "\n",
    "# Random Search (sample from distribution)\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'max_depth': randint(3, 15),\n",
    "    'min_samples_split': randint(2, 20)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(rf, param_dist, n_iter=20, cv=3, \n",
    "                                   scoring='f1', random_state=42, n_jobs=-1, verbose=0)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nRandom Search Results:\")\n",
    "print(f\"  Best params: {random_search.best_params_}\")\n",
    "print(f\"  Best score: {random_search.best_score_:.3f}\")\n",
    "\n",
    "# Compare on test set\n",
    "y_pred_tuned = grid_search.best_estimator_.predict(X_test)\n",
    "print(f\"\\nTest F1 (tuned): {f1_score(y_test, y_pred_tuned):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pipelines\n",
    "\n",
    "### End-to-end workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Simple pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit and predict\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred_pipe = pipe.predict(X_test)\n",
    "print(f\"Pipeline Accuracy: {accuracy_score(y_test, y_pred_pipe):.3f}\")\n",
    "\n",
    "# More complex: Different preprocessing for different features\n",
    "# (Demo with synthetic data)\n",
    "X_mixed = np.column_stack([\n",
    "    np.random.randn(1000, 5),  # Numeric features\n",
    "    np.random.choice(['A', 'B', 'C'], (1000, 2))  # Categorical\n",
    "])\n",
    "\n",
    "numeric_features = [0, 1, 2, 3, 4]\n",
    "categorical_features = [5, 6]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(sparse_output=False), categorical_features)\n",
    "    ])\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "print(\"\\nâœ… Pipelines ensure:\")\n",
    "print(\"  1. No data leakage (fit only on train)\")\n",
    "print(\"  2. Reproducible preprocessing\")\n",
    "print(\"  3. Easy deployment (single object)\")\n",
    "print(\"  4. Hyperparameter tuning across all steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ Key Takeaways\n",
    "\n",
    "### ML Workflow\n",
    "\n",
    "```python\n",
    "# 1. Load data\n",
    "X, y = load_data()\n",
    "\n",
    "# 2. Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# 3. Preprocess (fit on train only!)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)  # No fit!\n",
    "\n",
    "# 4. Train\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "# 6. Tune (optional)\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "### Critical Points\n",
    "\n",
    "1. **Always split BEFORE preprocessing** (avoid data leakage)\n",
    "2. **Fit on train, transform on test** (no fit on test!)\n",
    "3. **Use stratify for imbalanced data**\n",
    "4. **Use pipelines** for reproducibility\n",
    "5. **Cross-validation** for robust evaluation\n",
    "6. **Tree-based models don't need scaling**\n",
    "\n",
    "### Common Metrics\n",
    "\n",
    "**Classification:**\n",
    "- Accuracy: Overall correctness\n",
    "- Precision: Of predicted positives, how many correct?\n",
    "- Recall: Of actual positives, how many found?\n",
    "- F1: Harmonic mean of precision & recall\n",
    "- ROC AUC: Trade-off FPR vs TPR\n",
    "\n",
    "**Regression:**\n",
    "- MSE/RMSE: Squared error (penalizes large errors)\n",
    "- MAE: Absolute error (robust to outliers)\n",
    "- RÂ²: Explained variance (0-1, higher better)\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** OpenCV for computer vision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
