{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî• TensorFlow Foundation - Part 1-A\n",
    "# Tensor Basics: N·ªÅn T·∫£ng C·ªßa Deep Learning\n",
    "\n",
    "---\n",
    "\n",
    "**M·ª•c ti√™u:**\n",
    "- Hi·ªÉu TensorFlow & Keras l√† g√¨\n",
    "- N·∫Øm v·ªØng kh√°i ni·ªám Tensor\n",
    "- Th√†nh th·∫°o c√°c ph√©p to√°n tensor c∆° b·∫£n\n",
    "- So s√°nh TensorFlow vs NumPy\n",
    "\n",
    "**Th·ªùi l∆∞·ª£ng:** 45-60 ph√∫t\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö M·ª•c L·ª•c\n",
    "\n",
    "1. [Gi·ªõi thi·ªáu TensorFlow](#intro)\n",
    "2. [Tensor l√† g√¨?](#tensor-concept)\n",
    "3. [T·∫°o Tensor](#create-tensor)\n",
    "4. [Shape & Dtype](#shape-dtype)\n",
    "5. [Tensor Operations](#operations)\n",
    "6. [TensorFlow vs NumPy](#tf-vs-numpy)\n",
    "7. [Common Mistakes](#mistakes)\n",
    "8. [B√†i T·∫≠p](#exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"intro\"></a>\n",
    "## 1. üéØ Gi·ªõi Thi·ªáu TensorFlow & Keras\n",
    "\n",
    "### TensorFlow l√† g√¨?\n",
    "\n",
    "**TensorFlow** l√† framework Deep Learning m√£ ngu·ªìn m·ªü ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi Google Brain.\n",
    "\n",
    "```\n",
    "TensorFlow = Tensor + Flow\n",
    "   ‚Üì           ‚Üì       ‚Üì\n",
    " Framework   Data   Computation\n",
    "```\n",
    "\n",
    "### Keras l√† g√¨?\n",
    "\n",
    "**Keras** l√† high-level API c·ªßa TensorFlow (t·ª´ TF 2.0+):\n",
    "- D·ªÖ h·ªçc, d·ªÖ d√πng\n",
    "- Pythonic\n",
    "- Production-ready\n",
    "\n",
    "```python\n",
    "# TensorFlow 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# keras ƒë√£ t√≠ch h·ª£p s·∫µn trong TensorFlow!\n",
    "```\n",
    "\n",
    "### T·∫°i sao ch·ªçn TensorFlow?\n",
    "\n",
    "‚úÖ **Production-ready**: Tri·ªÉn khai d·ªÖ d√†ng (TF Serving, TF Lite)  \n",
    "‚úÖ **Ecosystem m·∫°nh**: TensorBoard, TFX, TF Hub  \n",
    "‚úÖ **Multi-platform**: CPU, GPU, TPU, Mobile, Web  \n",
    "‚úÖ **Industry standard**: Google, Airbnb, Uber s·ª≠ d·ª•ng  \n",
    "‚úÖ **Keras API**: ƒê∆°n gi·∫£n nh∆∞ PyTorch nh∆∞ng m·∫°nh nh∆∞ TensorFlow  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√†i ƒë·∫∑t (n·∫øu ch∆∞a c√≥)\n",
    "# !pip install tensorflow\n",
    "\n",
    "# Import th∆∞ vi·ªán\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"üî• TensorFlow version:\", tf.__version__)\n",
    "print(\"‚úÖ Keras version:\", tf.keras.__version__)\n",
    "print(\"üñ•Ô∏è  Built with CUDA:\", tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"tensor-concept\"></a>\n",
    "## 2. üß† Tensor L√† G√¨?\n",
    "\n",
    "### ƒê·ªãnh nghƒ©a\n",
    "\n",
    "**Tensor** = M·∫£ng ƒëa chi·ªÅu (multi-dimensional array)\n",
    "\n",
    "```\n",
    "Chi·ªÅu (Rank)  ‚îÇ  T√™n g·ªçi      ‚îÇ  V√≠ d·ª•\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "0D            ‚îÇ  Scalar       ‚îÇ  5\n",
    "1D            ‚îÇ  Vector       ‚îÇ  [1, 2, 3]\n",
    "2D            ‚îÇ  Matrix       ‚îÇ  [[1, 2], [3, 4]]\n",
    "3D            ‚îÇ  3D Tensor    ‚îÇ  ·∫¢nh RGB: [H, W, 3]\n",
    "4D+           ‚îÇ  High-D       ‚îÇ  Video, Batch images\n",
    "```\n",
    "\n",
    "### So s√°nh v·ªõi NumPy\n",
    "\n",
    "| Feature | NumPy ndarray | TensorFlow Tensor |\n",
    "|---------|---------------|-------------------|\n",
    "| **Mutable** | ‚úÖ C√≥ th·ªÉ thay ƒë·ªïi | ‚ùå Immutable (kh√¥ng ƒë·ªïi) |\n",
    "| **GPU** | ‚ùå CPU only | ‚úÖ CPU, GPU, TPU |\n",
    "| **Auto Diff** | ‚ùå Kh√¥ng | ‚úÖ tf.GradientTape |\n",
    "| **Distributed** | ‚ùå Kh√¥ng | ‚úÖ Multi-device |\n",
    "\n",
    "### T·∫°i sao Tensor quan tr·ªçng?\n",
    "\n",
    "üéØ **T·∫•t c·∫£ d·ªØ li·ªáu trong Deep Learning ƒë·ªÅu l√† Tensor:**\n",
    "- ·∫¢nh: `[batch, height, width, channels]`\n",
    "- Text: `[batch, sequence_length, embedding_dim]`\n",
    "- Audio: `[batch, time_steps, features]`\n",
    "- Video: `[batch, frames, height, width, channels]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"create-tensor\"></a>\n",
    "## 3. üõ†Ô∏è T·∫°o Tensor\n",
    "\n",
    "C√≥ nhi·ªÅu c√°ch ƒë·ªÉ t·∫°o tensor trong TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. T·∫°o t·ª´ list Python\n",
    "scalar = tf.constant(5)                    # 0D: Scalar\n",
    "vector = tf.constant([1, 2, 3])            # 1D: Vector\n",
    "matrix = tf.constant([[1, 2], [3, 4]])     # 2D: Matrix\n",
    "\n",
    "print(\"Scalar:\", scalar)\n",
    "print(\"Vector:\", vector)\n",
    "print(\"Matrix:\")\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. T·∫°o tensor ƒë·∫∑c bi·ªát\n",
    "\n",
    "# Tensor to√†n s·ªë 0\n",
    "zeros = tf.zeros([2, 3])  # Shape [2, 3]\n",
    "print(\"Zeros:\")\n",
    "print(zeros)\n",
    "print()\n",
    "\n",
    "# Tensor to√†n s·ªë 1\n",
    "ones = tf.ones([3, 2])\n",
    "print(\"Ones:\")\n",
    "print(ones)\n",
    "print()\n",
    "\n",
    "# Tensor v·ªõi gi√° tr·ªã c·ª• th·ªÉ\n",
    "filled = tf.fill([2, 2], value=9)\n",
    "print(\"Filled with 9:\")\n",
    "print(filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. T·∫°o tensor ng·∫´u nhi√™n\n",
    "\n",
    "# Random t·ª´ ph√¢n ph·ªëi chu·∫©n N(0, 1)\n",
    "random_normal = tf.random.normal([3, 3], mean=0.0, stddev=1.0)\n",
    "print(\"Random Normal:\")\n",
    "print(random_normal)\n",
    "print()\n",
    "\n",
    "# Random ƒë·ªÅu t·ª´ [0, 1)\n",
    "random_uniform = tf.random.uniform([2, 2], minval=0, maxval=1)\n",
    "print(\"Random Uniform:\")\n",
    "print(random_uniform)\n",
    "print()\n",
    "\n",
    "# ‚ö†Ô∏è L∆ØU √ù: M·ªói l·∫ßn ch·∫°y s·∫Ω kh√°c nhau!\n",
    "# ƒê·ªÉ reproducible, d√πng: tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. T·∫°o d√£y s·ªë\n",
    "\n",
    "# Gi·ªëng range() c·ªßa Python\n",
    "range_tensor = tf.range(start=0, limit=10, delta=2)\n",
    "print(\"Range [0, 10) b∆∞·ªõc 2:\", range_tensor)\n",
    "\n",
    "# Linspace: chia ƒë·ªÅu t·ª´ start ƒë·∫øn stop\n",
    "linspace_tensor = tf.linspace(start=0.0, stop=1.0, num=5)\n",
    "print(\"Linspace [0, 1] v·ªõi 5 ƒëi·ªÉm:\", linspace_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Chuy·ªÉn ƒë·ªïi t·ª´ NumPy\n",
    "\n",
    "numpy_array = np.array([[1, 2], [3, 4]])\n",
    "tensor_from_numpy = tf.constant(numpy_array)\n",
    "\n",
    "print(\"NumPy array:\")\n",
    "print(numpy_array)\n",
    "print(\"\\nTensor:\")\n",
    "print(tensor_from_numpy)\n",
    "\n",
    "# ‚úÖ QUAN TR·ªåNG: \n",
    "# tf.constant() COPY d·ªØ li·ªáu (kh√¥ng share memory v·ªõi NumPy)\n",
    "# Kh√°c v·ªõi PyTorch: torch.from_numpy() share memory!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"shape-dtype\"></a>\n",
    "## 4. üìê Shape & Dtype\n",
    "\n",
    "### Shape (K√≠ch th∆∞·ªõc)\n",
    "\n",
    "**Shape** m√¥ t·∫£ chi·ªÅu c·ªßa tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√≠ d·ª• v·ªÅ shape\n",
    "t = tf.constant([\n",
    "    [[1, 2, 3], [4, 5, 6]],\n",
    "    [[7, 8, 9], [10, 11, 12]]\n",
    "])\n",
    "\n",
    "print(\"Tensor:\")\n",
    "print(t)\n",
    "print()\n",
    "\n",
    "# C√°c thu·ªôc t√≠nh v·ªÅ shape\n",
    "print(\"Shape:\", t.shape)              # TensorShape([2, 2, 3])\n",
    "print(\"Ndim (s·ªë chi·ªÅu):\", t.ndim)     # 3\n",
    "print(\"Size (t·ªïng ph·∫ßn t·ª≠):\", tf.size(t).numpy())  # 12\n",
    "\n",
    "# Gi·∫£i th√≠ch shape [2, 2, 3]:\n",
    "# - Chi·ªÅu 0: 2 (2 matrices)\n",
    "# - Chi·ªÅu 1: 2 (m·ªói matrix c√≥ 2 rows)\n",
    "# - Chi·ªÅu 2: 3 (m·ªói row c√≥ 3 elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape trong Deep Learning\n",
    "\n",
    "# ·∫¢nh RGB\n",
    "image = tf.random.normal([224, 224, 3])  # [Height, Width, Channels]\n",
    "print(\"Image shape:\", image.shape)\n",
    "\n",
    "# Batch images\n",
    "batch_images = tf.random.normal([32, 224, 224, 3])  # [Batch, H, W, C]\n",
    "print(\"Batch images shape:\", batch_images.shape)\n",
    "\n",
    "# Text sequence\n",
    "text_seq = tf.random.normal([16, 100, 512])  # [Batch, SeqLen, Embedding]\n",
    "print(\"Text sequence shape:\", text_seq.shape)\n",
    "\n",
    "# üéØ Quy ∆∞·ªõc:\n",
    "# - Batch lu√¥n ·ªü chi·ªÅu ƒë·∫ßu ti√™n (axis=0)\n",
    "# - Channels: TensorFlow d√πng \"channels-last\" (NHWC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dtype (Ki·ªÉu d·ªØ li·ªáu)\n",
    "\n",
    "**Dtype** x√°c ƒë·ªãnh ki·ªÉu d·ªØ li·ªáu c·ªßa tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√°c dtype ph·ªï bi·∫øn\n",
    "\n",
    "# Float\n",
    "float_tensor = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)\n",
    "print(\"Float32:\", float_tensor, \"| dtype:\", float_tensor.dtype)\n",
    "\n",
    "# Integer\n",
    "int_tensor = tf.constant([1, 2, 3], dtype=tf.int32)\n",
    "print(\"Int32:\", int_tensor, \"| dtype:\", int_tensor.dtype)\n",
    "\n",
    "# Boolean\n",
    "bool_tensor = tf.constant([True, False, True], dtype=tf.bool)\n",
    "print(\"Bool:\", bool_tensor, \"| dtype:\", bool_tensor.dtype)\n",
    "\n",
    "# String\n",
    "string_tensor = tf.constant([\"hello\", \"world\"], dtype=tf.string)\n",
    "print(\"String:\", string_tensor, \"| dtype:\", string_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuy·ªÉn ƒë·ªïi dtype (type casting)\n",
    "\n",
    "x = tf.constant([1, 2, 3], dtype=tf.int32)\n",
    "print(\"Original (int32):\", x)\n",
    "\n",
    "# Cast sang float32\n",
    "x_float = tf.cast(x, dtype=tf.float32)\n",
    "print(\"Cast to float32:\", x_float)\n",
    "\n",
    "# Cast sang bool\n",
    "x_bool = tf.cast(x, dtype=tf.bool)\n",
    "print(\"Cast to bool:\", x_bool)  # 0 -> False, kh√°c 0 -> True\n",
    "\n",
    "# ‚ö†Ô∏è L∆ØU √ù:\n",
    "# - Lu√¥n cast v·ªÅ float32 khi train neural networks\n",
    "# - int32 cho indices, labels\n",
    "# - float32 cho weights, activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°i sao dtype quan tr·ªçng?\n",
    "\n",
    "# ‚ùå SAI: C·ªông int32 v·ªõi float32\n",
    "try:\n",
    "    a = tf.constant([1, 2], dtype=tf.int32)\n",
    "    b = tf.constant([1.0, 2.0], dtype=tf.float32)\n",
    "    c = a + b  # TypeError!\n",
    "except Exception as e:\n",
    "    print(\"‚ùå L·ªói:\", type(e).__name__)\n",
    "\n",
    "# ‚úÖ ƒê√öNG: Cast tr∆∞·ªõc khi t√≠nh\n",
    "a = tf.constant([1, 2], dtype=tf.int32)\n",
    "b = tf.constant([1.0, 2.0], dtype=tf.float32)\n",
    "c = tf.cast(a, tf.float32) + b\n",
    "print(\"‚úÖ K·∫øt qu·∫£:\", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"operations\"></a>\n",
    "## 5. üîß Tensor Operations\n",
    "\n",
    "### 5.1 Ph√©p to√°n c∆° b·∫£n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise operations (theo t·ª´ng ph·∫ßn t·ª≠)\n",
    "\n",
    "a = tf.constant([1.0, 2.0, 3.0])\n",
    "b = tf.constant([4.0, 5.0, 6.0])\n",
    "\n",
    "# C·ªông, tr·ª´, nh√¢n, chia\n",
    "print(\"a + b =\", a + b)           # [5, 7, 9]\n",
    "print(\"a - b =\", a - b)           # [-3, -3, -3]\n",
    "print(\"a * b =\", a * b)           # [4, 10, 18]\n",
    "print(\"b / a =\", b / a)           # [4, 2.5, 2]\n",
    "print(\"a ** 2 =\", a ** 2)         # [1, 4, 9]\n",
    "\n",
    "# Ho·∫∑c d√πng function\n",
    "print(\"\\ntf.add(a, b) =\", tf.add(a, b))\n",
    "print(\"tf.multiply(a, b) =\", tf.multiply(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math functions\n",
    "\n",
    "x = tf.constant([1.0, 2.0, 3.0, 4.0])\n",
    "\n",
    "print(\"tf.sqrt(x) =\", tf.sqrt(x))          # CƒÉn b·∫≠c 2\n",
    "print(\"tf.exp(x) =\", tf.exp(x))            # e^x\n",
    "print(\"tf.log(x) =\", tf.log(x))            # ln(x)\n",
    "print(\"tf.abs(x) =\", tf.abs(x))            # |x|\n",
    "print(\"tf.round(x) =\", tf.round(x))        # L√†m tr√≤n\n",
    "\n",
    "# Activation functions\n",
    "print(\"\\ntf.nn.relu(x) =\", tf.nn.relu(x))  # ReLU\n",
    "print(\"tf.nn.sigmoid(x) =\", tf.nn.sigmoid(x))  # Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Matrix Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix multiplication (nh√¢n ma tr·∫≠n)\n",
    "\n",
    "A = tf.constant([[1, 2], [3, 4]])  # 2x2\n",
    "B = tf.constant([[5, 6], [7, 8]])  # 2x2\n",
    "\n",
    "print(\"Matrix A:\")\n",
    "print(A)\n",
    "print(\"\\nMatrix B:\")\n",
    "print(B)\n",
    "\n",
    "# Nh√¢n ma tr·∫≠n\n",
    "C = tf.matmul(A, B)  # Ho·∫∑c A @ B\n",
    "print(\"\\nA @ B (matrix multiplication):\")\n",
    "print(C)\n",
    "\n",
    "# ‚ö†Ô∏è Kh√°c v·ªõi element-wise multiplication!\n",
    "D = A * B  # Element-wise\n",
    "print(\"\\nA * B (element-wise):\")\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose (chuy·ªÉn v·ªã)\n",
    "\n",
    "matrix = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"Original shape:\", matrix.shape)  # (2, 3)\n",
    "print(matrix)\n",
    "\n",
    "transposed = tf.transpose(matrix)\n",
    "print(\"\\nTransposed shape:\", transposed.shape)  # (3, 2)\n",
    "print(transposed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Reduction Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√°c ph√©p to√°n gi·∫£m chi·ªÅu\n",
    "\n",
    "data = tf.constant([\n",
    "    [1.0, 2.0, 3.0],\n",
    "    [4.0, 5.0, 6.0]\n",
    "])\n",
    "\n",
    "print(\"Data:\")\n",
    "print(data)\n",
    "print()\n",
    "\n",
    "# Reduce all (to√†n b·ªô tensor)\n",
    "print(\"tf.reduce_sum(data) =\", tf.reduce_sum(data))      # 21.0\n",
    "print(\"tf.reduce_mean(data) =\", tf.reduce_mean(data))    # 3.5\n",
    "print(\"tf.reduce_max(data) =\", tf.reduce_max(data))      # 6.0\n",
    "print(\"tf.reduce_min(data) =\", tf.reduce_min(data))      # 1.0\n",
    "print()\n",
    "\n",
    "# Reduce theo axis (chi·ªÅu)\n",
    "print(\"Sum theo axis=0 (c·ªôt):\", tf.reduce_sum(data, axis=0))  # [5, 7, 9]\n",
    "print(\"Sum theo axis=1 (h√†ng):\", tf.reduce_sum(data, axis=1))  # [6, 15]\n",
    "print()\n",
    "\n",
    "# Mean theo axis\n",
    "print(\"Mean theo axis=0:\", tf.reduce_mean(data, axis=0))  # [2.5, 3.5, 4.5]\n",
    "print(\"Mean theo axis=1:\", tf.reduce_mean(data, axis=1))  # [2.0, 5.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape: Thay ƒë·ªïi shape nh∆∞ng gi·ªØ nguy√™n d·ªØ li·ªáu\n",
    "\n",
    "original = tf.constant([1, 2, 3, 4, 5, 6])\n",
    "print(\"Original:\", original, \"| shape:\", original.shape)\n",
    "\n",
    "# Reshape th√†nh 2x3\n",
    "reshaped = tf.reshape(original, [2, 3])\n",
    "print(\"\\nReshaped to [2, 3]:\")\n",
    "print(reshaped)\n",
    "\n",
    "# Reshape th√†nh 3x2\n",
    "reshaped2 = tf.reshape(original, [3, 2])\n",
    "print(\"\\nReshaped to [3, 2]:\")\n",
    "print(reshaped2)\n",
    "\n",
    "# -1: T·ª± ƒë·ªông t√≠nh chi·ªÅu\n",
    "auto_shape = tf.reshape(original, [2, -1])  # [2, 3]\n",
    "print(\"\\nAuto shape [2, -1]:\", auto_shape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand dims: Th√™m chi·ªÅu\n",
    "\n",
    "vector = tf.constant([1, 2, 3])  # shape: (3,)\n",
    "print(\"Vector shape:\", vector.shape)\n",
    "\n",
    "# Th√™m chi·ªÅu ·ªü v·ªã tr√≠ 0\n",
    "expanded_0 = tf.expand_dims(vector, axis=0)  # shape: (1, 3)\n",
    "print(\"Expanded at axis=0:\", expanded_0.shape)\n",
    "print(expanded_0)\n",
    "\n",
    "# Th√™m chi·ªÅu ·ªü v·ªã tr√≠ 1\n",
    "expanded_1 = tf.expand_dims(vector, axis=1)  # shape: (3, 1)\n",
    "print(\"\\nExpanded at axis=1:\", expanded_1.shape)\n",
    "print(expanded_1)\n",
    "\n",
    "# üéØ Use case: Th√™m batch dimension\n",
    "# Single image (224, 224, 3) -> Batch (1, 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squeeze: Lo·∫°i b·ªè c√°c chi·ªÅu = 1\n",
    "\n",
    "tensor_with_ones = tf.constant([[[1], [2], [3]]])  # shape: (1, 3, 1)\n",
    "print(\"Original shape:\", tensor_with_ones.shape)\n",
    "print(tensor_with_ones)\n",
    "\n",
    "# Squeeze t·∫•t c·∫£ chi·ªÅu = 1\n",
    "squeezed = tf.squeeze(tensor_with_ones)\n",
    "print(\"\\nSqueezed shape:\", squeezed.shape)  # (3,)\n",
    "print(squeezed)\n",
    "\n",
    "# Squeeze chi·ªÅu c·ª• th·ªÉ\n",
    "squeezed_axis = tf.squeeze(tensor_with_ones, axis=0)\n",
    "print(\"\\nSqueezed axis=0:\", squeezed_axis.shape)  # (3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Indexing & Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing gi·ªëng NumPy\n",
    "\n",
    "matrix = tf.constant([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [9, 10, 11, 12]\n",
    "])\n",
    "\n",
    "print(\"Matrix:\")\n",
    "print(matrix)\n",
    "print()\n",
    "\n",
    "# L·∫•y 1 ph·∫ßn t·ª≠\n",
    "print(\"matrix[0, 0] =\", matrix[0, 0])  # 1\n",
    "print(\"matrix[1, 2] =\", matrix[1, 2])  # 7\n",
    "print()\n",
    "\n",
    "# L·∫•y 1 h√†ng\n",
    "print(\"matrix[0] =\", matrix[0])        # [1, 2, 3, 4]\n",
    "print(\"matrix[1] =\", matrix[1])        # [5, 6, 7, 8]\n",
    "print()\n",
    "\n",
    "# L·∫•y 1 c·ªôt\n",
    "print(\"matrix[:, 0] =\", matrix[:, 0])  # [1, 5, 9]\n",
    "print(\"matrix[:, 2] =\", matrix[:, 2])  # [3, 7, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing (c·∫Øt)\n",
    "\n",
    "print(\"Matrix:\")\n",
    "print(matrix)\n",
    "print()\n",
    "\n",
    "# L·∫•y 2 h√†ng ƒë·∫ßu\n",
    "print(\"2 h√†ng ƒë·∫ßu:\")\n",
    "print(matrix[:2])  # Ho·∫∑c matrix[0:2]\n",
    "print()\n",
    "\n",
    "# L·∫•y 3 c·ªôt ƒë·∫ßu\n",
    "print(\"3 c·ªôt ƒë·∫ßu:\")\n",
    "print(matrix[:, :3])\n",
    "print()\n",
    "\n",
    "# L·∫•y sub-matrix\n",
    "print(\"Sub-matrix [0:2, 1:3]:\")\n",
    "print(matrix[0:2, 1:3])  # 2 h√†ng, c·ªôt 1-2\n",
    "print()\n",
    "\n",
    "# Step (b∆∞·ªõc nh·∫£y)\n",
    "print(\"M·ªói h√†ng, m·ªói 2 c·ªôt:\")\n",
    "print(matrix[:, ::2])  # C·ªôt 0, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean indexing\n",
    "\n",
    "data = tf.constant([1, 2, 3, 4, 5, 6])\n",
    "print(\"Data:\", data)\n",
    "\n",
    "# T·∫°o boolean mask\n",
    "mask = data > 3  # [False, False, False, True, True, True]\n",
    "print(\"Mask (data > 3):\", mask)\n",
    "\n",
    "# Filter v·ªõi boolean_mask\n",
    "filtered = tf.boolean_mask(data, mask)\n",
    "print(\"Filtered (> 3):\", filtered)  # [4, 5, 6]\n",
    "\n",
    "# Where: T√¨m indices c·ªßa True\n",
    "indices = tf.where(mask)\n",
    "print(\"Indices where True:\", indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Concatenation & Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate: N·ªëi tensor theo axis\n",
    "\n",
    "a = tf.constant([[1, 2], [3, 4]])\n",
    "b = tf.constant([[5, 6], [7, 8]])\n",
    "\n",
    "print(\"Tensor a:\")\n",
    "print(a)\n",
    "print(\"\\nTensor b:\")\n",
    "print(b)\n",
    "print()\n",
    "\n",
    "# Concat theo axis=0 (vertical)\n",
    "concat_0 = tf.concat([a, b], axis=0)\n",
    "print(\"Concat axis=0:\")\n",
    "print(concat_0)\n",
    "print(\"Shape:\", concat_0.shape)  # (4, 2)\n",
    "print()\n",
    "\n",
    "# Concat theo axis=1 (horizontal)\n",
    "concat_1 = tf.concat([a, b], axis=1)\n",
    "print(\"Concat axis=1:\")\n",
    "print(concat_1)\n",
    "print(\"Shape:\", concat_1.shape)  # (2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack: T·∫°o chi·ªÅu m·ªõi v√† x·∫øp tensor\n",
    "\n",
    "x = tf.constant([1, 2, 3])\n",
    "y = tf.constant([4, 5, 6])\n",
    "\n",
    "print(\"x:\", x, \"| shape:\", x.shape)\n",
    "print(\"y:\", y, \"| shape:\", y.shape)\n",
    "print()\n",
    "\n",
    "# Stack theo axis=0\n",
    "stacked_0 = tf.stack([x, y], axis=0)\n",
    "print(\"Stack axis=0:\")\n",
    "print(stacked_0)\n",
    "print(\"Shape:\", stacked_0.shape)  # (2, 3)\n",
    "print()\n",
    "\n",
    "# Stack theo axis=1\n",
    "stacked_1 = tf.stack([x, y], axis=1)\n",
    "print(\"Stack axis=1:\")\n",
    "print(stacked_1)\n",
    "print(\"Shape:\", stacked_1.shape)  # (3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"tf-vs-numpy\"></a>\n",
    "## 6. üîÑ TensorFlow vs NumPy\n",
    "\n",
    "### Chuy·ªÉn ƒë·ªïi qua l·∫°i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy -> TensorFlow\n",
    "numpy_array = np.array([[1, 2], [3, 4]])\n",
    "tensor = tf.constant(numpy_array)\n",
    "\n",
    "print(\"NumPy array:\")\n",
    "print(numpy_array)\n",
    "print(\"Type:\", type(numpy_array))\n",
    "print()\n",
    "\n",
    "print(\"TensorFlow tensor:\")\n",
    "print(tensor)\n",
    "print(\"Type:\", type(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow -> NumPy\n",
    "tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "numpy_array = tensor.numpy()  # Convert to numpy\n",
    "\n",
    "print(\"TensorFlow tensor:\")\n",
    "print(tensor)\n",
    "print(\"Type:\", type(tensor))\n",
    "print()\n",
    "\n",
    "print(\"NumPy array:\")\n",
    "print(numpy_array)\n",
    "print(\"Type:\", type(numpy_array))\n",
    "\n",
    "# ‚úÖ Ho·∫∑c d√πng: np.array(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So s√°nh API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy vs TensorFlow - T∆∞∆°ng t·ª± nhau!\n",
    "\n",
    "# NumPy\n",
    "np_array = np.array([1, 2, 3])\n",
    "print(\"NumPy:\")\n",
    "print(\"  Shape:\", np_array.shape)\n",
    "print(\"  Mean:\", np.mean(np_array))\n",
    "print(\"  Sum:\", np.sum(np_array))\n",
    "print(\"  Squared:\", np_array ** 2)\n",
    "print()\n",
    "\n",
    "# TensorFlow\n",
    "tf_tensor = tf.constant([1, 2, 3])\n",
    "print(\"TensorFlow:\")\n",
    "print(\"  Shape:\", tf_tensor.shape)\n",
    "print(\"  Mean:\", tf.reduce_mean(tf_tensor).numpy())\n",
    "print(\"  Sum:\", tf.reduce_sum(tf_tensor).numpy())\n",
    "print(\"  Squared:\", (tf_tensor ** 2).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S·ª± kh√°c bi·ªát quan tr·ªçng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Immutability (TensorFlow tensor kh√¥ng th·ªÉ thay ƒë·ªïi)\n",
    "\n",
    "# NumPy: Mutable\n",
    "np_arr = np.array([1, 2, 3])\n",
    "np_arr[0] = 999  # ‚úÖ OK\n",
    "print(\"NumPy after modification:\", np_arr)\n",
    "\n",
    "# TensorFlow: Immutable\n",
    "tf_tensor = tf.constant([1, 2, 3])\n",
    "try:\n",
    "    tf_tensor[0] = 999  # ‚ùå ERROR!\n",
    "except Exception as e:\n",
    "    print(\"\\nTensorFlow error:\", type(e).__name__)\n",
    "    print(\"Tensor l√† immutable - kh√¥ng th·ªÉ thay ƒë·ªïi!\")\n",
    "\n",
    "# ‚úÖ Mu·ªën thay ƒë·ªïi? D√πng tf.Variable (s·∫Ω h·ªçc sau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. GPU support\n",
    "\n",
    "# NumPy: CPU only\n",
    "np_arr = np.array([1, 2, 3])\n",
    "print(\"NumPy device: CPU only\")\n",
    "\n",
    "# TensorFlow: CPU or GPU\n",
    "tf_tensor = tf.constant([1, 2, 3])\n",
    "print(\"\\nTensorFlow device:\", tf_tensor.device)\n",
    "\n",
    "# Check available devices\n",
    "print(\"\\nAvailable devices:\")\n",
    "for device in tf.config.list_physical_devices():\n",
    "    print(f\"  - {device.device_type}: {device.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"mistakes\"></a>\n",
    "## 7. ‚ö†Ô∏è Common Mistakes\n",
    "\n",
    "### L·ªói 1: Nh·∫ßm l·∫´n shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå SAI: Shape kh√¥ng kh·ªõp\n",
    "try:\n",
    "    a = tf.constant([[1, 2, 3]])      # shape: (1, 3)\n",
    "    b = tf.constant([[1], [2], [3]])  # shape: (3, 1)\n",
    "    c = a + b  # Broadcasting s·∫Ω t·∫°o shape (3, 3) - c√≥ th·ªÉ kh√¥ng mong mu·ªën!\n",
    "    print(\"Result shape:\", c.shape)\n",
    "    print(c)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "# ‚úÖ ƒê√öNG: Check shape tr∆∞·ªõc\n",
    "print(\"\\n‚úÖ Lu√¥n print shape:\")\n",
    "print(\"a.shape:\", a.shape)\n",
    "print(\"b.shape:\", b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L·ªói 2: Dtype mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå SAI: C·ªông int v·ªõi float\n",
    "try:\n",
    "    x = tf.constant([1, 2], dtype=tf.int32)\n",
    "    y = tf.constant([1.0, 2.0], dtype=tf.float32)\n",
    "    z = x + y\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error:\", type(e).__name__)\n",
    "\n",
    "# ‚úÖ ƒê√öNG: Cast dtype\n",
    "x = tf.constant([1, 2], dtype=tf.int32)\n",
    "y = tf.constant([1.0, 2.0], dtype=tf.float32)\n",
    "z = tf.cast(x, tf.float32) + y\n",
    "print(\"\\n‚úÖ Result:\", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L·ªói 3: Nh·∫ßm element-wise vs matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.constant([[1, 2], [3, 4]])\n",
    "B = tf.constant([[5, 6], [7, 8]])\n",
    "\n",
    "# Element-wise multiplication (*)\n",
    "elementwise = A * B\n",
    "print(\"A * B (element-wise):\")\n",
    "print(elementwise)\n",
    "print()\n",
    "\n",
    "# Matrix multiplication (@)\n",
    "matmul = A @ B  # Ho·∫∑c tf.matmul(A, B)\n",
    "print(\"A @ B (matrix multiplication):\")\n",
    "print(matmul)\n",
    "\n",
    "# üéØ Quy t·∫Øc:\n",
    "# - * : Element-wise (t·ª´ng ph·∫ßn t·ª≠)\n",
    "# - @ : Matrix multiplication (nh√¢n ma tr·∫≠n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L·ªói 4: Qu√™n .numpy() khi debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow tensor khi print\n",
    "tensor = tf.constant([1.23456789, 2.34567890])\n",
    "print(\"Tensor:\", tensor)  # In ki·ªÉu TensorFlow\n",
    "\n",
    "# NumPy array (d·ªÖ ƒë·ªçc h∆°n)\n",
    "print(\"NumPy:\", tensor.numpy())  # In ki·ªÉu NumPy\n",
    "\n",
    "# ‚úÖ TIP: D√πng .numpy() khi debug ƒë·ªÉ d·ªÖ ƒë·ªçc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"exercises\"></a>\n",
    "## 8. üí™ B√†i T·∫≠p Th·ª±c H√†nh\n",
    "\n",
    "### B√†i 1: T·∫°o v√† Ki·ªÉm tra Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: T·∫°o c√°c tensor sau v√† in ra shape, dtype\n",
    "\n",
    "# 1. Tensor 3x4 to√†n s·ªë 0, dtype=float32\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 2. Tensor 5x5 random t·ª´ ph√¢n ph·ªëi chu·∫©n N(0, 1)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 3. Tensor 1D t·ª´ 0 ƒë·∫øn 9 (d√πng tf.range)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 4. Tensor 2D [[1, 2, 3], [4, 5, 6]], cast sang float32\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B√†i 2: Ph√©p To√°n Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cho 2 tensor:\n",
    "A = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "B = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
    "\n",
    "# TODO:\n",
    "# 1. T√≠nh A + B\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 2. T√≠nh A @ B (matrix multiplication)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 3. T√≠nh mean c·ªßa A theo axis=0\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 4. T√≠nh sum c·ªßa B theo axis=1\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 5. Transpose A\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B√†i 3: Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cho tensor:\n",
    "data = tf.range(24)  # [0, 1, 2, ..., 23]\n",
    "\n",
    "# TODO:\n",
    "# 1. Reshape th√†nh shape (2, 12)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 2. Reshape th√†nh shape (4, 6)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 3. Reshape th√†nh shape (2, 3, 4)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 4. Expand dims ·ªü axis=0 (th√™m batch dimension)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B√†i 4: Indexing & Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cho matrix:\n",
    "matrix = tf.constant([\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [6, 7, 8, 9, 10],\n",
    "    [11, 12, 13, 14, 15],\n",
    "    [16, 17, 18, 19, 20]\n",
    "])\n",
    "\n",
    "# TODO:\n",
    "# 1. L·∫•y ph·∫ßn t·ª≠ ·ªü h√†ng 2, c·ªôt 3 (gi√° tr·ªã 14)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 2. L·∫•y to√†n b·ªô h√†ng th·ª© 1\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 3. L·∫•y to√†n b·ªô c·ªôt th·ª© 2\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 4. L·∫•y sub-matrix 2x2 ·ªü g√≥c tr√™n b√™n tr√°i\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 5. L·ªçc ra c√°c ph·∫ßn t·ª≠ > 10\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B√†i 5: Challenge - Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o batch 4 ·∫£nh RGB k√≠ch th∆∞·ªõc 64x64\n",
    "# Shape: [batch_size, height, width, channels]\n",
    "\n",
    "# TODO:\n",
    "# 1. T·∫°o batch_images v·ªõi shape (4, 64, 64, 3)\n",
    "batch_images = None  # YOUR CODE HERE\n",
    "\n",
    "# 2. L·∫•y ·∫£nh ƒë·∫ßu ti√™n trong batch\n",
    "first_image = None  # YOUR CODE HERE\n",
    "\n",
    "# 3. L·∫•y channel R (red) c·ªßa t·∫•t c·∫£ ·∫£nh\n",
    "red_channel = None  # YOUR CODE HERE\n",
    "\n",
    "# 4. T√≠nh mean theo chi·ªÅu height (axis=1)\n",
    "mean_height = None  # YOUR CODE HERE\n",
    "\n",
    "# 5. Flatten batch_images th√†nh shape (4, 64*64*3)\n",
    "flattened = None  # YOUR CODE HERE\n",
    "\n",
    "# Print shapes ƒë·ªÉ ki·ªÉm tra\n",
    "if batch_images is not None:\n",
    "    print(\"batch_images shape:\", batch_images.shape)\n",
    "if first_image is not None:\n",
    "    print(\"first_image shape:\", first_image.shape)\n",
    "if red_channel is not None:\n",
    "    print(\"red_channel shape:\", red_channel.shape)\n",
    "if flattened is not None:\n",
    "    print(\"flattened shape:\", flattened.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì T√≥m T·∫Øt\n",
    "\n",
    "### ‚úÖ ƒê√£ h·ªçc:\n",
    "\n",
    "1. **TensorFlow & Keras**\n",
    "   - Framework Deep Learning m·∫°nh nh·∫•t\n",
    "   - Keras = High-level API\n",
    "\n",
    "2. **Tensor**\n",
    "   - M·∫£ng ƒëa chi·ªÅu\n",
    "   - Immutable (kh√°c NumPy)\n",
    "   - Support GPU\n",
    "\n",
    "3. **T·∫°o Tensor**\n",
    "   - `tf.constant()`, `tf.zeros()`, `tf.ones()`\n",
    "   - `tf.random.normal()`, `tf.random.uniform()`\n",
    "   - Convert t·ª´ NumPy\n",
    "\n",
    "4. **Shape & Dtype**\n",
    "   - Shape: K√≠ch th∆∞·ªõc tensor\n",
    "   - Dtype: Ki·ªÉu d·ªØ li·ªáu (float32, int32, ...)\n",
    "   - `tf.cast()` ƒë·ªÉ chuy·ªÉn dtype\n",
    "\n",
    "5. **Operations**\n",
    "   - Element-wise: `+, -, *, /, **`\n",
    "   - Matrix: `tf.matmul()`, `@`\n",
    "   - Reduction: `reduce_sum`, `reduce_mean`\n",
    "   - Reshape: `reshape`, `expand_dims`, `squeeze`\n",
    "   - Indexing & Slicing\n",
    "\n",
    "6. **TensorFlow vs NumPy**\n",
    "   - API t∆∞∆°ng t·ª±\n",
    "   - TF: Immutable, GPU, Auto Diff\n",
    "   - NumPy: Mutable, CPU only\n",
    "\n",
    "### üéØ Ti·∫øp theo:\n",
    "\n",
    "**File 1-B: Eager Execution & GradientTape**\n",
    "- Gradient l√† g√¨\n",
    "- tf.GradientTape\n",
    "- Linear Regression t·ª´ ƒë·∫ßu\n",
    "\n",
    "---\n",
    "\n",
    "## üìö T√†i Li·ªáu Tham Kh·∫£o\n",
    "\n",
    "- [TensorFlow Official Docs](https://www.tensorflow.org/api_docs)\n",
    "- [TensorFlow Guide - Tensors](https://www.tensorflow.org/guide/tensor)\n",
    "- [Keras Documentation](https://keras.io/)\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Ch√∫c m·ª´ng! B·∫°n ƒë√£ ho√†n th√†nh Part 1-A!**\n",
    "\n",
    "H√£y l√†m ƒë·∫ßy ƒë·ªß c√°c b√†i t·∫≠p tr∆∞·ªõc khi chuy·ªÉn sang Part 1-B."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
