{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“• FILE 3-A: TRANSFER LEARNING & MIXED PRECISION\n",
    "\n",
    "**Pháº§n:** ADVANCED & PROFESSIONAL (Production-Ready)\n",
    "\n",
    "**Má»¥c tiÃªu:**\n",
    "- âœ… Hiá»ƒu vÃ  Ã¡p dá»¥ng Transfer Learning\n",
    "- âœ… Sá»­ dá»¥ng pre-trained models (MobileNet, ResNet)\n",
    "- âœ… Fine-tuning hiá»‡u quáº£\n",
    "- âœ… Mixed Precision Training Ä‘á»ƒ tÄƒng tá»‘c\n",
    "- âœ… Tá»‘i Æ°u performance cho production\n",
    "\n",
    "**Thá»i lÆ°á»£ng:** 3-4 tuáº§n\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š Má»¥c Lá»¥c\n",
    "\n",
    "### PHáº¦N 1: TRANSFER LEARNING\n",
    "1. Transfer Learning lÃ  gÃ¬?\n",
    "2. Pre-trained Models trong TensorFlow\n",
    "3. Feature Extraction\n",
    "4. Fine-tuning\n",
    "5. Transfer Learning vá»›i MobileNetV2\n",
    "6. Transfer Learning vá»›i ResNet50\n",
    "7. Best Practices\n",
    "\n",
    "### PHáº¦N 2: MIXED PRECISION TRAINING\n",
    "1. Mixed Precision lÃ  gÃ¬?\n",
    "2. Táº¡i sao dÃ¹ng Mixed Precision?\n",
    "3. Cáº¥u hÃ¬nh Mixed Precision\n",
    "4. Training vá»›i Mixed Precision\n",
    "5. So sÃ¡nh Performance\n",
    "6. Best Practices\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import (\n",
    "    MobileNetV2, ResNet50, EfficientNetB0, VGG16\n",
    ")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "print(f\"âœ… TensorFlow version: {tf.__version__}\")\n",
    "print(f\"âœ… GPU available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "print(f\"âœ… Built with CUDA: {tf.test.is_built_with_cuda()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PHáº¦N 1: TRANSFER LEARNING\n",
    "\n",
    "## 1.1 Transfer Learning lÃ  gÃ¬?\n",
    "\n",
    "### Äá»‹nh nghÄ©a\n",
    "\n",
    "**Transfer Learning** = Sá»­ dá»¥ng láº¡i kiáº¿n thá»©c tá»« model Ä‘Ã£ Ä‘Æ°á»£c train trÃªn dataset lá»›n\n",
    "\n",
    "### VÃ­ dá»¥ thá»±c táº¿\n",
    "\n",
    "Giá»‘ng nhÆ° má»™t ngÆ°á»i Ä‘Ã£ há»c váº½ ngÆ°á»i, sáº½ dá»… dÃ ng há»c váº½ Ä‘á»™ng váº­t hÆ¡n ngÆ°á»i má»›i báº¯t Ä‘áº§u!\n",
    "\n",
    "### Táº¡i sao dÃ¹ng Transfer Learning?\n",
    "\n",
    "| Váº¥n Ä‘á» | Giáº£i phÃ¡p vá»›i Transfer Learning |\n",
    "|--------|----------------------------------|\n",
    "| ğŸ“Š Ãt dá»¯ liá»‡u | DÃ¹ng model Ä‘Ã£ há»c tá»« dataset lá»›n (ImageNet) |\n",
    "| â±ï¸ Tá»‘n thá»i gian | KhÃ´ng cáº§n train tá»« Ä‘áº§u |\n",
    "| ğŸ’° Tá»‘n chi phÃ­ | KhÃ´ng cáº§n GPU máº¡nh Ä‘á»ƒ train lÃ¢u |\n",
    "| ğŸ¯ Hiá»‡u quáº£ cao | Äáº¡t accuracy cao vá»›i Ã­t dá»¯ liá»‡u |\n",
    "\n",
    "### Khi nÃ o dÃ¹ng Transfer Learning?\n",
    "\n",
    "âœ… **NÃŠN DÃ™NG khi:**\n",
    "- Dataset nhá» (< 10,000 images)\n",
    "- BÃ i toÃ¡n tÆ°Æ¡ng tá»± vá»›i ImageNet (phÃ¢n loáº¡i áº£nh)\n",
    "- Cáº§n káº¿t quáº£ nhanh\n",
    "- Ãt tÃ i nguyÃªn (GPU, thá»i gian)\n",
    "\n",
    "âŒ **KHÃ”NG NÃŠN DÃ™NG khi:**\n",
    "- Dataset ráº¥t lá»›n vÃ  khÃ¡c biá»‡t (medical images, satellite...)\n",
    "- CÃ³ Ä‘á»§ tÃ i nguyÃªn Ä‘á»ƒ train tá»« Ä‘áº§u\n",
    "- BÃ i toÃ¡n hoÃ n toÃ n má»›i (khÃ´ng giá»‘ng ImageNet)\n",
    "\n",
    "### Hai chiáº¿n lÆ°á»£c chÃ­nh\n",
    "\n",
    "#### 1. Feature Extraction\n",
    "- **Freeze** toÃ n bá»™ pre-trained layers\n",
    "- Chá»‰ train classifier má»›i\n",
    "- Nhanh, Ã­t data\n",
    "\n",
    "#### 2. Fine-tuning\n",
    "- **Unfreeze** má»™t sá»‘ layers cuá»‘i\n",
    "- Train láº¡i vá»›i learning rate nhá»\n",
    "- Cháº­m hÆ¡n nhÆ°ng chÃ­nh xÃ¡c hÆ¡n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Pre-trained Models trong TensorFlow\n",
    "\n",
    "### ImageNet Dataset\n",
    "\n",
    "- 14 triá»‡u áº£nh\n",
    "- 1000 classes (dog, cat, car, plane...)\n",
    "- Benchmark cho Computer Vision\n",
    "\n",
    "### CÃ¡c Pre-trained Models phá»• biáº¿n\n",
    "\n",
    "| Model | Parameters | Top-1 Accuracy | Khi nÃ o dÃ¹ng |\n",
    "|-------|-----------|----------------|---------------|\n",
    "| **MobileNetV2** | 3.5M | 71.8% | Mobile, edge devices, tá»‘c Ä‘á»™ |\n",
    "| **ResNet50** | 25.6M | 75.0% | CÃ¢n báº±ng accuracy/speed |\n",
    "| **EfficientNetB0** | 5.3M | 77.1% | Hiá»‡u quáº£ nháº¥t (accuracy/size) |\n",
    "| **VGG16** | 138M | 71.3% | ÄÆ¡n giáº£n, dá»… hiá»ƒu |\n",
    "| **InceptionV3** | 23.9M | 77.9% | Accuracy cao |\n",
    "\n",
    "### Khuyáº¿n nghá»‹\n",
    "\n",
    "- ğŸš€ **Production/Mobile**: MobileNetV2, EfficientNetB0\n",
    "- ğŸ¯ **Accuracy Æ°u tiÃªn**: ResNet50, InceptionV3\n",
    "- ğŸ“š **Há»c táº­p**: MobileNetV2 (nhá», nhanh)\n",
    "- ğŸ’» **Research**: EfficientNet series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained models Ä‘á»ƒ so sÃ¡nh\n",
    "\n",
    "print(\"ğŸ“¦ Loading pre-trained models...\\n\")\n",
    "\n",
    "models_info = []\n",
    "\n",
    "# MobileNetV2\n",
    "mobilenet = MobileNetV2(weights='imagenet', include_top=False)\n",
    "models_info.append({\n",
    "    'name': 'MobileNetV2',\n",
    "    'params': mobilenet.count_params(),\n",
    "    'model': mobilenet\n",
    "})\n",
    "\n",
    "# ResNet50\n",
    "resnet = ResNet50(weights='imagenet', include_top=False)\n",
    "models_info.append({\n",
    "    'name': 'ResNet50',\n",
    "    'params': resnet.count_params(),\n",
    "    'model': resnet\n",
    "})\n",
    "\n",
    "# EfficientNetB0\n",
    "efficientnet = EfficientNetB0(weights='imagenet', include_top=False)\n",
    "models_info.append({\n",
    "    'name': 'EfficientNetB0',\n",
    "    'params': efficientnet.count_params(),\n",
    "    'model': efficientnet\n",
    "})\n",
    "\n",
    "# So sÃ¡nh\n",
    "print(\"ğŸ“Š SO SÃNH CÃC PRE-TRAINED MODELS:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Model':<20} {'Parameters':<15} {'Size (MB)':<12}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for info in models_info:\n",
    "    params = info['params']\n",
    "    size_mb = params * 4 / (1024 * 1024)  # Float32 = 4 bytes\n",
    "    print(f\"{info['name']:<20} {params:>12,}   {size_mb:>8.2f} MB\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nğŸ’¡ Giáº£i thÃ­ch:\")\n",
    "print(\"   - include_top=False: Loáº¡i bá» classifier layer (1000 classes)\")\n",
    "print(\"   - weights='imagenet': Load weights Ä‘Ã£ train trÃªn ImageNet\")\n",
    "print(\"   - ChÃºng ta sáº½ thÃªm classifier má»›i cho bÃ i toÃ¡n cá»§a mÃ¬nh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Chuáº©n bá»‹ Dataset: Cats vs Dogs\n",
    "\n",
    "ChÃºng ta sáº½ dÃ¹ng dataset **Cats vs Dogs** Ä‘á»ƒ demo Transfer Learning.\n",
    "\n",
    "### Dataset\n",
    "- 2000 áº£nh training (1000 cats, 1000 dogs)\n",
    "- 1000 áº£nh validation (500 cats, 500 dogs)\n",
    "- Subset tá»« Kaggle Cats vs Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Download Cats vs Dogs subset\n",
    "url = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "dataset_path = 'cats_and_dogs_filtered.zip'\n",
    "\n",
    "if not os.path.exists('cats_and_dogs_filtered'):\n",
    "    print(\"ğŸ“¥ Downloading dataset...\")\n",
    "    urllib.request.urlretrieve(url, dataset_path)\n",
    "    \n",
    "    print(\"ğŸ“¦ Extracting...\")\n",
    "    with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "    \n",
    "    print(\"âœ… Dataset ready!\")\n",
    "else:\n",
    "    print(\"âœ… Dataset already exists!\")\n",
    "\n",
    "# Dataset paths\n",
    "base_dir = 'cats_and_dogs_filtered'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Count images\n",
    "train_cats = len(os.listdir(os.path.join(train_dir, 'cats')))\n",
    "train_dogs = len(os.listdir(os.path.join(train_dir, 'dogs')))\n",
    "val_cats = len(os.listdir(os.path.join(validation_dir, 'cats')))\n",
    "val_dogs = len(os.listdir(os.path.join(validation_dir, 'dogs')))\n",
    "\n",
    "print(\"\\nğŸ“Š DATASET INFO:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training:\")\n",
    "print(f\"  - Cats: {train_cats}\")\n",
    "print(f\"  - Dogs: {train_dogs}\")\n",
    "print(f\"  - Total: {train_cats + train_dogs}\")\n",
    "print()\n",
    "print(f\"Validation:\")\n",
    "print(f\"  - Cats: {val_cats}\")\n",
    "print(f\"  - Dogs: {val_dogs}\")\n",
    "print(f\"  - Total: {val_cats + val_dogs}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize má»™t sá»‘ áº£nh\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Get sample images\n",
    "cat_files = [os.path.join(train_dir, 'cats', f) \n",
    "             for f in os.listdir(os.path.join(train_dir, 'cats'))[:4]]\n",
    "dog_files = [os.path.join(train_dir, 'dogs', f) \n",
    "             for f in os.listdir(os.path.join(train_dir, 'dogs'))[:4]]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i, img_path in enumerate(cat_files + dog_files):\n",
    "    img = image.load_img(img_path, target_size=(150, 150))\n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title('Cat' if i < 4 else 'Dog')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Data Pipeline vá»›i tf.keras.preprocessing\n",
    "\n",
    "### ImageDataGenerator\n",
    "\n",
    "Táº¡o data pipeline vá»›i augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Image size cho MobileNetV2\n",
    "IMG_SIZE = 224  # MobileNetV2 input size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Data augmentation cho training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,              # Normalize vá» [0, 1]\n",
    "    rotation_range=20,           # Rotate Â±20 Ä‘á»™\n",
    "    width_shift_range=0.2,       # Shift ngang 20%\n",
    "    height_shift_range=0.2,      # Shift dá»c 20%\n",
    "    horizontal_flip=True,        # Flip ngang\n",
    "    zoom_range=0.2,              # Zoom in/out 20%\n",
    "    fill_mode='nearest'          # Fill pixels khi transform\n",
    ")\n",
    "\n",
    "# Chá»‰ rescale cho validation (KHÃ”NG augment)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'  # Binary classification\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "print(\"âœ… Data generators created!\")\n",
    "print(f\"   Classes: {train_generator.class_indices}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Image size: {IMG_SIZE}x{IMG_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize augmented images\n",
    "sample_training_images, _ = next(train_generator)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    plt.imshow(sample_training_images[i])\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Augmented Training Images', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ“Š Data augmentation giÃºp:\")\n",
    "print(\"   âœ… TÄƒng sá»‘ lÆ°á»£ng data áº£o\")\n",
    "print(\"   âœ… Model robust hÆ¡n vá»›i cÃ¡c biáº¿n thá»ƒ\")\n",
    "print(\"   âœ… Giáº£m overfitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Feature Extraction vá»›i MobileNetV2\n",
    "\n",
    "### Chiáº¿n lÆ°á»£c 1: Feature Extraction\n",
    "\n",
    "```\n",
    "Pre-trained MobileNetV2 (FROZEN)\n",
    "        â†“\n",
    "Global Average Pooling\n",
    "        â†“\n",
    "Dense (NEW, TRAINABLE)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained MobileNetV2\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,  # Loáº¡i bá» classification head\n",
    "    weights='imagenet'  # Weights tá»« ImageNet\n",
    ")\n",
    "\n",
    "# FREEZE base model (QUAN TRá»ŒNG!)\n",
    "base_model.trainable = False\n",
    "\n",
    "print(\"ğŸ“¦ MobileNetV2 base model:\")\n",
    "print(f\"   Total layers: {len(base_model.layers)}\")\n",
    "print(f\"   Trainable: {base_model.trainable}\")\n",
    "print(f\"   Parameters: {base_model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XÃ¢y dá»±ng model vá»›i Feature Extraction\n",
    "\n",
    "# Input\n",
    "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# Pre-trained base (frozen)\n",
    "x = base_model(inputs, training=False)  # training=False Ä‘á»ƒ khÃ´ng update batch norm\n",
    "\n",
    "# Global Average Pooling\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Dropout Ä‘á»ƒ trÃ¡nh overfitting\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "# Output layer\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create model\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "print(\"\\nâœ… Feature Extraction Model:\")\n",
    "model.summary()\n",
    "\n",
    "# Giáº£i thÃ­ch:\n",
    "print(\"\\nğŸ“š Giáº£i thÃ­ch:\")\n",
    "print(\"   1. Base model (MobileNetV2): FROZEN â†’ KhÃ´ng train\")\n",
    "print(\"   2. GlobalAveragePooling2D: Chuyá»ƒn feature maps thÃ nh vector\")\n",
    "print(\"   3. Dropout(0.2): Táº¯t 20% neurons â†’ TrÃ¡nh overfitting\")\n",
    "print(\"   4. Dense(1, sigmoid): Binary classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiá»ƒm tra trainable parameters\n",
    "trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])\n",
    "non_trainable_params = sum([tf.size(w).numpy() for w in model.non_trainable_weights])\n",
    "total_params = model.count_params()\n",
    "\n",
    "print(\"ğŸ“Š PARAMETERS BREAKDOWN:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total parameters:        {total_params:>15,}\")\n",
    "print(f\"Trainable parameters:    {trainable_params:>15,}  ({trainable_params/total_params*100:.2f}%)\")\n",
    "print(f\"Non-trainable parameters:{non_trainable_params:>15,}  ({non_trainable_params/total_params*100:.2f}%)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nğŸ’¡ ChÃº Ã½:\")\n",
    "print(\"   - Chá»‰ train ~0.1% parameters!\")\n",
    "print(\"   - Training ráº¥t nhanh\")\n",
    "print(\"   - PhÃ¹ há»£p khi cÃ³ Ã­t dá»¯ liá»‡u\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"âœ… Model compiled!\")\n",
    "print(\"   Optimizer: Adam (lr=0.001)\")\n",
    "print(\"   Loss: binary_crossentropy\")\n",
    "print(\"   Metrics: accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_feature_extraction_model.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"âœ… Callbacks configured:\")\n",
    "print(\"   1. EarlyStopping: Stop náº¿u khÃ´ng cáº£i thiá»‡n sau 5 epochs\")\n",
    "print(\"   2. ModelCheckpoint: LÆ°u model tá»‘t nháº¥t\")\n",
    "print(\"   3. ReduceLROnPlateau: Giáº£m LR náº¿u stuck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "print(\"ğŸš€ Training Feature Extraction Model...\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history\n",
    "def plot_history(history, title_prefix=''):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    \n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training', linewidth=2)\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "    plt.xlabel('Epoch', fontsize=11)\n",
    "    plt.ylabel('Accuracy', fontsize=11)\n",
    "    plt.title(f'{title_prefix}Model Accuracy', fontsize=12, fontweight='bold')\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training', linewidth=2)\n",
    "    plt.plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "    plt.xlabel('Epoch', fontsize=11)\n",
    "    plt.ylabel('Loss', fontsize=11)\n",
    "    plt.title(f'{title_prefix}Model Loss', fontsize=12, fontweight='bold')\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history, 'Feature Extraction - ')\n",
    "\n",
    "print(\"ğŸ“Š Quan sÃ¡t:\")\n",
    "print(\"   âœ… Validation accuracy cao ngay tá»« Ä‘áº§u (transfer learning!)\")\n",
    "print(\"   âœ… Converge nhanh (chá»‰ train classifier)\")\n",
    "print(\"   âœ… Ãt overfit (frozen base model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "print(\"ğŸ“Š FEATURE EXTRACTION RESULTS:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "train_loss, train_acc = model.evaluate(train_generator, verbose=0)\n",
    "val_loss, val_acc = model.evaluate(val_generator, verbose=0)\n",
    "\n",
    "print(f\"Training Accuracy:   {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "print(f\"Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nâœ… Káº¿t quáº£ tá»‘t vá»›i chá»‰ 2000 áº£nh training!\")\n",
    "print(\"   Nhá» pre-trained weights tá»« ImageNet (1.4M áº£nh)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Fine-tuning\n",
    "\n",
    "### Chiáº¿n lÆ°á»£c 2: Fine-tuning\n",
    "\n",
    "**Fine-tuning** = Unfreeze má»™t sá»‘ layers cuá»‘i vÃ  train láº¡i vá»›i learning rate nhá»\n",
    "\n",
    "### Khi nÃ o dÃ¹ng Fine-tuning?\n",
    "\n",
    "âœ… **DÃ¹ng khi:**\n",
    "- Feature Extraction chÆ°a Ä‘á»§ tá»‘t\n",
    "- CÃ³ Ä‘á»§ dá»¯ liá»‡u (>5000 images)\n",
    "- Dataset khÃ¡c biá»‡t vá»›i ImageNet\n",
    "\n",
    "### Quy trÃ¬nh Fine-tuning\n",
    "\n",
    "1. Train vá»›i Feature Extraction trÆ°á»›c\n",
    "2. Unfreeze má»™t sá»‘ layers cuá»‘i\n",
    "3. Train láº¡i vá»›i learning rate Ráº¤T NHá» (0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze base model\n",
    "base_model.trainable = True\n",
    "\n",
    "print(f\"ğŸ“¦ Base model cÃ³ {len(base_model.layers)} layers\")\n",
    "print(\"\\nğŸ”“ Unfreeze cÃ¡c layers cuá»‘i...\")\n",
    "\n",
    "# Freeze cÃ¡c layers Ä‘áº§u (100 layers Ä‘áº§u)\n",
    "for layer in base_model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Unfreeze cÃ¡c layers cuá»‘i\n",
    "for layer in base_model.layers[100:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Äáº¿m trainable layers\n",
    "trainable_layers = sum([layer.trainable for layer in base_model.layers])\n",
    "print(f\"\\nâœ… Trainable layers: {trainable_layers}/{len(base_model.layers)}\")\n",
    "\n",
    "# Äáº¿m parameters\n",
    "trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])\n",
    "total_params = model.count_params()\n",
    "\n",
    "print(\"\\nğŸ“Š PARAMETERS AFTER UNFREEZING:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total parameters:     {total_params:>15,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:>15,}  ({trainable_params/total_params*100:.2f}%)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nğŸ’¡ ChÃº Ã½:\")\n",
    "print(\"   - Unfreeze ~50% layers cuá»‘i\")\n",
    "print(\"   - Giá»¯ frozen cÃ¡c layers Ä‘áº§u (low-level features)\")\n",
    "print(\"   - Train cÃ¡c layers cuá»‘i (high-level features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompile vá»›i learning rate Ráº¤T NHá»\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),  # 10x nhá» hÆ¡n!\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"âœ… Model recompiled for fine-tuning!\")\n",
    "print(\"   Learning rate: 1e-5 (Ráº¤T NHá»)\")\n",
    "print(\"\\nâš ï¸  QUAN TRá»ŒNG:\")\n",
    "print(\"   - Learning rate pháº£i Ráº¤T NHá» khi fine-tuning\")\n",
    "print(\"   - Náº¿u quÃ¡ lá»›n â†’ phÃ¡ há»§y pre-trained weights\")\n",
    "print(\"   - Khuyáº¿n nghá»‹: 10-100x nhá» hÆ¡n training tá»« Ä‘áº§u\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning\n",
    "print(\"ğŸš€ Fine-tuning model...\\n\")\n",
    "\n",
    "# Callbacks cho fine-tuning\n",
    "finetune_callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_finetuned_model.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,  # Ãt epochs hÆ¡n\n",
    "    validation_data=val_generator,\n",
    "    callbacks=finetune_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Fine-tuning completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fine-tuning results\n",
    "plot_history(history_finetune, 'Fine-tuning - ')\n",
    "\n",
    "print(\"ğŸ“Š Quan sÃ¡t:\")\n",
    "print(\"   âœ… Accuracy tÄƒng thÃªm sau fine-tuning\")\n",
    "print(\"   âœ… Model adapt tá»‘t hÆ¡n vá»›i Cats vs Dogs\")\n",
    "print(\"   âš ï¸  Training cháº­m hÆ¡n (train nhiá»u layers hÆ¡n)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare Feature Extraction vs Fine-tuning\n",
    "print(\"ğŸ“Š SO SÃNH Káº¾T QUáº¢:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load best feature extraction model\n",
    "fe_model = keras.models.load_model('best_feature_extraction_model.keras')\n",
    "fe_val_loss, fe_val_acc = fe_model.evaluate(val_generator, verbose=0)\n",
    "\n",
    "# Current fine-tuned model\n",
    "ft_val_loss, ft_val_acc = model.evaluate(val_generator, verbose=0)\n",
    "\n",
    "print(f\"{'Method':<25} {'Val Accuracy':<15} {'Val Loss':<12}\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Feature Extraction':<25} {fe_val_acc:>10.4f}    {fe_val_loss:>10.4f}\")\n",
    "print(f\"{'Fine-tuning':<25} {ft_val_acc:>10.4f}    {ft_val_loss:>10.4f}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "improvement = (ft_val_acc - fe_val_acc) * 100\n",
    "print(f\"\\nâœ… Improvement: +{improvement:.2f}% accuracy\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Káº¿t luáº­n:\")\n",
    "print(\"   - Feature Extraction: Nhanh, Ä‘á»§ tá»‘t cho nhiá»u bÃ i toÃ¡n\")\n",
    "print(\"   - Fine-tuning: Cháº­m hÆ¡n nhÆ°ng accuracy cao hÆ¡n\")\n",
    "print(\"   - Khuyáº¿n nghá»‹: Thá»­ Feature Extraction trÆ°á»›c, náº¿u chÆ°a Ä‘á»§ tá»‘t â†’ Fine-tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Transfer Learning vá»›i ResNet50\n",
    "\n",
    "### ResNet50\n",
    "\n",
    "- **Residual Networks**: Skip connections\n",
    "- 50 layers deep\n",
    "- 25.6M parameters\n",
    "- Top-1 accuracy: 75.0% trÃªn ImageNet\n",
    "\n",
    "### Khi nÃ o dÃ¹ng ResNet50?\n",
    "\n",
    "âœ… Cáº§n accuracy cao hÆ¡n MobileNet\n",
    "âœ… CÃ³ Ä‘á»§ GPU memory\n",
    "âœ… KhÃ´ng Æ°u tiÃªn tá»‘c Ä‘á»™ inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50\n",
    "resnet_base = ResNet50(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Freeze\n",
    "resnet_base.trainable = False\n",
    "\n",
    "# Build model\n",
    "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = resnet_base(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "resnet_model = keras.Model(inputs, outputs)\n",
    "\n",
    "print(\"âœ… ResNet50 Model:\")\n",
    "print(f\"   Total layers: {len(resnet_base.layers)}\")\n",
    "print(f\"   Total parameters: {resnet_model.count_params():,}\")\n",
    "print(f\"   Trainable parameters: {sum([tf.size(w).numpy() for w in resnet_model.trainable_weights]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "resnet_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(\"ğŸš€ Training ResNet50 model...\\n\")\n",
    "\n",
    "history_resnet = resnet_model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=5, restore_best_weights=True),\n",
    "        ModelCheckpoint('best_resnet_model.keras', save_best_only=True)\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… ResNet50 training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "print(\"ğŸ“Š SO SÃNH Táº¤T Cáº¢ CÃC MODELS:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Evaluate all models\n",
    "mobilenet_val_loss, mobilenet_val_acc = fe_model.evaluate(val_generator, verbose=0)\n",
    "resnet_val_loss, resnet_val_acc = resnet_model.evaluate(val_generator, verbose=0)\n",
    "\n",
    "results = [\n",
    "    ('MobileNetV2 (Feature Extraction)', mobilenet_val_acc, mobilenet_val_loss, 3.5),\n",
    "    ('MobileNetV2 (Fine-tuned)', ft_val_acc, ft_val_loss, 3.5),\n",
    "    ('ResNet50 (Feature Extraction)', resnet_val_acc, resnet_val_loss, 25.6)\n",
    "]\n",
    "\n",
    "print(f\"{'Model':<35} {'Val Acc':<12} {'Val Loss':<12} {'Size (M params)'}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for name, acc, loss, size in results:\n",
    "    print(f\"{name:<35} {acc:>8.4f}    {loss:>10.4f}    {size:>10.1f}M\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ’¡ Káº¿t luáº­n:\")\n",
    "print(\"   - MobileNetV2: Nhá», nhanh, phÃ¹ há»£p production\")\n",
    "print(\"   - ResNet50: Lá»›n hÆ¡n, accuracy cÃ³ thá»ƒ cao hÆ¡n\")\n",
    "print(\"   - Fine-tuning: TÄƒng accuracy nhÆ°ng tá»‘n thá»i gian hÆ¡n\")\n",
    "print(\"\\n   Khuyáº¿n nghá»‹: MobileNetV2 + Fine-tuning cho háº§u háº¿t bÃ i toÃ¡n!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Best Practices cho Transfer Learning\n",
    "\n",
    "### âœ… DO (NÃŠN LÃ€M)\n",
    "\n",
    "#### 1. Data Preparation\n",
    "```python\n",
    "# âœ… Normalize theo pre-trained model\n",
    "# MobileNetV2: [0, 1]\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# ResNet50: mean=[123.68, 116.78, 103.94]\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "```\n",
    "\n",
    "#### 2. Learning Rate\n",
    "```python\n",
    "# âœ… Feature Extraction: Normal LR\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# âœ… Fine-tuning: Ráº¤T NHá»\n",
    "optimizer = Adam(learning_rate=1e-5)\n",
    "```\n",
    "\n",
    "#### 3. Layer Freezing\n",
    "```python\n",
    "# âœ… Freeze base model khi Feature Extraction\n",
    "base_model.trainable = False\n",
    "\n",
    "# âœ… Unfreeze tá»« tá»« khi Fine-tuning\n",
    "for layer in base_model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "```\n",
    "\n",
    "#### 4. Training Strategy\n",
    "```python\n",
    "# âœ… Step 1: Feature Extraction (epochs=10-20)\n",
    "# âœ… Step 2: Fine-tuning (epochs=10)\n",
    "```\n",
    "\n",
    "### âŒ DON'T (KHÃ”NG NÃŠN)\n",
    "\n",
    "#### 1. Learning Rate quÃ¡ lá»›n khi Fine-tuning\n",
    "```python\n",
    "# âŒ WRONG: PhÃ¡ há»§y pre-trained weights\n",
    "optimizer = Adam(learning_rate=0.01)  # QuÃ¡ lá»›n!\n",
    "\n",
    "# âœ… CORRECT\n",
    "optimizer = Adam(learning_rate=1e-5)\n",
    "```\n",
    "\n",
    "#### 2. Unfreeze táº¥t cáº£ layers ngay tá»« Ä‘áº§u\n",
    "```python\n",
    "# âŒ WRONG\n",
    "base_model.trainable = True  # Ngay tá»« Ä‘áº§u!\n",
    "\n",
    "# âœ… CORRECT: Feature Extraction trÆ°á»›c\n",
    "base_model.trainable = False\n",
    "# ... train ...\n",
    "# Sau Ä‘Ã³ má»›i unfreeze\n",
    "```\n",
    "\n",
    "#### 3. QuÃªn normalize data\n",
    "```python\n",
    "# âŒ WRONG: QuÃªn rescale\n",
    "train_datagen = ImageDataGenerator()  # Pixel values [0, 255]\n",
    "\n",
    "# âœ… CORRECT\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "```\n",
    "\n",
    "#### 4. KhÃ´ng dÃ¹ng data augmentation\n",
    "```python\n",
    "# âŒ WRONG: Chá»‰ rescale\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# âœ… CORRECT: ThÃªm augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2\n",
    ")\n",
    "```\n",
    "\n",
    "### ğŸ¯ Workflow Chuáº©n\n",
    "\n",
    "```python\n",
    "# STEP 1: Feature Extraction\n",
    "base_model.trainable = False\n",
    "model.compile(optimizer=Adam(lr=0.001))\n",
    "model.fit(epochs=10)\n",
    "\n",
    "# STEP 2: Fine-tuning (optional)\n",
    "base_model.trainable = True\n",
    "# Freeze layers Ä‘áº§u\n",
    "for layer in base_model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "model.compile(optimizer=Adam(lr=1e-5))  # LR nhá»!\n",
    "model.fit(epochs=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PHáº¦N 2: MIXED PRECISION TRAINING\n",
    "\n",
    "## 2.1 Mixed Precision lÃ  gÃ¬?\n",
    "\n",
    "### Äá»‹nh nghÄ©a\n",
    "\n",
    "**Mixed Precision** = Training model vá»›i 2 Ä‘á»™ chÃ­nh xÃ¡c sá»‘ há»c khÃ¡c nhau:\n",
    "- **Float16 (FP16)**: 16-bit floating point\n",
    "- **Float32 (FP32)**: 32-bit floating point (default)\n",
    "\n",
    "### Táº¡i sao dÃ¹ng Mixed Precision?\n",
    "\n",
    "| Lá»£i Ã­ch | Giáº£i thÃ­ch |\n",
    "|---------|------------|\n",
    "| ğŸš€ **Nhanh hÆ¡n** | FP16 tÃ­nh toÃ¡n nhanh hÆ¡n 2-3x (trÃªn GPU hiá»‡n Ä‘áº¡i) |\n",
    "| ğŸ’¾ **Ãt memory** | FP16 chá»‰ dÃ¹ng 50% memory so vá»›i FP32 |\n",
    "| ğŸ“Š **Batch size lá»›n hÆ¡n** | Memory tiáº¿t kiá»‡m â†’ batch size lá»›n hÆ¡n |\n",
    "| âœ… **KhÃ´ng giáº£m accuracy** | Káº¿t quáº£ tÆ°Æ¡ng Ä‘Æ°Æ¡ng FP32 |\n",
    "\n",
    "### Khi nÃ o dÃ¹ng Mixed Precision?\n",
    "\n",
    "âœ… **NÃŠN DÃ™NG khi:**\n",
    "- CÃ³ GPU há»— trá»£ Tensor Cores (V100, A100, RTX 20xx+)\n",
    "- Model lá»›n, tá»‘n memory\n",
    "- Muá»‘n tÄƒng tá»‘c training\n",
    "- Production environment\n",
    "\n",
    "âŒ **KHÃ”NG Cáº¦N khi:**\n",
    "- Chá»‰ cÃ³ CPU\n",
    "- GPU cÅ© (khÃ´ng há»— trá»£ FP16)\n",
    "- Model nhá», train nhanh rá»“i\n",
    "\n",
    "### CÃ¡ch hoáº¡t Ä‘á»™ng\n",
    "\n",
    "```\n",
    "Forward pass:  FP16 (nhanh, Ã­t memory)\n",
    "     â†“\n",
    "Compute loss:  FP16\n",
    "     â†“\n",
    "Backward pass: FP16 (tÃ­nh gradient)\n",
    "     â†“\n",
    "Update weights: FP32 (chÃ­nh xÃ¡c)\n",
    "```\n",
    "\n",
    "**Loss Scaling:** NhÃ¢n gradient vá»›i má»™t sá»‘ lá»›n Ä‘á»ƒ trÃ¡nh underflow trong FP16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Kiá»ƒm tra GPU há»— trá»£ Mixed Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiá»ƒm tra GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "print(\"ğŸ–¥ï¸  GPU INFO:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if len(gpus) == 0:\n",
    "    print(\"âŒ No GPU found\")\n",
    "    print(\"   Mixed Precision chá»‰ hoáº¡t Ä‘á»™ng trÃªn GPU\")\n",
    "    print(\"   Báº¡n cÃ³ thá»ƒ cháº¡y code nÃ y nhÆ°ng khÃ´ng tháº¥y speedup\")\n",
    "else:\n",
    "    print(f\"âœ… Found {len(gpus)} GPU(s):\")\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        print(f\"   GPU {i}: {gpu.name}\")\n",
    "    \n",
    "    # Kiá»ƒm tra compute capability\n",
    "    print(\"\\nğŸ“Š Mixed Precision Support:\")\n",
    "    print(\"   GPU vá»›i Tensor Cores (compute capability >= 7.0):\")\n",
    "    print(\"   - V100, A100, RTX 20xx/30xx/40xx: âœ… Full support\")\n",
    "    print(\"   - GTX 16xx, older: âš ï¸  Limited support\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Cáº¥u hÃ¬nh Mixed Precision\n",
    "\n",
    "### CÃ¡ch báº­t Mixed Precision trong TensorFlow 2.x\n",
    "\n",
    "Ráº¥t Ä‘Æ¡n giáº£n - chá»‰ cáº§n 1 dÃ²ng code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Báº­t Mixed Precision\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "# Set policy\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "print(\"âœ… Mixed Precision enabled!\")\n",
    "print(f\"   Compute dtype: {policy.compute_dtype}\")\n",
    "print(f\"   Variable dtype: {policy.variable_dtype}\")\n",
    "\n",
    "# Giáº£i thÃ­ch:\n",
    "print(\"\\nğŸ“š Giáº£i thÃ­ch:\")\n",
    "print(\"   - compute_dtype: float16 â†’ Forward/backward pass dÃ¹ng FP16\")\n",
    "print(\"   - variable_dtype: float32 â†’ Weights váº«n lÆ°u á»Ÿ FP32\")\n",
    "print(\"   â†’ Nhanh hÆ¡n nhÆ°ng khÃ´ng máº¥t Ä‘á»™ chÃ­nh xÃ¡c!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiá»ƒm tra policy hiá»‡n táº¡i\n",
    "current_policy = mixed_precision.global_policy()\n",
    "print(f\"Current policy: {current_policy}\")\n",
    "print(f\"Compute dtype: {current_policy.compute_dtype}\")\n",
    "print(f\"Variable dtype: {current_policy.variable_dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Training vá»›i Mixed Precision\n",
    "\n",
    "### Build model vá»›i Mixed Precision\n",
    "\n",
    "âš ï¸ **LÆ¯U Ã:** Output layer pháº£i dÃ¹ng float32 (khÃ´ng pháº£i float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model vá»›i Mixed Precision\n",
    "def create_model_mixed_precision():\n",
    "    \"\"\"Create model with mixed precision\"\"\"\n",
    "    # Load base model\n",
    "    base_model = MobileNetV2(\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build model\n",
    "    inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(1)(x)  # No activation yet\n",
    "    \n",
    "    # âš ï¸ QUAN TRá»ŒNG: Output layer PHáº¢I á»Ÿ float32\n",
    "    x = layers.Activation('sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model_mp = create_model_mixed_precision()\n",
    "\n",
    "print(\"âœ… Mixed Precision Model created!\")\n",
    "print(\"\\nğŸ“š LÆ°u Ã½:\")\n",
    "print(\"   - layers.Activation('sigmoid', dtype='float32')\")\n",
    "print(\"   - Output layer PHáº¢I á»Ÿ float32 Ä‘á»ƒ stable\")\n",
    "print(\"   - KhÃ´ng Ä‘á»ƒ output layer á»Ÿ float16 â†’ numerical instability!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "# âš ï¸ QUAN TRá»ŒNG: Optimizer cáº§n Ä‘Æ°á»£c wrap vá»›i LossScaleOptimizer\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Wrap optimizer vá»›i LossScaleOptimizer\n",
    "optimizer = mixed_precision.LossScaleOptimizer(optimizer)\n",
    "\n",
    "model_mp.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"âœ… Model compiled with Mixed Precision!\")\n",
    "print(\"\\nğŸ“š LossScaleOptimizer:\")\n",
    "print(\"   - Tá»± Ä‘á»™ng scale loss Ä‘á»ƒ trÃ¡nh gradient underflow\")\n",
    "print(\"   - Dynamically Ä‘iá»u chá»‰nh loss scale\")\n",
    "print(\"   - GiÃºp training stable vá»›i FP16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 So sÃ¡nh Performance: FP32 vs Mixed Precision\n",
    "\n",
    "ChÃºng ta sáº½ train 2 models vÃ  so sÃ¡nh:\n",
    "1. **FP32 (baseline)**: Training thÃ´ng thÆ°á»ng\n",
    "2. **Mixed Precision**: Training vá»›i FP16+FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº¯t Mixed Precision Ä‘á»ƒ train baseline\n",
    "mixed_precision.set_global_policy('float32')\n",
    "\n",
    "# Create FP32 model\n",
    "base_model_fp32 = MobileNetV2(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "base_model_fp32.trainable = False\n",
    "\n",
    "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = base_model_fp32(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model_fp32 = keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile\n",
    "model_fp32.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"âœ… FP32 baseline model created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train FP32 model\n",
    "print(\"ğŸš€ Training FP32 model...\\n\")\n",
    "\n",
    "start_time_fp32 = time.time()\n",
    "\n",
    "history_fp32 = model_fp32.fit(\n",
    "    train_generator,\n",
    "    epochs=5,  # Ãt epochs Ä‘á»ƒ demo\n",
    "    validation_data=val_generator,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "training_time_fp32 = time.time() - start_time_fp32\n",
    "\n",
    "print(f\"\\nâœ… FP32 training completed in {training_time_fp32:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Báº­t láº¡i Mixed Precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Train Mixed Precision model\n",
    "print(\"ğŸš€ Training Mixed Precision model...\\n\")\n",
    "\n",
    "start_time_mp = time.time()\n",
    "\n",
    "history_mp = model_mp.fit(\n",
    "    train_generator,\n",
    "    epochs=5,\n",
    "    validation_data=val_generator,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "training_time_mp = time.time() - start_time_mp\n",
    "\n",
    "print(f\"\\nâœ… Mixed Precision training completed in {training_time_mp:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "print(\"ğŸ“Š PERFORMANCE COMPARISON:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Training time\n",
    "speedup = training_time_fp32 / training_time_mp\n",
    "time_saved = training_time_fp32 - training_time_mp\n",
    "\n",
    "print(\"TRAINING TIME:\")\n",
    "print(f\"  FP32:           {training_time_fp32:>8.2f}s\")\n",
    "print(f\"  Mixed Precision:{training_time_mp:>8.2f}s\")\n",
    "print(f\"  Speedup:        {speedup:>8.2f}x\")\n",
    "print(f\"  Time saved:     {time_saved:>8.2f}s ({time_saved/training_time_fp32*100:.1f}%)\")\n",
    "print()\n",
    "\n",
    "# Final accuracy\n",
    "fp32_val_acc = history_fp32.history['val_accuracy'][-1]\n",
    "mp_val_acc = history_mp.history['val_accuracy'][-1]\n",
    "\n",
    "print(\"VALIDATION ACCURACY:\")\n",
    "print(f\"  FP32:           {fp32_val_acc:>8.4f}\")\n",
    "print(f\"  Mixed Precision:{mp_val_acc:>8.4f}\")\n",
    "print(f\"  Difference:     {abs(fp32_val_acc - mp_val_acc):>8.4f}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nâœ… Káº¿t luáº­n:\")\n",
    "if speedup > 1.3:\n",
    "    print(f\"   ğŸš€ Mixed Precision nhanh hÆ¡n {speedup:.2f}x!\")\n",
    "    print(f\"   ğŸ’¾ Tiáº¿t kiá»‡m {time_saved:.1f}s má»—i 5 epochs\")\n",
    "else:\n",
    "    print(f\"   âš ï¸  Speedup khÃ´ng rÃµ rÃ ng (cÃ³ thá»ƒ do GPU khÃ´ng há»— trá»£ tá»‘t)\")\n",
    "\n",
    "if abs(fp32_val_acc - mp_val_acc) < 0.01:\n",
    "    print(f\"   âœ… Accuracy tÆ°Æ¡ng Ä‘Æ°Æ¡ng nhau\")\n",
    "else:\n",
    "    print(f\"   âš ï¸  Accuracy khÃ¡c biá»‡t Ä‘Ã¡ng ká»ƒ\")\n",
    "\n",
    "print(\"\\nğŸ’¡ LÆ°u Ã½:\")\n",
    "print(\"   - Speedup phá»¥ thuá»™c vÃ o GPU (V100/A100 tá»‘t nháº¥t)\")\n",
    "print(\"   - Vá»›i CPU hoáº·c GPU cÅ©, khÃ´ng tháº¥y improvement\")\n",
    "print(\"   - Model cÃ ng lá»›n, speedup cÃ ng rÃµ rÃ ng\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Best Practices cho Mixed Precision\n",
    "\n",
    "### âœ… DO (NÃŠN LÃ€M)\n",
    "\n",
    "#### 1. Báº­t Mixed Precision ngay tá»« Ä‘áº§u\n",
    "```python\n",
    "# âœ… Äáº·t á»Ÿ Ä‘áº§u code\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "```\n",
    "\n",
    "#### 2. Output layer dÃ¹ng float32\n",
    "```python\n",
    "# âœ… CORRECT\n",
    "x = layers.Dense(1)(x)\n",
    "x = layers.Activation('sigmoid', dtype='float32')(x)\n",
    "\n",
    "# Hoáº·c\n",
    "outputs = layers.Dense(1, activation='sigmoid', dtype='float32')(x)\n",
    "```\n",
    "\n",
    "#### 3. Wrap optimizer\n",
    "```python\n",
    "# âœ… CORRECT\n",
    "optimizer = keras.optimizers.Adam()\n",
    "optimizer = mixed_precision.LossScaleOptimizer(optimizer)\n",
    "```\n",
    "\n",
    "#### 4. Kiá»ƒm tra GPU support\n",
    "```python\n",
    "# âœ… Check trÆ°á»›c khi dÃ¹ng\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if len(gpus) > 0:\n",
    "    mixed_precision.set_global_policy('mixed_float16')\n",
    "```\n",
    "\n",
    "### âŒ DON'T (KHÃ”NG NÃŠN)\n",
    "\n",
    "#### 1. QuÃªn wrap optimizer\n",
    "```python\n",
    "# âŒ WRONG: KhÃ´ng wrap optimizer\n",
    "optimizer = keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer)  # Thiáº¿u LossScaleOptimizer!\n",
    "\n",
    "# âœ… CORRECT\n",
    "optimizer = mixed_precision.LossScaleOptimizer(optimizer)\n",
    "```\n",
    "\n",
    "#### 2. Output layer á»Ÿ float16\n",
    "```python\n",
    "# âŒ WRONG\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)  # dtype=float16\n",
    "\n",
    "# âœ… CORRECT\n",
    "outputs = layers.Dense(1, activation='sigmoid', dtype='float32')(x)\n",
    "```\n",
    "\n",
    "#### 3. DÃ¹ng Mixed Precision trÃªn CPU\n",
    "```python\n",
    "# âŒ WRONG: Waste time checking\n",
    "mixed_precision.set_global_policy('mixed_float16')  # TrÃªn CPU!\n",
    "\n",
    "# âœ… CORRECT: Check GPU first\n",
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    mixed_precision.set_global_policy('mixed_float16')\n",
    "```\n",
    "\n",
    "### ğŸ¯ Checklist\n",
    "\n",
    "- [ ] CÃ³ GPU há»— trá»£ Tensor Cores?\n",
    "- [ ] ÄÃ£ set policy á»Ÿ Ä‘áº§u code?\n",
    "- [ ] Output layer dÃ¹ng dtype='float32'?\n",
    "- [ ] Optimizer Ä‘Æ°á»£c wrap vá»›i LossScaleOptimizer?\n",
    "- [ ] ÄÃ£ test accuracy khÃ´ng bá»‹ áº£nh hÆ°á»Ÿng?\n",
    "\n",
    "### ğŸ“Š Khi nÃ o tháº¥y speedup rÃµ rÃ ng?\n",
    "\n",
    "| Äiá»u kiá»‡n | Speedup |\n",
    "|-----------|----------|\n",
    "| V100/A100 GPU | 2-3x |\n",
    "| RTX 30xx | 1.5-2x |\n",
    "| RTX 20xx | 1.2-1.5x |\n",
    "| GTX 16xx/CPU | ~1x (khÃ´ng cÃ³) |\n",
    "\n",
    "Model cÃ ng lá»›n, speedup cÃ ng rÃµ rÃ ng!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“ Tá»•ng káº¿t FILE 3-A\n",
    "\n",
    "## âœ… Nhá»¯ng gÃ¬ Ä‘Ã£ há»c\n",
    "\n",
    "### 1. Transfer Learning\n",
    "- **KhÃ¡i niá»‡m**: Sá»­ dá»¥ng pre-trained models\n",
    "- **Chiáº¿n lÆ°á»£c**:\n",
    "  - Feature Extraction (freeze base, train classifier)\n",
    "  - Fine-tuning (unfreeze má»™t sá»‘ layers, train vá»›i LR nhá»)\n",
    "- **Pre-trained models**: MobileNetV2, ResNet50\n",
    "- **Best practices**: LR nhá», freeze tá»« tá»«, data augmentation\n",
    "\n",
    "### 2. Mixed Precision Training\n",
    "- **KhÃ¡i niá»‡m**: Training vá»›i FP16 + FP32\n",
    "- **Lá»£i Ã­ch**: 2-3x nhanh hÆ¡n, Ã­t memory hÆ¡n\n",
    "- **CÃ¡ch dÃ¹ng**: 1 dÃ²ng code Ä‘á»ƒ báº­t\n",
    "- **Best practices**: Output layer float32, wrap optimizer\n",
    "\n",
    "## ğŸš€ Key Takeaways\n",
    "\n",
    "1. **Transfer Learning** lÃ  must-have cho Computer Vision\n",
    "2. **Feature Extraction** â†’ nhanh, Ä‘á»§ tá»‘t cho nhiá»u bÃ i toÃ¡n\n",
    "3. **Fine-tuning** â†’ cháº­m hÆ¡n nhÆ°ng accuracy cao hÆ¡n\n",
    "4. **Mixed Precision** â†’ free speedup náº¿u cÃ³ GPU tá»‘t\n",
    "5. **MobileNetV2** â†’ best choice cho production\n",
    "\n",
    "## ğŸ“ Next Steps\n",
    "\n",
    "File tiáº¿p theo (**3-B**) sáº½ há»c:\n",
    "- Clean ML Pipeline\n",
    "- Reproducibility\n",
    "- Model Evaluation & Metrics\n",
    "\n",
    "---\n",
    "\n",
    "**ChÃºc má»«ng báº¡n Ä‘Ã£ hoÃ n thÃ nh FILE 3-A! ğŸ‰**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
