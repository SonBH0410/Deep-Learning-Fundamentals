{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“— FILE 2-C â€“ CNN & Callbacks\n",
    "\n",
    "## ğŸ¯ Má»¥c tiÃªu\n",
    "\n",
    "Sau bÃ i nÃ y báº¡n sáº½ hiá»ƒu:\n",
    "- **CNN** (Convolutional Neural Networks) lÃ  gÃ¬\n",
    "- **Conv2D & Pooling** layers\n",
    "- Build CNN cho **Image Classification**\n",
    "- **Callbacks** - EarlyStopping, ModelCheckpoint\n",
    "- Best practices cho Computer Vision\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Œ Táº¡i sao CNN?\n",
    "\n",
    "**Váº¥n Ä‘á» vá»›i Dense layers cho images:**\n",
    "```\n",
    "Image 28Ã—28 = 784 pixels\n",
    "Dense(128) â†’ 784 Ã— 128 = 100,352 parameters!\n",
    "```\n",
    "- âŒ QuÃ¡ nhiá»u parameters\n",
    "- âŒ KhÃ´ng táº­n dá»¥ng spatial structure\n",
    "- âŒ KhÃ´ng translation invariant\n",
    "\n",
    "**CNN giáº£i quyáº¿t:**\n",
    "- âœ… Parameter sharing\n",
    "- âœ… Local connectivity\n",
    "- âœ… Translation invariance\n",
    "- âœ… Hierarchical features\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1ï¸âƒ£ Convolution - CÆ¡ cháº¿ cá»‘t lÃµi\n",
    "\n",
    "### ğŸ”¹ Convolution lÃ  gÃ¬?\n",
    "\n",
    "**Idea:** Slide a **filter** (kernel) over image to detect patterns\n",
    "\n",
    "```\n",
    "Image:           Filter:        Output:\n",
    "[1 2 3]          [1 0]          [1Ã—1+2Ã—0+4Ã—1+5Ã—0] = 5\n",
    "[4 5 6]    *     [1 0]    =     [2Ã—1+3Ã—0+5Ã—1+6Ã—0] = 7\n",
    "[7 8 9]                         ...\n",
    "```\n",
    "\n",
    "**Key concepts:**\n",
    "- **Filter/Kernel**: Small matrix (e.g., 3Ã—3)\n",
    "- **Stride**: Step size\n",
    "- **Padding**: Add borders to maintain size\n",
    "- **Feature map**: Output of convolution\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize convolution\n",
    "# Create simple image\n",
    "image = np.array([\n",
    "    [0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 0, 0, 0, 0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Filters\n",
    "filter_vertical = np.array([\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0, 1]\n",
    "], dtype=np.float32)\n",
    "\n",
    "filter_horizontal = np.array([\n",
    "    [-1, -1, -1],\n",
    "    [ 0,  0,  0],\n",
    "    [ 1,  1,  1]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Reshape for TensorFlow (batch, height, width, channels)\n",
    "image_tf = image.reshape(1, 5, 5, 1)\n",
    "filter_v_tf = filter_vertical.reshape(3, 3, 1, 1)\n",
    "filter_h_tf = filter_horizontal.reshape(3, 3, 1, 1)\n",
    "\n",
    "# Apply convolution\n",
    "output_v = tf.nn.conv2d(image_tf, filter_v_tf, strides=1, padding='VALID')\n",
    "output_h = tf.nn.conv2d(image_tf, filter_h_tf, strides=1, padding='VALID')\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].imshow(image, cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(output_v[0, :, :, 0], cmap='gray')\n",
    "axes[1].set_title('Vertical Edge Detection')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(output_h[0, :, :, 0], cmap='gray')\n",
    "axes[2].set_title('Horizontal Edge Detection')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Convolution detected edges in the image!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2ï¸âƒ£ Conv2D Layer\n",
    "\n",
    "### ğŸ”¹ Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Conv2D\n",
    "conv_layer = tf.keras.layers.Conv2D(\n",
    "    filters=32,              # Sá»‘ filters (output channels)\n",
    "    kernel_size=(3, 3),      # KÃ­ch thÆ°á»›c filter\n",
    "    strides=(1, 1),          # Stride (default: 1)\n",
    "    padding='same',          # 'same' or 'valid'\n",
    "    activation='relu',       # Activation function\n",
    "    input_shape=(28, 28, 1)  # (height, width, channels)\n",
    ")\n",
    "\n",
    "print(conv_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”¹ Padding: 'same' vs 'valid'\n",
    "\n",
    "**'valid' (no padding):**\n",
    "```\n",
    "Input:  (28, 28)\n",
    "Filter: (3, 3)\n",
    "Output: (26, 26)  # Shrinks!\n",
    "```\n",
    "\n",
    "**'same' (with padding):**\n",
    "```\n",
    "Input:  (28, 28)\n",
    "Filter: (3, 3)\n",
    "Output: (28, 28)  # Same size!\n",
    "```\n",
    "\n",
    "**Best practice:** DÃ¹ng `'same'` Ä‘á»ƒ maintain spatial dimensions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo padding effect\n",
    "input_tensor = tf.random.normal([1, 28, 28, 1])\n",
    "\n",
    "# Valid padding\n",
    "conv_valid = tf.keras.layers.Conv2D(32, (3, 3), padding='valid')\n",
    "output_valid = conv_valid(input_tensor)\n",
    "\n",
    "# Same padding\n",
    "conv_same = tf.keras.layers.Conv2D(32, (3, 3), padding='same')\n",
    "output_same = conv_same(input_tensor)\n",
    "\n",
    "print(f\"Input shape:  {input_tensor.shape}\")\n",
    "print(f\"Valid output: {output_valid.shape}\")\n",
    "print(f\"Same output:  {output_same.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3ï¸âƒ£ Pooling Layers\n",
    "\n",
    "### ğŸ”¹ Táº¡i sao cáº§n Pooling?\n",
    "\n",
    "**Goals:**\n",
    "- Reduce spatial dimensions â†’ fewer parameters\n",
    "- Add translation invariance\n",
    "- Prevent overfitting\n",
    "\n",
    "### ğŸ”¹ MaxPooling vs AveragePooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "feature_map = np.array([\n",
    "    [1, 3, 2, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [3, 2, 1, 0],\n",
    "    [1, 2, 3, 4]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Reshape for TensorFlow\n",
    "feature_map_tf = feature_map.reshape(1, 4, 4, 1)\n",
    "\n",
    "# MaxPooling (2Ã—2)\n",
    "maxpool = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "output_max = maxpool(feature_map_tf)\n",
    "\n",
    "# AveragePooling (2Ã—2)\n",
    "avgpool = tf.keras.layers.AveragePooling2D(pool_size=(2, 2))\n",
    "output_avg = avgpool(feature_map_tf)\n",
    "\n",
    "print(\"Original:\")\n",
    "print(feature_map)\n",
    "print(\"\\nMaxPooling (2Ã—2):\")\n",
    "print(output_max[0, :, :, 0].numpy())\n",
    "print(\"\\nAveragePooling (2Ã—2):\")\n",
    "print(output_avg[0, :, :, 0].numpy())\n",
    "\n",
    "print(\"\\nMaxPooling: Picks maximum value â†’ retains strong features\")\n",
    "print(\"AveragePooling: Takes average â†’ smoother\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”¹ Khi nÃ o dÃ¹ng?\n",
    "\n",
    "- **MaxPooling**: Default choice, tá»‘t cho edge/texture detection\n",
    "- **AveragePooling**: Smoother, Ã­t dÃ¹ng trong hidden layers\n",
    "- **GlobalAveragePooling**: Thay tháº¿ Flatten á»Ÿ cuá»‘i network\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4ï¸âƒ£ CNN Architecture - Typical Pattern\n",
    "\n",
    "### ğŸ”¹ Standard CNN pattern\n",
    "\n",
    "```\n",
    "Input Image\n",
    "    â†“\n",
    "[Conv2D â†’ ReLU â†’ MaxPool] Ã— N  # Feature extraction\n",
    "    â†“\n",
    "Flatten\n",
    "    â†“\n",
    "[Dense â†’ ReLU â†’ Dropout] Ã— M   # Classification\n",
    "    â†“\n",
    "Output (Softmax)\n",
    "```\n",
    "\n",
    "**Key principles:**\n",
    "- Filters increase: 32 â†’ 64 â†’ 128\n",
    "- Spatial size decreases: 28Ã—28 â†’ 14Ã—14 â†’ 7Ã—7\n",
    "- Add Dropout before Dense layers\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5ï¸âƒ£ Build CNN for MNIST\n",
    "\n",
    "### ğŸ”¹ Load & prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "# Visualize samples\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(X_train[i], cmap='gray')\n",
    "    ax.set_title(f'Label: {y_train[i]}')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "# 1. Reshape to add channel dimension\n",
    "X_train = X_train.reshape(-1, 28, 28, 1).astype(np.float32)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1).astype(np.float32)\n",
    "\n",
    "# 2. Normalize to [0, 1]\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# 3. Labels (already 0-9, no need to one-hot for sparse_categorical_crossentropy)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"Value range: [{X_train.min():.2f}, {X_train.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”¹ Build CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN\n",
    "model_cnn = tf.keras.Sequential([\n",
    "    # Block 1\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Block 2\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Block 3\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    \n",
    "    # Classifier\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "], name='simple_cnn')\n",
    "\n",
    "print(model_cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "model_cnn.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model compiled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6ï¸âƒ£ Callbacks - Smart Training Control\n",
    "\n",
    "### ğŸ”¹ Callbacks lÃ  gÃ¬?\n",
    "\n",
    "**Callbacks** = Functions Ä‘Æ°á»£c gá»i táº¡i cÃ¡c Ä‘iá»ƒm trong training\n",
    "\n",
    "**Use cases:**\n",
    "- Stop training early (EarlyStopping)\n",
    "- Save best model (ModelCheckpoint)\n",
    "- Adjust learning rate (ReduceLROnPlateau)\n",
    "- Log to TensorBoard\n",
    "- Custom logic\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”¹ 1. EarlyStopping\n",
    "\n",
    "**Problem:** KhÃ´ng biáº¿t train bao nhiÃªu epochs\n",
    "\n",
    "**Solution:** Stop khi val_loss khÃ´ng improve\n",
    "\n",
    "**Parameters:**\n",
    "- `monitor`: Metric to monitor (e.g., 'val_loss')\n",
    "- `patience`: Sá»‘ epochs chá» trÆ°á»›c khi stop\n",
    "- `restore_best_weights`: Restore weights tá»« best epoch\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',         # Theo dÃµi validation loss\n",
    "    patience=5,                 # Chá» 5 epochs\n",
    "    restore_best_weights=True,  # Restore best model\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"EarlyStopping configured:\")\n",
    "print(f\"  - Monitor: val_loss\")\n",
    "print(f\"  - Patience: 5 epochs\")\n",
    "print(f\"  - Will restore best weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”¹ 2. ModelCheckpoint\n",
    "\n",
    "**Problem:** Muá»‘n save best model during training\n",
    "\n",
    "**Solution:** Auto save khi val_loss improve\n",
    "\n",
    "**Parameters:**\n",
    "- `filepath`: NÆ¡i save model\n",
    "- `monitor`: Metric to monitor\n",
    "- `save_best_only`: Chá»‰ save khi improve\n",
    "- `save_weights_only`: Save weights only (faster)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint callback\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='/tmp/best_model.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"ModelCheckpoint configured:\")\n",
    "print(f\"  - Filepath: /tmp/best_model.keras\")\n",
    "print(f\"  - Monitor: val_accuracy\")\n",
    "print(f\"  - Save best only: True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”¹ 3. ReduceLROnPlateau\n",
    "\n",
    "**Problem:** Learning rate khÃ´ng tá»‘i Æ°u\n",
    "\n",
    "**Solution:** Giáº£m LR khi val_loss plateau\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReduceLROnPlateau callback\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,          # LR má»›i = LR cÅ© Ã— 0.5\n",
    "    patience=3,          # Chá» 3 epochs\n",
    "    min_lr=1e-7,         # Minimum LR\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"ReduceLROnPlateau configured:\")\n",
    "print(f\"  - Factor: 0.5 (halve LR)\")\n",
    "print(f\"  - Patience: 3 epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”¹ Train with Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine callbacks\n",
    "callbacks = [\n",
    "    early_stopping,\n",
    "    checkpoint,\n",
    "    reduce_lr\n",
    "]\n",
    "\n",
    "# Train\n",
    "print(\"Training with callbacks...\")\n",
    "history = model_cnn.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,                    # Set high, EarlyStopping will stop\n",
    "    batch_size=128,\n",
    "    validation_split=0.1,\n",
    "    callbacks=callbacks,          # Add callbacks!\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training & Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history.history['accuracy'], label='Train Acc', linewidth=2)\n",
    "axes[1].plot(history.history['val_accuracy'], label='Val Acc', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Training & Validation Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Training stopped at epoch: {len(history.history['loss'])}\")\n",
    "print(f\"Best val_accuracy: {max(history.history['val_accuracy']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = model_cnn.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model = tf.keras.models.load_model('/tmp/best_model.keras')\n",
    "best_test_loss, best_test_acc = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"Best Model Test Accuracy: {best_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7ï¸âƒ£ Visualize CNN Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model_cnn.predict(X_test[:20])\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(4, 5, figsize=(15, 12))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(X_test[i].reshape(28, 28), cmap='gray')\n",
    "    \n",
    "    # Color: green if correct, red if wrong\n",
    "    color = 'green' if predicted_classes[i] == y_test[i] else 'red'\n",
    "    ax.set_title(f'True: {y_test[i]}, Pred: {predicted_classes[i]}', color=color)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "correct = np.sum(predicted_classes == y_test[:20])\n",
    "print(f\"Correct predictions: {correct}/20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8ï¸âƒ£ Data Augmentation\n",
    "\n",
    "### ğŸ”¹ Táº¡i sao cáº§n augmentation?\n",
    "\n",
    "**Problem:** Limited training data â†’ overfitting\n",
    "\n",
    "**Solution:** Táº¡o variations cá»§a training images\n",
    "\n",
    "**Techniques:**\n",
    "- Rotation\n",
    "- Flip\n",
    "- Zoom\n",
    "- Shift\n",
    "- Brightness\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation layer (TF 2.x style)\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomRotation(0.1),       # Â±10% rotation\n",
    "    tf.keras.layers.RandomZoom(0.1),           # Â±10% zoom\n",
    "    tf.keras.layers.RandomTranslation(0.1, 0.1)  # Â±10% shift\n",
    "])\n",
    "\n",
    "# Visualize augmentation\n",
    "sample_image = X_train[0:1]  # Take first image\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    augmented = data_augmentation(sample_image, training=True)\n",
    "    ax.imshow(augmented[0, :, :, 0], cmap='gray')\n",
    "    ax.set_title(f'Augmented {i+1}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN with data augmentation\n",
    "model_with_aug = tf.keras.Sequential([\n",
    "    # Data augmentation (only during training)\n",
    "    data_augmentation,\n",
    "    \n",
    "    # CNN layers\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    \n",
    "    # Classifier\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_with_aug.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model with augmentation ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9ï¸âƒ£ Best Practices Summary\n",
    "\n",
    "### âœ… CNN Architecture\n",
    "\n",
    "```python\n",
    "# Standard pattern\n",
    "model = Sequential([\n",
    "    # Feature extraction\n",
    "    Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    \n",
    "    Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    \n",
    "    # More layers...\n",
    "    \n",
    "    # Classification head\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "```\n",
    "\n",
    "### âœ… Training Setup\n",
    "\n",
    "```python\n",
    "# Always use callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model.keras', save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "]\n",
    "\n",
    "# Train\n",
    "model.fit(X_train, y_train, \n",
    "          validation_split=0.1,\n",
    "          callbacks=callbacks,\n",
    "          epochs=100)  # Set high, callbacks will handle it\n",
    "```\n",
    "\n",
    "### âœ… Data Preparation\n",
    "\n",
    "1. Normalize: `X / 255.0`\n",
    "2. Reshape: Add channel dimension\n",
    "3. Augmentation: For small datasets\n",
    "4. Validation split: 10-20%\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”Ÿ Exercises\n",
    "\n",
    "### ğŸ“ Exercise 1: Deeper CNN\n",
    "\n",
    "Build deeper CNN:\n",
    "- 4 conv blocks instead of 3\n",
    "- Filters: 32 â†’ 64 â†’ 128 â†’ 128\n",
    "- Compare with simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# TODO: Build deeper CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ Exercise 2: Custom Callback\n",
    "\n",
    "Implement custom callback:\n",
    "- Print learning rate at end of each epoch\n",
    "- Save model every 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    # TODO: Implement\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ Exercise 3: Fashion MNIST\n",
    "\n",
    "Apply CNN to Fashion MNIST:\n",
    "- Load fashion_mnist dataset\n",
    "- Build CNN (similar to MNIST)\n",
    "- Use callbacks\n",
    "- Achieve >90% test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# TODO: Complete Fashion MNIST classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ TÃ³m táº¯t\n",
    "\n",
    "### âœ… ÄÃ£ há»c\n",
    "\n",
    "1. **CNN Basics**: Convolution, Pooling\n",
    "2. **Conv2D & MaxPooling2D** layers\n",
    "3. **CNN Architecture** patterns\n",
    "4. **Image Classification** with MNIST\n",
    "5. **Callbacks**: EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "6. **Data Augmentation**\n",
    "\n",
    "### ğŸ“ Key Takeaways\n",
    "\n",
    "**CNN Pattern:**\n",
    "```\n",
    "Input â†’ [Convâ†’ReLUâ†’Pool]Ã—N â†’ Flatten â†’ [Denseâ†’Dropout]Ã—M â†’ Output\n",
    "```\n",
    "\n",
    "**Always use:**\n",
    "- EarlyStopping (avoid overfitting)\n",
    "- ModelCheckpoint (save best model)\n",
    "- Data augmentation (if dataset small)\n",
    "\n",
    "### ğŸ“š What's Next?\n",
    "\n",
    "**PHáº¦N 3 - ADVANCED** (náº¿u cÃ³):\n",
    "- Transfer Learning\n",
    "- Advanced CNN architectures\n",
    "- Multi-GPU training\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ‰ HoÃ n thÃ nh PHáº¦N 2!\n",
    "\n",
    "Báº¡n Ä‘Ã£ náº¯m Ä‘Æ°á»£c:\n",
    "- âœ… Data pipeline (tf.data)\n",
    "- âœ… Optimizers & Regularization\n",
    "- âœ… CNN & Callbacks\n",
    "\n",
    "**Ready for production!** ğŸš€\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“– References\n",
    "\n",
    "- [Keras CNN Guide](https://www.tensorflow.org/tutorials/images/cnn)\n",
    "- [Keras Callbacks](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks)\n",
    "- [Data Augmentation](https://www.tensorflow.org/tutorials/images/data_augmentation)\n",
    "\n",
    "---\n",
    "\n",
    "**ChÃºc báº¡n há»c tá»‘t! ğŸš€**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
