{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìò FILE 1-D ‚Äì GPU, Debugging & Exercises\n",
    "\n",
    "## üéØ M·ª•c ti√™u\n",
    "\n",
    "Sau b√†i n√†y b·∫°n s·∫Ω hi·ªÉu:\n",
    "- **CPU vs GPU** - Khi n√†o d√πng g√¨\n",
    "- C√°ch ki·ªÉm tra v√† s·ª≠ d·ª•ng GPU\n",
    "- **Device placement** - Ch·ªâ ƒë·ªãnh device cho operations\n",
    "- **Common errors** - L·ªói newbie th∆∞·ªùng g·∫∑p\n",
    "- **Debugging tips** - K·ªπ thu·∫≠t debug hi·ªáu qu·∫£\n",
    "- **Best practices** - Quy t·∫Øc vi·∫øt code t·ªët\n",
    "\n",
    "---\n",
    "\n",
    "## üìå T·∫°i sao ph·∫£i h·ªçc v·ªÅ GPU?\n",
    "\n",
    "- Deep Learning c·∫ßn **t√≠nh to√°n kh·ªïng l·ªì**\n",
    "- GPU nhanh h∆°n CPU **10-100x** cho matrix operations\n",
    "- Production models **b·∫Øt bu·ªôc** d√πng GPU\n",
    "- Bi·∫øt GPU ‚Üí ti·∫øt ki·ªám th·ªùi gian training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ CPU vs GPU\n",
    "\n",
    "### üîπ CPU (Central Processing Unit)\n",
    "\n",
    "**ƒê·∫∑c ƒëi·ªÉm:**\n",
    "- 4-16 cores m·∫°nh\n",
    "- T·ªëc ƒë·ªô clock cao (3-5 GHz)\n",
    "- T·ªëi ∆∞u cho **sequential tasks**\n",
    "\n",
    "**Khi n√†o d√πng:**\n",
    "- Small models (< 1M parameters)\n",
    "- Data preprocessing\n",
    "- Inference v·ªõi batch size nh·ªè\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ GPU (Graphics Processing Unit)\n",
    "\n",
    "**ƒê·∫∑c ƒëi·ªÉm:**\n",
    "- 1000+ cores nh·ªè\n",
    "- T·ªëc ƒë·ªô clock th·∫•p h∆°n (~1-2 GHz)\n",
    "- T·ªëi ∆∞u cho **parallel tasks**\n",
    "\n",
    "**Khi n√†o d√πng:**\n",
    "- Large models (> 10M parameters)\n",
    "- Matrix operations (convolution, matmul)\n",
    "- Training v·ªõi batch size l·ªõn\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ So s√°nh tr·ª±c quan\n",
    "\n",
    "```\n",
    "CPU: [====================] 1 task\n",
    "\n",
    "GPU: [=][=][=][=][=][=][=][=][=][=]\n",
    "     [=][=][=][=][=][=][=][=][=][=]  1000+ tasks parallel\n",
    "     [=][=][=][=][=][=][=][=][=][=]\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Ki·ªÉm tra GPU\n",
    "\n",
    "### üîπ C√°c c√°ch ki·ªÉm tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√°ch 1: List t·∫•t c·∫£ physical devices\n",
    "print(\"=\" * 60)\n",
    "print(\"ALL PHYSICAL DEVICES\")\n",
    "print(\"=\" * 60)\n",
    "devices = tf.config.list_physical_devices()\n",
    "for device in devices:\n",
    "    print(f\"  {device.device_type:5s}: {device.name}\")\n",
    "\n",
    "# C√°ch 2: Ch·ªâ GPU\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"GPU DEVICES\")\n",
    "print(\"=\" * 60)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        print(f\"  GPU {i}: {gpu.name}\")\n",
    "else:\n",
    "    print(\"  No GPU found\")\n",
    "\n",
    "# C√°ch 3: Built-in test\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TF BUILT-IN TEST\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  GPU available: {tf.test.is_built_with_cuda()}\")\n",
    "print(f\"  GPU device: {tf.test.gpu_device_name()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ki·ªÉm tra chi ti·∫øt GPU (n·∫øu c√≥)\n",
    "if gpus:\n",
    "    gpu_details = tf.config.experimental.get_device_details(gpus[0])\n",
    "    print(\"GPU Details:\")\n",
    "    for key, value in gpu_details.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"No GPU available - running on CPU\")\n",
    "    print(\"Don't worry! Code v·∫´n ch·∫°y b√¨nh th∆∞·ªùng, ch·ªâ ch·∫≠m h∆°n.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ GPU Memory Management\n",
    "\n",
    "### üîπ V·∫•n ƒë·ªÅ: GPU memory kh√¥ng ƒë·ªß\n",
    "\n",
    "**M·∫∑c ƒë·ªãnh:** TensorFlow chi·∫øm **to√†n b·ªô** GPU memory\n",
    "\n",
    "**V·∫•n ƒë·ªÅ:**\n",
    "- Kh√¥ng ch·∫°y ƒë∆∞·ª£c nhi·ªÅu process\n",
    "- Out of Memory (OOM) errors\n",
    "\n",
    "### üîπ Gi·∫£i ph√°p: Memory Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable memory growth\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth enabled\")\n",
    "        print(\"TensorFlow s·∫Ω ch·ªâ d√πng memory khi c·∫ßn\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "else:\n",
    "    print(\"No GPU available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gi·ªõi h·∫°n memory c·ª• th·ªÉ (v√≠ d·ª•: 2GB)\n",
    "if gpus:\n",
    "    try:\n",
    "        # Uncomment ƒë·ªÉ test\n",
    "        # tf.config.set_logical_device_configuration(\n",
    "        #     gpus[0],\n",
    "        #     [tf.config.LogicalDeviceConfiguration(memory_limit=2048)]  # MB\n",
    "        # )\n",
    "        print(\"Memory limit: 2GB (n·∫øu uncomment)\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "else:\n",
    "    print(\"No GPU available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Device Placement\n",
    "\n",
    "### üîπ T·ª± ƒë·ªông vs Th·ªß c√¥ng\n",
    "\n",
    "**M·∫∑c ƒë·ªãnh:** TensorFlow t·ª± ch·ªçn device\n",
    "- GPU n·∫øu c√≥\n",
    "- CPU n·∫øu kh√¥ng\n",
    "\n",
    "**Th·ªß c√¥ng:** D√πng `tf.device()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ki·ªÉm tra device m·∫∑c ƒë·ªãnh\n",
    "x = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "print(f\"Default device: {x.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force CPU\n",
    "with tf.device('/CPU:0'):\n",
    "    x_cpu = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "    y_cpu = tf.matmul(x_cpu, x_cpu)\n",
    "\n",
    "print(f\"x_cpu device: {x_cpu.device}\")\n",
    "print(f\"y_cpu device: {y_cpu.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force GPU (n·∫øu c√≥)\n",
    "if gpus:\n",
    "    with tf.device('/GPU:0'):\n",
    "        x_gpu = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "        y_gpu = tf.matmul(x_gpu, x_gpu)\n",
    "    \n",
    "    print(f\"x_gpu device: {x_gpu.device}\")\n",
    "    print(f\"y_gpu device: {y_gpu.device}\")\n",
    "else:\n",
    "    print(\"No GPU available - skipping GPU test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîπ Benchmark: CPU vs GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function ƒë·ªÉ benchmark\n",
    "def benchmark_matmul(device_name, matrix_size, num_iterations=100):\n",
    "    \"\"\"Benchmark matrix multiplication\"\"\"\n",
    "    with tf.device(device_name):\n",
    "        # Create random matrices\n",
    "        a = tf.random.normal([matrix_size, matrix_size])\n",
    "        b = tf.random.normal([matrix_size, matrix_size])\n",
    "        \n",
    "        # Warm up\n",
    "        _ = tf.matmul(a, b)\n",
    "        \n",
    "        # Benchmark\n",
    "        start = time.time()\n",
    "        for _ in range(num_iterations):\n",
    "            c = tf.matmul(a, b)\n",
    "        end = time.time()\n",
    "        \n",
    "    avg_time = (end - start) / num_iterations * 1000  # ms\n",
    "    return avg_time\n",
    "\n",
    "# Test v·ªõi nhi·ªÅu sizes\n",
    "sizes = [100, 500, 1000, 2000]\n",
    "cpu_times = []\n",
    "gpu_times = []\n",
    "\n",
    "print(\"Benchmarking CPU...\")\n",
    "for size in sizes:\n",
    "    cpu_time = benchmark_matmul('/CPU:0', size, num_iterations=10)\n",
    "    cpu_times.append(cpu_time)\n",
    "    print(f\"  Size {size:4d}: {cpu_time:6.2f} ms\")\n",
    "\n",
    "if gpus:\n",
    "    print(\"\\nBenchmarking GPU...\")\n",
    "    for size in sizes:\n",
    "        gpu_time = benchmark_matmul('/GPU:0', size, num_iterations=10)\n",
    "        gpu_times.append(gpu_time)\n",
    "        print(f\"  Size {size:4d}: {gpu_time:6.2f} ms\")\n",
    "else:\n",
    "    print(\"\\nNo GPU available - skipping GPU benchmark\")\n",
    "    gpu_times = [0] * len(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "if gpus and any(gpu_times):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    x = np.arange(len(sizes))\n",
    "    width = 0.35\n",
    "    plt.bar(x - width/2, cpu_times, width, label='CPU', alpha=0.8)\n",
    "    plt.bar(x + width/2, gpu_times, width, label='GPU', alpha=0.8)\n",
    "    plt.xlabel('Matrix Size')\n",
    "    plt.ylabel('Time (ms)')\n",
    "    plt.title('CPU vs GPU Performance')\n",
    "    plt.xticks(x, sizes)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    speedup = [cpu / gpu if gpu > 0 else 0 for cpu, gpu in zip(cpu_times, gpu_times)]\n",
    "    plt.plot(sizes, speedup, 'go-', linewidth=2, markersize=8)\n",
    "    plt.xlabel('Matrix Size')\n",
    "    plt.ylabel('Speedup (CPU time / GPU time)')\n",
    "    plt.title('GPU Speedup')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.axhline(y=1, color='r', linestyle='--', alpha=0.5, label='No speedup')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nSpeedup:\")\n",
    "    for size, speed in zip(sizes, speedup):\n",
    "        print(f\"  Size {size:4d}: {speed:.2f}x faster\")\n",
    "else:\n",
    "    print(\"No GPU available - skipping visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Common Errors & Solutions\n",
    "\n",
    "### ‚ùå Error 1: Shape Mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAI\n",
    "try:\n",
    "    a = tf.constant([[1, 2, 3]])\n",
    "    b = tf.constant([[1], [2]])\n",
    "    c = tf.matmul(a, b)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(f\"\\nNguy√™n nh√¢n: a.shape={a.shape}, b.shape={b.shape}\")\n",
    "    print(f\"Matmul y√™u c·∫ßu: (m, n) @ (n, p) = (m, p)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒê√öNG\n",
    "a = tf.constant([[1, 2, 3]])\n",
    "b = tf.constant([[1], [2], [3]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(f\"a.shape: {a.shape}\")\n",
    "print(f\"b.shape: {b.shape}\")\n",
    "print(f\"c.shape: {c.shape}\")\n",
    "print(f\"Result: {c.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùå Error 2: Dtype Mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAI\n",
    "try:\n",
    "    a = tf.constant([1, 2, 3], dtype=tf.int32)\n",
    "    b = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)\n",
    "    c = a + b\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(f\"\\nNguy√™n nh√¢n: a.dtype={a.dtype}, b.dtype={b.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒê√öNG - C√°ch 1: Cast\n",
    "a = tf.constant([1, 2, 3], dtype=tf.int32)\n",
    "b = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)\n",
    "c = tf.cast(a, tf.float32) + b\n",
    "print(f\"Result: {c.numpy()}\")\n",
    "\n",
    "# ƒê√öNG - C√°ch 2: D√πng c√πng dtype t·ª´ ƒë·∫ßu\n",
    "a = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)\n",
    "b = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)\n",
    "c = a + b\n",
    "print(f\"Result: {c.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùå Error 3: Gradient is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAI\n",
    "x = tf.constant(2.0)  # Tensor th∆∞·ªùng\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    # QU√äN tape.watch(x)\n",
    "    y = x ** 2\n",
    "\n",
    "grad = tape.gradient(y, x)\n",
    "print(f\"Gradient: {grad}\")  # None!\n",
    "print(\"\\nNguy√™n nh√¢n: Qu√™n watch tensor th∆∞·ªùng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒê√öNG - C√°ch 1: Watch\n",
    "x = tf.constant(2.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = x ** 2\n",
    "\n",
    "grad = tape.gradient(y, x)\n",
    "print(f\"Gradient: {grad.numpy()}\")\n",
    "\n",
    "# ƒê√öNG - C√°ch 2: D√πng Variable\n",
    "x = tf.Variable(2.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x ** 2\n",
    "\n",
    "grad = tape.gradient(y, x)\n",
    "print(f\"Gradient: {grad.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùå Error 4: OOM (Out of Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√ç D·ª§ g√¢y OOM (KH√îNG RUN n·∫øu GPU nh·ªè!)\n",
    "print(\"V√≠ d·ª• code g√¢y OOM:\")\n",
    "print(\"\"\"\n",
    "# SAI - Batch size qu√° l·ªõn\n",
    "model.fit(X, y, batch_size=10000, epochs=100)\n",
    "\n",
    "# ƒê√öNG - Gi·∫£m batch size\n",
    "model.fit(X, y, batch_size=32, epochs=100)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nC√°ch kh·∫Øc ph·ª•c OOM:\")\n",
    "print(\"1. Gi·∫£m batch_size\")\n",
    "print(\"2. Gi·∫£m k√≠ch th∆∞·ªõc model\")\n",
    "print(\"3. Enable memory growth (ƒë√£ l√†m ·ªü tr√™n)\")\n",
    "print(\"4. D√πng mixed precision training (s·∫Ω h·ªçc sau)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùå Error 5: Model not compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAI\n",
    "try:\n",
    "    model = tf.keras.Sequential([tf.keras.layers.Dense(1)])\n",
    "    # QU√äN compile\n",
    "    X = np.random.randn(10, 5).astype(np.float32)\n",
    "    y = np.random.randn(10, 1).astype(np.float32)\n",
    "    model.fit(X, y, epochs=1, verbose=0)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"\\nNguy√™n nh√¢n: Qu√™n compile model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒê√öNG\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(1)])\n",
    "model.compile(optimizer='adam', loss='mse')  # B·∫ÆT BU·ªòC!\n",
    "\n",
    "X = np.random.randn(10, 5).astype(np.float32)\n",
    "y = np.random.randn(10, 1).astype(np.float32)\n",
    "model.fit(X, y, epochs=1, verbose=0)\n",
    "\n",
    "print(\"Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ Debugging Tips\n",
    "\n",
    "### üîπ Tip 1: Print shapes th∆∞·ªùng xuy√™n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST PRACTICE\n",
    "def debug_shapes(model, sample_input):\n",
    "    \"\"\"Print output shape c·ªßa m·ªói layer\"\"\"\n",
    "    print(\"Layer Shapes:\")\n",
    "    print(\"=\" * 60)\n",
    "    x = sample_input\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        x = layer(x)\n",
    "        print(f\"  Layer {i} ({layer.name:15s}): {x.shape}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Test\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(10,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "sample = tf.random.normal([5, 10])  # batch_size=5\n",
    "debug_shapes(model, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîπ Tip 2: Check for NaN/Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nan_inf(tensor, name=\"tensor\"):\n",
    "    \"\"\"Ki·ªÉm tra NaN v√† Inf\"\"\"\n",
    "    has_nan = tf.reduce_any(tf.math.is_nan(tensor))\n",
    "    has_inf = tf.reduce_any(tf.math.is_inf(tensor))\n",
    "    \n",
    "    if has_nan:\n",
    "        print(f\"‚ö†Ô∏è  WARNING: {name} contains NaN!\")\n",
    "    if has_inf:\n",
    "        print(f\"‚ö†Ô∏è  WARNING: {name} contains Inf!\")\n",
    "    if not has_nan and not has_inf:\n",
    "        print(f\"‚úì {name} is clean (no NaN/Inf)\")\n",
    "\n",
    "# Test\n",
    "good_tensor = tf.constant([1.0, 2.0, 3.0])\n",
    "bad_tensor = tf.constant([1.0, float('nan'), 3.0])\n",
    "inf_tensor = tf.constant([1.0, float('inf'), 3.0])\n",
    "\n",
    "check_nan_inf(good_tensor, \"good_tensor\")\n",
    "check_nan_inf(bad_tensor, \"bad_tensor\")\n",
    "check_nan_inf(inf_tensor, \"inf_tensor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîπ Tip 3: Visualize gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gradients(model, X, y):\n",
    "    \"\"\"Plot gradient magnitudes\"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(X)\n",
    "        loss = tf.keras.losses.mse(y, predictions)\n",
    "    \n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    \n",
    "    # Compute gradient norms\n",
    "    grad_norms = [tf.norm(g).numpy() for g in grads if g is not None]\n",
    "    layer_names = [v.name for v in model.trainable_variables]\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.bar(range(len(grad_norms)), grad_norms)\n",
    "    plt.xlabel('Layer')\n",
    "    plt.ylabel('Gradient Norm')\n",
    "    plt.title('Gradient Magnitudes per Layer')\n",
    "    plt.xticks(range(len(grad_norms)), [f\"L{i}\" for i in range(len(grad_norms))], rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Gradient norms:\")\n",
    "    for i, (name, norm) in enumerate(zip(layer_names, grad_norms)):\n",
    "        print(f\"  {name:30s}: {norm:.6f}\")\n",
    "\n",
    "# Test\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(10,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "X_sample = tf.random.normal([32, 10])\n",
    "y_sample = tf.random.normal([32, 1])\n",
    "\n",
    "plot_gradients(model, X_sample, y_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ Best Practices\n",
    "\n",
    "### ‚úÖ 1. Always normalize input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# BAD\n",
    "X_bad = np.random.randn(100, 10) * 1000  # Large scale\n",
    "\n",
    "# GOOD\n",
    "scaler = StandardScaler()\n",
    "X_good = scaler.fit_transform(X_bad)\n",
    "\n",
    "print(f\"Before normalization: mean={X_bad.mean():.2f}, std={X_bad.std():.2f}\")\n",
    "print(f\"After normalization:  mean={X_good.mean():.2f}, std={X_good.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ 2. Use appropriate activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "CHEAT SHEET:\n",
    "\n",
    "Task                        Hidden Layers    Output Layer\n",
    "================================================================\n",
    "Regression                  ReLU             None (linear)\n",
    "Binary Classification       ReLU             Sigmoid\n",
    "Multi-class Classification  ReLU             Softmax\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ 3. Monitor training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOD - D√πng validation split\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(10,)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "X = np.random.randn(1000, 10).astype(np.float32)\n",
    "y = np.random.randn(1000, 1).astype(np.float32)\n",
    "\n",
    "history = model.fit(\n",
    "    X, y,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,  # QUAN TR·ªåNG!\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Monitoring')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Ki·ªÉm tra:\")\n",
    "print(\"- Train loss gi·∫£m ‚Üí model ƒëang h·ªçc\")\n",
    "print(\"- Val loss gi·∫£m ‚Üí model generalize t·ªët\")\n",
    "print(\"- Val loss tƒÉng ‚Üí overfitting!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ 4. Use tf.function for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slow - Eager mode\n",
    "def slow_function(x):\n",
    "    for i in range(10):\n",
    "        x = x + 1\n",
    "    return x\n",
    "\n",
    "# Fast - Graph mode\n",
    "@tf.function\n",
    "def fast_function(x):\n",
    "    for i in range(10):\n",
    "        x = x + 1\n",
    "    return x\n",
    "\n",
    "# Benchmark\n",
    "x = tf.random.normal([1000, 1000])\n",
    "\n",
    "# Slow\n",
    "start = time.time()\n",
    "for _ in range(10):\n",
    "    _ = slow_function(x)\n",
    "slow_time = time.time() - start\n",
    "\n",
    "# Fast\n",
    "start = time.time()\n",
    "for _ in range(10):\n",
    "    _ = fast_function(x)\n",
    "fast_time = time.time() - start\n",
    "\n",
    "print(f\"Slow (eager): {slow_time:.4f}s\")\n",
    "print(f\"Fast (graph): {fast_time:.4f}s\")\n",
    "print(f\"Speedup: {slow_time/fast_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8Ô∏è‚É£ Final Exercises\n",
    "\n",
    "### üìù Exercise 1: Debug Broken Model\n",
    "\n",
    "Code d∆∞·ªõi ƒë√¢y c√≥ nhi·ªÅu l·ªói. T√¨m v√† s·ª≠a!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BROKEN CODE - FIX ME!\n",
    "\"\"\"\n",
    "# Data\n",
    "X = np.random.randn(100, 10)\n",
    "y = np.random.randn(100, 1)\n",
    "\n",
    "# Model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64),  # Bug 1: No activation\n",
    "    tf.keras.layers.Dense(32),  # Bug 2: No activation\n",
    "    tf.keras.layers.Dense(1, activation='relu')  # Bug 3: Wrong activation for regression\n",
    "])\n",
    "\n",
    "# Train (Bug 4: Not compiled!)\n",
    "model.fit(X, y, epochs=10)\n",
    "\"\"\"\n",
    "\n",
    "# YOUR FIXED CODE HERE\n",
    "# TODO: Fix all bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù Exercise 2: Gradient Debugging\n",
    "\n",
    "Write function ƒë·ªÉ:\n",
    "1. Check gradient is None\n",
    "2. Check gradient contains NaN/Inf\n",
    "3. Print gradient statistics (min, max, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def debug_gradient(model, X, y, loss_fn):\n",
    "    \"\"\"\n",
    "    Debug gradients c·ªßa model\n",
    "    \n",
    "    Args:\n",
    "        model: Keras model\n",
    "        X: Input data\n",
    "        y: Target data\n",
    "        loss_fn: Loss function\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    pass\n",
    "\n",
    "# Test your function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù Exercise 3: Build Complete Pipeline\n",
    "\n",
    "Build end-to-end pipeline:\n",
    "1. Load data (breast cancer)\n",
    "2. Normalize\n",
    "3. Split train/val/test\n",
    "4. Build model\n",
    "5. Train v·ªõi monitoring\n",
    "6. Evaluate\n",
    "7. Save model\n",
    "\n",
    "**Y√™u c·∫ßu:**\n",
    "- Accuracy > 95%\n",
    "- No overfitting\n",
    "- Clean code v·ªõi comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# TODO: Complete pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù Exercise 4: Custom Training Loop (BONUS)\n",
    "\n",
    "Implement custom training loop v·ªõi:\n",
    "- Progress bar\n",
    "- Learning rate scheduling\n",
    "- Early stopping\n",
    "- Gradient clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# TODO: Implement custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Foundation Summary\n",
    "\n",
    "### ‚úÖ ƒê√£ h·ªçc (Files 1A-1D)\n",
    "\n",
    "**File 1-A: TensorFlow & Tensor Basics**\n",
    "- Tensor operations\n",
    "- Shape, dtype, slicing\n",
    "- NumPy interop\n",
    "\n",
    "**File 1-B: Eager Execution & GradientTape**\n",
    "- Eager execution\n",
    "- Automatic differentiation\n",
    "- Manual training loop\n",
    "- Linear regression from scratch\n",
    "\n",
    "**File 1-C: tf.keras & First Neural Network**\n",
    "- Sequential API\n",
    "- Dense layers\n",
    "- Activation functions\n",
    "- model.compile/fit/evaluate/predict\n",
    "\n",
    "**File 1-D: GPU, Debugging & Exercises**\n",
    "- CPU vs GPU\n",
    "- Device placement\n",
    "- Common errors\n",
    "- Debugging tips\n",
    "- Best practices\n",
    "\n",
    "---\n",
    "\n",
    "### üéì Key Skills Acquired\n",
    "\n",
    "1. ‚úÖ Hi·ªÉu c∆° ch·∫ø TensorFlow\n",
    "2. ‚úÖ T√≠nh gradient th·ªß c√¥ng\n",
    "3. ‚úÖ Build & train neural networks\n",
    "4. ‚úÖ Debug & optimize code\n",
    "5. ‚úÖ GPU awareness\n",
    "\n",
    "### üìö Ready for Next Step\n",
    "\n",
    "**PH·∫¶N 2 - INTERMEDIATE** (Files 2A-2D):\n",
    "- tf.data pipeline\n",
    "- Advanced optimizers\n",
    "- Regularization\n",
    "- Callbacks & custom training\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ References\n",
    "\n",
    "- [TensorFlow GPU Guide](https://www.tensorflow.org/guide/gpu)\n",
    "- [TensorFlow Performance Guide](https://www.tensorflow.org/guide/profiler)\n",
    "- [Debugging TensorFlow](https://www.tensorflow.org/guide/debugging)\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Ch√∫c m·ª´ng!\n",
    "\n",
    "B·∫°n ƒë√£ ho√†n th√†nh **FOUNDATION (BEGINNER)**!\n",
    "\n",
    "**ƒêi·ªÅu quan tr·ªçng:**\n",
    "- Kh√¥ng ph·∫£i h·ªçc thu·ªôc, m√† l√† **hi·ªÉu b·∫£n ch·∫•t**\n",
    "- Practice, practice, practice!\n",
    "- Quay l·∫°i xem l·∫°i khi c·∫ßn\n",
    "\n",
    "**Next steps:**\n",
    "1. L√†m h·∫øt exercises\n",
    "2. Build 1-2 projects nh·ªè\n",
    "3. Chuy·ªÉn sang PH·∫¶N 2\n",
    "\n",
    "---\n",
    "\n",
    "**Ch√∫c b·∫°n h·ªçc t·ªët! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
