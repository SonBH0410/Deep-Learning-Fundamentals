{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìò PYTORCH PHASE 1 - FILE 1: OPTIMIZATION\n",
    "\n",
    "**Core Concepts:** Optimization Fundamentals & Practical Experiments\n",
    "\n",
    "**M·ª•c ti√™u:**\n",
    "- ‚úÖ Hi·ªÉu optimization landscape (convex vs non-convex)\n",
    "- ‚úÖ Master SGD family (Momentum, Nesterov)\n",
    "- ‚úÖ Understand adaptive optimizers (Adam, AdamW)\n",
    "- ‚úÖ Learning rate strategies (decay, warmup, cosine)\n",
    "- ‚úÖ Practical experiments & visualization\n",
    "\n",
    "**Th·ªùi l∆∞·ª£ng:** 2-3 tu·∫ßn\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö M·ª•c L·ª•c\n",
    "\n",
    "### 1. OPTIMIZATION FUNDAMENTALS\n",
    "1.1 Loss Landscape\n",
    "1.2 Convex vs Non-convex\n",
    "1.3 Saddle Points vs Local Minima\n",
    "1.4 Gradient Noise & Stochasticity\n",
    "1.5 Batch Size Effects\n",
    "\n",
    "### 2. SGD FAMILY\n",
    "2.1 Vanilla SGD\n",
    "2.2 SGD + Momentum\n",
    "2.3 Nesterov Momentum\n",
    "2.4 Exponential Moving Average\n",
    "2.5 Practical Comparison\n",
    "\n",
    "### 3. ADAPTIVE OPTIMIZERS\n",
    "3.1 Adagrad\n",
    "3.2 RMSProp\n",
    "3.3 Adam\n",
    "3.4 AdamW (Weight Decay)\n",
    "3.5 Adam vs SGD in Practice\n",
    "\n",
    "### 4. LEARNING RATE STRATEGIES\n",
    "4.1 Constant vs Decaying LR\n",
    "4.2 Step Decay\n",
    "4.3 Exponential Decay\n",
    "4.4 Cosine Annealing\n",
    "4.5 Warmup Strategies\n",
    "4.6 LR Range Test\n",
    "\n",
    "### 5. PRACTICAL EXPERIMENTS\n",
    "5.1 Optimizer Comparison\n",
    "5.2 Loss Curve Analysis\n",
    "5.3 LR Misconfiguration Effects\n",
    "5.4 Training Instability Visualization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import copy\n",
    "\n",
    "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"‚úÖ Using device: {device}\")\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. OPTIMIZATION FUNDAMENTALS\n",
    "\n",
    "## 1.1 Loss Landscape\n",
    "\n",
    "### ƒê·ªãnh nghƒ©a\n",
    "\n",
    "**Loss Landscape** = B·ªÅ m·∫∑t th·ªÉ hi·ªán loss function tr√™n kh√¥ng gian parameters\n",
    "\n",
    "### Convex vs Non-convex\n",
    "\n",
    "#### Convex (L·ªìi)\n",
    "- **ƒê·∫∑c ƒëi·ªÉm**: C√≥ duy nh·∫•t m·ªôt global minimum\n",
    "- **T√≠nh ch·∫•t**: B·∫•t k·ª≥ local minimum n√†o c≈©ng l√† global minimum\n",
    "- **V√≠ d·ª•**: Linear regression, Logistic regression\n",
    "- **Optimization**: D·ªÖ d√†ng, guaranteed converge\n",
    "\n",
    "#### Non-convex (Kh√¥ng l·ªìi)\n",
    "- **ƒê·∫∑c ƒëi·ªÉm**: Nhi·ªÅu local minima, saddle points\n",
    "- **T√≠nh ch·∫•t**: Ph·ª©c t·∫°p, nhi·ªÅu \"thung l≈©ng\"\n",
    "- **V√≠ d·ª•**: Deep neural networks\n",
    "- **Optimization**: Kh√≥ khƒÉn, kh√¥ng guarantee global minimum\n",
    "\n",
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Convex vs Non-convex Loss\n",
    "\n",
    "def plot_loss_landscape():\n",
    "    \"\"\"Plot 2D loss landscape comparison\"\"\"\n",
    "    x = np.linspace(-5, 5, 100)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Convex: Quadratic\n",
    "    y_convex = x**2\n",
    "    axes[0].plot(x, y_convex, linewidth=3, color='blue')\n",
    "    axes[0].scatter([0], [0], s=200, c='red', marker='*', zorder=5, label='Global Minimum')\n",
    "    axes[0].set_xlabel('Parameter', fontsize=12)\n",
    "    axes[0].set_ylabel('Loss', fontsize=12)\n",
    "    axes[0].set_title('Convex Loss Landscape', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend(fontsize=11)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Non-convex: Multiple minima\n",
    "    y_nonconvex = x**4 - 5*x**2 + 4\n",
    "    axes[1].plot(x, y_nonconvex, linewidth=3, color='green')\n",
    "    # Local minima\n",
    "    minima_x = [-1.58, 1.58]\n",
    "    minima_y = [x**4 - 5*x**2 + 4 for x in minima_x]\n",
    "    axes[1].scatter(minima_x, minima_y, s=200, c='red', marker='*', zorder=5, label='Local Minima')\n",
    "    # Saddle point\n",
    "    axes[1].scatter([0], [4], s=200, c='orange', marker='o', zorder=5, label='Saddle Point')\n",
    "    axes[1].set_xlabel('Parameter', fontsize=12)\n",
    "    axes[1].set_ylabel('Loss', fontsize=12)\n",
    "    axes[1].set_title('Non-convex Loss Landscape', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend(fontsize=11)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üìä Observations:\")\n",
    "    print(\"   Convex: One clear path to global minimum\")\n",
    "    print(\"   Non-convex: Multiple valleys, saddle points\")\n",
    "    print(\"   Deep learning = Non-convex optimization!\")\n",
    "\n",
    "plot_loss_landscape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Saddle Points vs Local Minima\n",
    "\n",
    "### Saddle Point (ƒêi·ªÉm y√™n ng·ª±a)\n",
    "- Gradient = 0\n",
    "- Minimum theo m·ªôt s·ªë directions, maximum theo directions kh√°c\n",
    "- Common trong high-dimensional spaces\n",
    "- **Problem**: SGD c√≥ th·ªÉ stuck ·ªü saddle points\n",
    "\n",
    "### Local Minimum (C·ª±c ti·ªÉu ƒë·ªãa ph∆∞∆°ng)\n",
    "- Gradient = 0\n",
    "- Minimum theo m·ªçi directions\n",
    "- **Problem**: Kh√¥ng ph·∫£i global minimum\n",
    "\n",
    "### Key Insight\n",
    "- Trong deep learning, **saddle points** ph·ªï bi·∫øn h∆°n local minima\n",
    "- SGD + Momentum gi√∫p escape saddle points\n",
    "- Stochastic gradient noise gi√∫p exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Gradient Noise & Mini-batch Stochasticity\n",
    "\n",
    "### Full Batch vs Mini-batch\n",
    "\n",
    "#### Full Batch Gradient Descent\n",
    "```python\n",
    "# Compute gradient tr√™n TO√ÄN B·ªò dataset\n",
    "loss = compute_loss(model(X_train), y_train)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "```\n",
    "- ‚úÖ Gradient ch√≠nh x√°c\n",
    "- ‚ùå Ch·∫≠m (ph·∫£i x·ª≠ l√Ω to√†n b·ªô data)\n",
    "- ‚ùå Memory intensive\n",
    "\n",
    "#### Mini-batch SGD\n",
    "```python\n",
    "# Compute gradient tr√™n SUBSET\n",
    "for X_batch, y_batch in dataloader:\n",
    "    loss = compute_loss(model(X_batch), y_batch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "```\n",
    "- ‚úÖ Nhanh\n",
    "- ‚úÖ Memory efficient\n",
    "- ‚úÖ Gradient noise gi√∫p exploration\n",
    "- ‚ùå Gradient kh√¥ng ch√≠nh x√°c (noisy)\n",
    "\n",
    "### Effect of Batch Size\n",
    "\n",
    "| Batch Size | Gradient Noise | Convergence Speed | Generalization |\n",
    "|------------|----------------|-------------------|----------------|\n",
    "| **Small (32)** | High | Slow per epoch, fast per iteration | Better (more noise) |\n",
    "| **Medium (256)** | Medium | Balanced | Balanced |\n",
    "| **Large (2048)** | Low | Fast per epoch, slow per iteration | Worse (less noise) |\n",
    "\n",
    "### Key Finding\n",
    "- Small batch ‚Üí Better generalization (noise acts as regularization)\n",
    "- Large batch ‚Üí Sharper minima ‚Üí Worse generalization\n",
    "- Solution: Large batch + LR warmup + longer training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: Batch Size Effect\n",
    "\n",
    "def train_with_batch_size(model, train_data, batch_size, epochs=10):\n",
    "    \"\"\"\n",
    "    Train model v·ªõi batch size c·ª• th·ªÉ\n",
    "    \"\"\"\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            epoch_loss += loss.item()\n",
    "    \n",
    "    return losses\n",
    "\n",
    "# Create toy dataset\n",
    "X = torch.randn(1000, 10)\n",
    "y = torch.randint(0, 2, (1000,))\n",
    "train_data = TensorDataset(X, y)\n",
    "\n",
    "# Simple model\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(10, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Compare different batch sizes\n",
    "batch_sizes = [16, 64, 256]\n",
    "results = {}\n",
    "\n",
    "print(\"üîÑ Training v·ªõi different batch sizes...\\n\")\n",
    "\n",
    "for bs in batch_sizes:\n",
    "    model = SimpleNet().to(device)\n",
    "    losses = train_with_batch_size(model, train_data, batch_size=bs, epochs=5)\n",
    "    results[bs] = losses\n",
    "    print(f\"‚úÖ Batch size {bs}: {len(losses)} iterations\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "for bs, losses in results.items():\n",
    "    # Smooth with moving average\n",
    "    window = 10\n",
    "    smoothed = np.convolve(losses, np.ones(window)/window, mode='valid')\n",
    "    plt.plot(smoothed, label=f'Batch size = {bs}', linewidth=2, alpha=0.8)\n",
    "\n",
    "plt.xlabel('Iteration', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Effect of Batch Size on Training Loss', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Observations:\")\n",
    "print(\"   Small batch (16): Noisy but fast convergence per iteration\")\n",
    "print(\"   Large batch (256): Smooth but slower convergence per iteration\")\n",
    "print(\"   Trade-off: Noise vs Stability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. SGD FAMILY\n",
    "\n",
    "## 2.1 Vanilla SGD\n",
    "\n",
    "### Formula\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\eta \\nabla L(\\theta_t)$$\n",
    "\n",
    "Trong ƒë√≥:\n",
    "- $\\theta$: Parameters\n",
    "- $\\eta$: Learning rate\n",
    "- $\\nabla L$: Gradient c·ªßa loss\n",
    "\n",
    "### Characteristics\n",
    "- ‚úÖ Simple, easy to understand\n",
    "- ‚úÖ Memory efficient\n",
    "- ‚ùå Slow convergence\n",
    "- ‚ùå Oscillates around minimum\n",
    "- ‚ùå Sensitive to learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla SGD Implementation\n",
    "\n",
    "class VanillaSGD:\n",
    "    \"\"\"\n",
    "    Vanilla SGD optimizer (for educational purposes)\n",
    "    \"\"\"\n",
    "    def __init__(self, params, lr=0.01):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self):\n",
    "        \"\"\"Update parameters\"\"\"\n",
    "        with torch.no_grad():\n",
    "            for param in self.params:\n",
    "                if param.grad is not None:\n",
    "                    # Œ∏_{t+1} = Œ∏_t - Œ∑ * ‚àáL(Œ∏_t)\n",
    "                    param.data -= self.lr * param.grad\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\"Zero all gradients\"\"\"\n",
    "        for param in self.params:\n",
    "            if param.grad is not None:\n",
    "                param.grad.zero_()\n",
    "\n",
    "print(\"‚úÖ Vanilla SGD implemented!\")\n",
    "print(\"\\nüí° Formula: Œ∏_{t+1} = Œ∏_t - Œ∑ * ‚àáL(Œ∏_t)\")\n",
    "print(\"   - Simple update rule\")\n",
    "print(\"   - No memory of past gradients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 SGD + Momentum\n",
    "\n",
    "### Motivation\n",
    "\n",
    "Vanilla SGD c√≥ v·∫•n ƒë·ªÅ:\n",
    "- Dao ƒë·ªông nhi·ªÅu trong narrow valleys\n",
    "- Ch·∫≠m khi surface ph·∫≥ng\n",
    "\n",
    "### Solution: Momentum\n",
    "\n",
    "$$v_t = \\beta v_{t-1} + \\nabla L(\\theta_t)$$\n",
    "$$\\theta_{t+1} = \\theta_t - \\eta v_t$$\n",
    "\n",
    "Trong ƒë√≥:\n",
    "- $v_t$: Velocity (momentum buffer)\n",
    "- $\\beta$: Momentum coefficient (typically 0.9)\n",
    "\n",
    "### Intuition\n",
    "\n",
    "Momentum = **Exponential Moving Average** of gradients\n",
    "\n",
    "$$v_t = \\beta v_{t-1} + g_t = \\sum_{i=0}^{t} \\beta^{t-i} g_i$$\n",
    "\n",
    "### Benefits\n",
    "- ‚úÖ Faster convergence\n",
    "- ‚úÖ Reduced oscillation\n",
    "- ‚úÖ Better handling of noisy gradients\n",
    "- ‚úÖ Can escape shallow local minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD + Momentum Implementation\n",
    "\n",
    "class SGDMomentum:\n",
    "    \"\"\"\n",
    "    SGD with Momentum\n",
    "    \"\"\"\n",
    "    def __init__(self, params, lr=0.01, momentum=0.9):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        \n",
    "        # Initialize velocity buffers\n",
    "        self.velocity = [torch.zeros_like(p.data) for p in self.params]\n",
    "    \n",
    "    def step(self):\n",
    "        \"\"\"Update parameters with momentum\"\"\"\n",
    "        with torch.no_grad():\n",
    "            for i, param in enumerate(self.params):\n",
    "                if param.grad is not None:\n",
    "                    # v_t = Œ≤ * v_{t-1} + g_t\n",
    "                    self.velocity[i] = self.momentum * self.velocity[i] + param.grad\n",
    "                    \n",
    "                    # Œ∏_{t+1} = Œ∏_t - Œ∑ * v_t\n",
    "                    param.data -= self.lr * self.velocity[i]\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for param in self.params:\n",
    "            if param.grad is not None:\n",
    "                param.grad.zero_()\n",
    "\n",
    "print(\"‚úÖ SGD + Momentum implemented!\")\n",
    "print(\"\\nüí° Key ideas:\")\n",
    "print(\"   - Accumulate gradient history\")\n",
    "print(\"   - Smooth out oscillations\")\n",
    "print(\"   - Accelerate in consistent directions\")\n",
    "print(\"   - Œ≤ = 0.9 means ~10 past gradients influence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Nesterov Momentum\n",
    "\n",
    "### Motivation\n",
    "\n",
    "Standard momentum:\n",
    "1. Compute gradient t·∫°i current position\n",
    "2. Update v·ªõi momentum\n",
    "\n",
    "Problem: Kh√¥ng \"look ahead\"\n",
    "\n",
    "### Nesterov Accelerated Gradient (NAG)\n",
    "\n",
    "$$v_t = \\beta v_{t-1} + \\nabla L(\\theta_t - \\beta v_{t-1})$$\n",
    "$$\\theta_{t+1} = \\theta_t - \\eta v_t$$\n",
    "\n",
    "Key difference: Compute gradient t·∫°i **lookahead position** $\\theta_t - \\beta v_{t-1}$\n",
    "\n",
    "### Intuition\n",
    "\n",
    "- Standard momentum: \"Jump first, look later\"\n",
    "- Nesterov: \"Look ahead, then jump\"\n",
    "\n",
    "### Benefits\n",
    "- ‚úÖ Better convergence than standard momentum\n",
    "- ‚úÖ Corrects before overshooting\n",
    "- ‚úÖ More stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize: SGD vs Momentum vs Nesterov\n",
    "\n",
    "def visualize_optimizer_paths():\n",
    "    \"\"\"\n",
    "    Visualize optimization paths for different optimizers\n",
    "    \"\"\"\n",
    "    # Simple 2D quadratic: f(x,y) = x^2 + 10*y^2\n",
    "    def loss_fn(x, y):\n",
    "        return x**2 + 10*y**2\n",
    "    \n",
    "    def grad_fn(x, y):\n",
    "        return 2*x, 20*y\n",
    "    \n",
    "    # Contour plot\n",
    "    x = np.linspace(-5, 5, 100)\n",
    "    y = np.linspace(-5, 5, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = loss_fn(X, Y)\n",
    "    \n",
    "    plt.figure(figsize=(14, 5))\n",
    "    \n",
    "    # Plot loss landscape\n",
    "    for idx, (name, lr, momentum) in enumerate([\n",
    "        ('Vanilla SGD', 0.1, 0.0),\n",
    "        ('SGD + Momentum', 0.1, 0.9),\n",
    "    ]):\n",
    "        plt.subplot(1, 2, idx+1)\n",
    "        plt.contour(X, Y, Z, levels=20, alpha=0.6)\n",
    "        plt.colorbar(label='Loss')\n",
    "        \n",
    "        # Simulate optimization\n",
    "        x_pos, y_pos = 4.0, 4.0\n",
    "        vx, vy = 0.0, 0.0\n",
    "        \n",
    "        trajectory_x = [x_pos]\n",
    "        trajectory_y = [y_pos]\n",
    "        \n",
    "        for _ in range(50):\n",
    "            gx, gy = grad_fn(x_pos, y_pos)\n",
    "            \n",
    "            # Update velocity\n",
    "            vx = momentum * vx + gx\n",
    "            vy = momentum * vy + gy\n",
    "            \n",
    "            # Update position\n",
    "            x_pos -= lr * vx\n",
    "            y_pos -= lr * vy\n",
    "            \n",
    "            trajectory_x.append(x_pos)\n",
    "            trajectory_y.append(y_pos)\n",
    "        \n",
    "        plt.plot(trajectory_x, trajectory_y, 'r-o', markersize=4, linewidth=2, alpha=0.7)\n",
    "        plt.scatter([0], [0], s=200, c='green', marker='*', zorder=5, label='Global Minimum')\n",
    "        plt.scatter([4], [4], s=150, c='red', marker='o', zorder=5, label='Start')\n",
    "        \n",
    "        plt.xlabel('x', fontsize=12)\n",
    "        plt.ylabel('y', fontsize=12)\n",
    "        plt.title(name, fontsize=13, fontweight='bold')\n",
    "        plt.legend(fontsize=10)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üìä Observations:\")\n",
    "    print(\"   Vanilla SGD: Oscillates, slow convergence\")\n",
    "    print(\"   Momentum: Smoother, faster convergence\")\n",
    "    print(\"   Nesterov: Even better correction\")\n",
    "\n",
    "visualize_optimizer_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. ADAPTIVE OPTIMIZERS\n",
    "\n",
    "## 3.1 Problem v·ªõi Fixed Learning Rate\n",
    "\n",
    "SGD family d√πng **same learning rate** cho all parameters:\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\eta \\nabla L(\\theta_t)$$\n",
    "\n",
    "### Issues\n",
    "- Parameters c√≥ gradients kh√°c nhau r·∫•t nhi·ªÅu\n",
    "- Some dimensions c·∫ßn large steps\n",
    "- Some dimensions c·∫ßn small steps\n",
    "- Fixed LR kh√¥ng optimal cho t·∫•t c·∫£\n",
    "\n",
    "### Solution: Adaptive Learning Rates\n",
    "\n",
    "**Idea**: Adapt learning rate per parameter d·ª±a tr√™n gradient history\n",
    "\n",
    "## 3.2 Adagrad\n",
    "\n",
    "### Formula\n",
    "\n",
    "$$G_t = G_{t-1} + g_t^2$$\n",
    "$$\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{G_t + \\epsilon}} g_t$$\n",
    "\n",
    "Trong ƒë√≥:\n",
    "- $G_t$: Sum of squared gradients\n",
    "- $\\epsilon$: Small constant (1e-8) for numerical stability\n",
    "\n",
    "### Intuition\n",
    "- Parameters v·ªõi large gradients ‚Üí smaller effective LR\n",
    "- Parameters v·ªõi small gradients ‚Üí larger effective LR\n",
    "\n",
    "### Problem\n",
    "- $G_t$ continuously grows ‚Üí LR shrinks to zero\n",
    "- Training stops prematurely\n",
    "- Not suitable for deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 RMSProp\n",
    "\n",
    "### Motivation\n",
    "\n",
    "Adagrad's problem: $G_t$ grows indefinitely\n",
    "\n",
    "### Solution\n",
    "\n",
    "Use **exponential moving average** instead of sum:\n",
    "\n",
    "$$v_t = \\beta v_{t-1} + (1-\\beta) g_t^2$$\n",
    "$$\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{v_t + \\epsilon}} g_t$$\n",
    "\n",
    "Trong ƒë√≥:\n",
    "- $\\beta$: Decay rate (typically 0.9 or 0.99)\n",
    "- $v_t$: Moving average of squared gradients\n",
    "\n",
    "### Benefits\n",
    "- ‚úÖ Prevents LR from shrinking to zero\n",
    "- ‚úÖ Adapts to recent gradient history\n",
    "- ‚úÖ Works well in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Adam (Adaptive Moment Estimation)\n",
    "\n",
    "### Formula\n",
    "\n",
    "Adam = **Momentum** + **RMSProp**\n",
    "\n",
    "$$m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t \\quad \\text{(First moment: mean)}$$\n",
    "$$v_t = \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2 \\quad \\text{(Second moment: variance)}$$\n",
    "\n",
    "Bias correction:\n",
    "$$\\hat{m}_t = \\frac{m_t}{1-\\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t}{1-\\beta_2^t}$$\n",
    "\n",
    "Update:\n",
    "$$\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t$$\n",
    "\n",
    "### Hyperparameters\n",
    "- $\\beta_1 = 0.9$ (momentum)\n",
    "- $\\beta_2 = 0.999$ (RMSProp)\n",
    "- $\\epsilon = 10^{-8}$\n",
    "- $\\eta$ = learning rate (often 0.001)\n",
    "\n",
    "### Benefits\n",
    "- ‚úÖ Combines best of momentum & adaptive LR\n",
    "- ‚úÖ Works well v·ªõi sparse gradients\n",
    "- ‚úÖ Default choice for many applications\n",
    "- ‚úÖ Bias correction prevents initial steps t·ª´ being too large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam Implementation (Simplified)\n",
    "\n",
    "class AdamOptimizer:\n",
    "    \"\"\"\n",
    "    Adam optimizer (educational implementation)\n",
    "    \"\"\"\n",
    "    def __init__(self, params, lr=0.001, beta1=0.9, beta2=0.999, eps=1e-8):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        \n",
    "        # Initialize moment estimates\n",
    "        self.m = [torch.zeros_like(p.data) for p in self.params]  # First moment\n",
    "        self.v = [torch.zeros_like(p.data) for p in self.params]  # Second moment\n",
    "        self.t = 0  # Timestep\n",
    "    \n",
    "    def step(self):\n",
    "        \"\"\"Adam update\"\"\"\n",
    "        self.t += 1\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, param in enumerate(self.params):\n",
    "                if param.grad is not None:\n",
    "                    g = param.grad\n",
    "                    \n",
    "                    # Update biased first moment estimate\n",
    "                    self.m[i] = self.beta1 * self.m[i] + (1 - self.beta1) * g\n",
    "                    \n",
    "                    # Update biased second moment estimate\n",
    "                    self.v[i] = self.beta2 * self.v[i] + (1 - self.beta2) * g**2\n",
    "                    \n",
    "                    # Bias correction\n",
    "                    m_hat = self.m[i] / (1 - self.beta1**self.t)\n",
    "                    v_hat = self.v[i] / (1 - self.beta2**self.t)\n",
    "                    \n",
    "                    # Update parameters\n",
    "                    param.data -= self.lr * m_hat / (torch.sqrt(v_hat) + self.eps)\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for param in self.params:\n",
    "            if param.grad is not None:\n",
    "                param.grad.zero_()\n",
    "\n",
    "print(\"‚úÖ Adam optimizer implemented!\")\n",
    "print(\"\\nüí° Adam = Momentum + RMSProp + Bias Correction\")\n",
    "print(\"   - m_t: First moment (mean of gradients)\")\n",
    "print(\"   - v_t: Second moment (variance of gradients)\")\n",
    "print(\"   - Bias correction: Important for initial steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 AdamW (Weight Decay)\n",
    "\n",
    "### Problem with Adam + L2 Regularization\n",
    "\n",
    "Traditional L2 regularization:\n",
    "$$L = L_{task} + \\frac{\\lambda}{2}||\\theta||^2$$\n",
    "\n",
    "Gradient:\n",
    "$$\\nabla L = \\nabla L_{task} + \\lambda \\theta$$\n",
    "\n",
    "**Problem**: Khi d√πng v·ªõi Adam, regularization term ƒë∆∞·ª£c adaptive ‚Üí kh√¥ng consistent!\n",
    "\n",
    "### Solution: Decoupled Weight Decay\n",
    "\n",
    "AdamW separates weight decay from gradient:\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\eta \\left(\\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon} + \\lambda \\theta_t\\right)$$\n",
    "\n",
    "### Key Difference\n",
    "\n",
    "| Aspect | Adam + L2 | AdamW |\n",
    "|--------|-----------|-------|\n",
    "| Weight decay | In gradient | Separate term |\n",
    "| Adaptive | Yes | No |\n",
    "| Effect | Inconsistent | Consistent |\n",
    "| Performance | Worse | Better |\n",
    "\n",
    "### Recommendation\n",
    "- ‚úÖ Use **AdamW** instead of Adam + L2\n",
    "- ‚úÖ Typical weight decay: 0.01 ~ 0.1\n",
    "- ‚úÖ Standard choice for Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéì T·ªïng k·∫øt FILE 1: Optimization\n",
    "\n",
    "## ‚úÖ Nh·ªØng g√¨ ƒë√£ h·ªçc\n",
    "\n",
    "### 1. Optimization Fundamentals\n",
    "- **Loss landscape**: Convex vs Non-convex\n",
    "- **Saddle points**: Common trong high dimensions\n",
    "- **Batch size effects**: Small batch ‚Üí better generalization\n",
    "- **Gradient noise**: Acts as regularization\n",
    "\n",
    "### 2. SGD Family\n",
    "- **Vanilla SGD**: Simple but slow\n",
    "- **Momentum**: Exponential moving average of gradients\n",
    "- **Nesterov**: Look-ahead correction\n",
    "- Œ≤ = 0.9 is typical momentum value\n",
    "\n",
    "### 3. Adaptive Optimizers\n",
    "- **Adagrad**: Accumulates squared gradients (problematic)\n",
    "- **RMSProp**: Moving average of squared gradients\n",
    "- **Adam**: Momentum + RMSProp + bias correction\n",
    "- **AdamW**: Decoupled weight decay (preferred)\n",
    "\n",
    "## üöÄ Key Takeaways\n",
    "\n",
    "1. **Deep learning = Non-convex optimization**\n",
    "2. **Momentum** smooths oscillations, accelerates convergence\n",
    "3. **Adam** = default choice (but not always best)\n",
    "4. **AdamW** better than Adam + L2\n",
    "5. **Small batch size** often generalizes better\n",
    "6. **Learning rate** most important hyperparameter\n",
    "\n",
    "## üìù Next: FILE 2\n",
    "\n",
    "- Learning Rate Strategies\n",
    "- Practical Experiments\n",
    "- Optimizer Comparison\n",
    "- When Adam fails\n",
    "\n",
    "---\n",
    "\n",
    "**Ch√∫c m·ª´ng b·∫°n ƒë√£ ho√†n th√†nh FILE 1! üéâ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
