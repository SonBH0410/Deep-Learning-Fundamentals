{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìó Ch∆∞∆°ng 4: Embeddings - H·ªçc Bi·ªÉu Di·ªÖn (Representation Learning)\n",
    "\n",
    "**Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi notebook t∆∞∆°ng t√°c v·ªÅ Embeddings!**\n",
    "\n",
    "## üéØ M·ª•c ti√™u h·ªçc t·∫≠p\n",
    "\n",
    "Trong ch∆∞∆°ng n√†y, b·∫°n s·∫Ω n·∫Øm v·ªØng:\n",
    "- üî¢ **S·ª± kh√°c bi·ªát** gi·ªØa one-hot encoding v√† embeddings\n",
    "- üß† **C√°ch embeddings h·ªçc** ƒë∆∞·ª£c bi·ªÉu di·ªÖn ng·ªØ nghƒ©a\n",
    "- ‚öñÔ∏è **Trade-off** c·ªßa k√≠ch th∆∞·ªõc embedding\n",
    "- üé® **Visualize v√† ph√¢n t√≠ch** kh√¥ng gian embedding\n",
    "- üíª **Implement t·ª´ ƒë·∫ßu** v√† train embeddings\n",
    "\n",
    "---\n",
    "\n",
    "## üìö N·ªôi dung\n",
    "\n",
    "1. [One-Hot vs Embedding](#section1)\n",
    "2. [Word/Token Embedding Implementation](#section2)\n",
    "3. [Embedding Properties](#section3)\n",
    "4. [Practical Experiments](#section4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SETUP: Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "# ============================================\n",
    "\n",
    "# N·∫øu ch∆∞a c√†i ƒë·∫∑t, uncomment d√≤ng d∆∞·ªõi:\n",
    "# !pip install torch numpy matplotlib seaborn scikit-learn plotly pandas\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from typing import List, Dict, Tuple\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# C·∫•u h√¨nh hi·ªÉn th·ªã\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ Device: {device}\")\n",
    "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section1'></a>\n",
    "## 4.1 One-Hot Encoding vs Embeddings\n",
    "\n",
    "### ü§î V·∫•n ƒë·ªÅ c·ªßa One-Hot Encoding\n",
    "\n",
    "**One-Hot Encoding** l√† c√°ch bi·ªÉu di·ªÖn ƒë∆°n gi·∫£n nh·∫•t:\n",
    "- M·ªói t·ª´/token ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng vector c√≥ **ƒë√∫ng 1 ph·∫ßn t·ª≠ = 1**, c√≤n l·∫°i = 0\n",
    "- V·ªõi vocabulary size = 10,000 t·ª´ ‚Üí m·ªói t·ª´ c·∫ßn vector **10,000 chi·ªÅu**!\n",
    "\n",
    "#### ‚ùå Nh∆∞·ª£c ƒëi·ªÉm c·ªßa One-Hot:\n",
    "1. **Sparse** (th∆∞a th·ªõt): 99.99% l√† s·ªë 0\n",
    "2. **Kh√¥ng c√≥ √Ω nghƒ©a ng·ªØ nghƒ©a**: \"vua\" v√† \"ho√†ng ƒë·∫ø\" xa nhau nh∆∞ \"vua\" v√† \"chu·ªëi\"\n",
    "3. **Chi·∫øm b·ªô nh·ªõ kh·ªïng l·ªì**: 10K t·ª´ √ó 10K dim = 100 tri·ªáu parameters!\n",
    "4. **Kh√¥ng generalize**: Kh√¥ng h·ªçc ƒë∆∞·ª£c m·ªëi quan h·ªá gi·ªØa c√°c t·ª´\n",
    "\n",
    "#### ‚úÖ ∆Øu ƒëi·ªÉm c·ªßa Embeddings:\n",
    "1. **Dense** (ƒë·∫∑c): M·ªói chi·ªÅu ƒë·ªÅu c√≥ √Ω nghƒ©a\n",
    "2. **Learned representation**: T·ª± ƒë·ªông h·ªçc ƒë∆∞·ª£c ng·ªØ nghƒ©a\n",
    "3. **Compact**: 10K t·ª´ √ó 300 dim = ch·ªâ 3 tri·ªáu parameters\n",
    "4. **Similarity**: T·ª´ c√≥ nghƒ©a g·∫ßn nhau ‚Üí embeddings g·∫ßn nhau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Demo: So s√°nh One-Hot vs Embedding\n",
    "# ============================================\n",
    "\n",
    "class OneHotVsEmbedding:\n",
    "    \"\"\"Class ƒë·ªÉ demo s·ª± kh√°c bi·ªát gi·ªØa One-Hot v√† Embedding\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size: int, embedding_dim: int):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "    def create_onehot(self, word_idx: int) -> torch.Tensor:\n",
    "        \"\"\"T·∫°o one-hot vector cho m·ªôt t·ª´\"\"\"\n",
    "        onehot = torch.zeros(self.vocab_size)\n",
    "        onehot[word_idx] = 1\n",
    "        return onehot\n",
    "    \n",
    "    def visualize_comparison(self):\n",
    "        \"\"\"Visualize s·ª± kh√°c bi·ªát v·ªÅ memory v√† sparsity\"\"\"\n",
    "        \n",
    "        # T√≠nh to√°n memory usage\n",
    "        onehot_memory = self.vocab_size * self.vocab_size * 4 / (1024**2)  # MB\n",
    "        embed_memory = self.vocab_size * self.embedding_dim * 4 / (1024**2)  # MB\n",
    "        \n",
    "        # T·∫°o visualization\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        \n",
    "        # 1. Memory Comparison\n",
    "        ax1 = axes[0, 0]\n",
    "        methods = ['One-Hot', 'Embedding']\n",
    "        memory = [onehot_memory, embed_memory]\n",
    "        colors = ['#ff6b6b', '#4ecdc4']\n",
    "        bars = ax1.bar(methods, memory, color=colors, alpha=0.7, edgecolor='black')\n",
    "        ax1.set_ylabel('Memory (MB)', fontsize=12, fontweight='bold')\n",
    "        ax1.set_title('üìä So s√°nh Memory Usage', fontsize=14, fontweight='bold')\n",
    "        ax1.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Th√™m labels\n",
    "        for bar, mem in zip(bars, memory):\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{mem:.1f} MB',\n",
    "                    ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # 2. Sparsity Visualization (One-Hot)\n",
    "        ax2 = axes[0, 1]\n",
    "        sample_size = min(20, self.vocab_size)\n",
    "        onehot_sample = torch.eye(sample_size)[:5]  # 5 t·ª´\n",
    "        im2 = ax2.imshow(onehot_sample, cmap='RdYlGn', aspect='auto')\n",
    "        ax2.set_xlabel('Vocabulary Index', fontsize=11)\n",
    "        ax2.set_ylabel('Word Index', fontsize=11)\n",
    "        ax2.set_title('‚ùå One-Hot: Sparse (99% zeros)', fontsize=13, fontweight='bold')\n",
    "        plt.colorbar(im2, ax=ax2)\n",
    "        \n",
    "        # 3. Embedding Visualization (Dense)\n",
    "        ax3 = axes[1, 0]\n",
    "        embedding_sample = torch.randn(5, min(20, self.embedding_dim))\n",
    "        im3 = ax3.imshow(embedding_sample, cmap='viridis', aspect='auto')\n",
    "        ax3.set_xlabel('Embedding Dimension', fontsize=11)\n",
    "        ax3.set_ylabel('Word Index', fontsize=11)\n",
    "        ax3.set_title('‚úÖ Embedding: Dense (m·ªçi gi√° tr·ªã ƒë·ªÅu c√≥ √Ω nghƒ©a)', \n",
    "                     fontsize=13, fontweight='bold')\n",
    "        plt.colorbar(im3, ax=ax3)\n",
    "        \n",
    "        # 4. Parameter Count Comparison\n",
    "        ax4 = axes[1, 1]\n",
    "        vocab_sizes = [100, 1000, 5000, 10000, 50000]\n",
    "        onehot_params = [v**2 for v in vocab_sizes]\n",
    "        embed_params = [v * self.embedding_dim for v in vocab_sizes]\n",
    "        \n",
    "        ax4.plot(vocab_sizes, onehot_params, 'o-', label='One-Hot', \n",
    "                linewidth=2, markersize=8, color='#ff6b6b')\n",
    "        ax4.plot(vocab_sizes, embed_params, 's-', label='Embedding', \n",
    "                linewidth=2, markersize=8, color='#4ecdc4')\n",
    "        ax4.set_xlabel('Vocabulary Size', fontsize=12, fontweight='bold')\n",
    "        ax4.set_ylabel('# Parameters (log scale)', fontsize=12, fontweight='bold')\n",
    "        ax4.set_title('üìà Scalability: Parameters vs Vocab Size', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "        ax4.set_yscale('log')\n",
    "        ax4.legend(fontsize=11, loc='upper left')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print statistics\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üìä SO S√ÅNH CHI TI·∫æT: ONE-HOT vs EMBEDDING\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\nüîπ Vocabulary Size: {self.vocab_size:,} t·ª´\")\n",
    "        print(f\"üîπ Embedding Dimension: {self.embedding_dim}\")\n",
    "        print(\"\\n\" + \"-\"*70)\n",
    "        print(\"ONE-HOT ENCODING:\")\n",
    "        print(\"-\"*70)\n",
    "        print(f\"  ‚Ä¢ Vector dimension: {self.vocab_size:,}\")\n",
    "        print(f\"  ‚Ä¢ Sparsity: {((self.vocab_size-1)/self.vocab_size*100):.2f}% zeros\")\n",
    "        print(f\"  ‚Ä¢ Memory: {onehot_memory:.2f} MB\")\n",
    "        print(f\"  ‚Ä¢ Parameters: {self.vocab_size**2:,}\")\n",
    "        print(\"\\n\" + \"-\"*70)\n",
    "        print(\"EMBEDDING:\")\n",
    "        print(\"-\"*70)\n",
    "        print(f\"  ‚Ä¢ Vector dimension: {self.embedding_dim}\")\n",
    "        print(f\"  ‚Ä¢ Sparsity: 0% (dense representation)\")\n",
    "        print(f\"  ‚Ä¢ Memory: {embed_memory:.2f} MB\")\n",
    "        print(f\"  ‚Ä¢ Parameters: {self.vocab_size * self.embedding_dim:,}\")\n",
    "        print(\"\\n\" + \"-\"*70)\n",
    "        print(\"TI·∫æT KI·ªÜM:\")\n",
    "        print(\"-\"*70)\n",
    "        print(f\"  ‚Ä¢ Memory reduction: {(1 - embed_memory/onehot_memory)*100:.1f}%\")\n",
    "        print(f\"  ‚Ä¢ Parameter reduction: {(1 - (self.vocab_size*self.embedding_dim)/(self.vocab_size**2))*100:.1f}%\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Demo v·ªõi vocabulary size = 5000, embedding dimension = 128\n",
    "demo = OneHotVsEmbedding(vocab_size=5000, embedding_dim=128)\n",
    "demo.visualize_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì Trade-off c·ªßa Embedding Dimension\n",
    "\n",
    "Ch·ªçn k√≠ch th∆∞·ªõc embedding l√† m·ªôt ngh·ªá thu·∫≠t! \n",
    "\n",
    "| Dimension | ∆Øu ƒëi·ªÉm | Nh∆∞·ª£c ƒëi·ªÉm | Khi n√†o d√πng? |\n",
    "|-----------|---------|------------|---------------|\n",
    "| **Nh·ªè (16-64)** | ‚ö° Nhanh, nh·∫π | ‚ö†Ô∏è √çt th√¥ng tin | Dataset nh·ªè, mobile |\n",
    "| **Trung b√¨nh (128-256)** | ‚öñÔ∏è C√¢n b·∫±ng t·ªët | üòê Trung b√¨nh | H·∫ßu h·∫øt use cases |\n",
    "| **L·ªõn (512-1024)** | üß† Nhi·ªÅu th√¥ng tin | üêå Ch·∫≠m, overfitting | Dataset l·ªõn, ph·ª©c t·∫°p |\n",
    "\n",
    "**Rule of thumb:**\n",
    "- Vocabulary < 10K ‚Üí dim = 128\n",
    "- Vocabulary 10K-100K ‚Üí dim = 256-512\n",
    "- Vocabulary > 100K ‚Üí dim = 512-768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Experiment: Embedding Dimension Trade-off\n",
    "# ============================================\n",
    "\n",
    "def analyze_embedding_dimensions():\n",
    "    \"\"\"Ph√¢n t√≠ch impact c·ªßa embedding dimension\"\"\"\n",
    "    \n",
    "    vocab_size = 10000\n",
    "    dimensions = [16, 32, 64, 128, 256, 512, 768, 1024]\n",
    "    \n",
    "    # Metrics ƒë·ªÉ track\n",
    "    memory_usage = []\n",
    "    capacity = []  # Information capacity\n",
    "    computation_cost = []\n",
    "    \n",
    "    for dim in dimensions:\n",
    "        # Memory usage (MB)\n",
    "        mem = vocab_size * dim * 4 / (1024**2)\n",
    "        memory_usage.append(mem)\n",
    "        \n",
    "        # Information capacity (bits per word)\n",
    "        cap = dim * 32  # 32-bit float\n",
    "        capacity.append(cap)\n",
    "        \n",
    "        # Relative computation cost\n",
    "        comp = dim / dimensions[0]  # relative to smallest\n",
    "        computation_cost.append(comp)\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # 1. Memory Usage\n",
    "    axes[0].plot(dimensions, memory_usage, 'o-', linewidth=3, \n",
    "                markersize=10, color='#3498db')\n",
    "    axes[0].fill_between(dimensions, memory_usage, alpha=0.3, color='#3498db')\n",
    "    axes[0].set_xlabel('Embedding Dimension', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_ylabel('Memory (MB)', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_title('üíæ Memory Usage', fontsize=14, fontweight='bold')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].set_xscale('log', base=2)\n",
    "    \n",
    "    # 2. Information Capacity\n",
    "    axes[1].plot(dimensions, capacity, 's-', linewidth=3, \n",
    "                markersize=10, color='#2ecc71')\n",
    "    axes[1].fill_between(dimensions, capacity, alpha=0.3, color='#2ecc71')\n",
    "    axes[1].set_xlabel('Embedding Dimension', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('Capacity (bits)', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_title('üß† Information Capacity', fontsize=14, fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].set_xscale('log', base=2)\n",
    "    \n",
    "    # 3. Computation Cost\n",
    "    axes[2].plot(dimensions, computation_cost, '^-', linewidth=3, \n",
    "                markersize=10, color='#e74c3c')\n",
    "    axes[2].fill_between(dimensions, computation_cost, alpha=0.3, color='#e74c3c')\n",
    "    axes[2].set_xlabel('Embedding Dimension', fontsize=12, fontweight='bold')\n",
    "    axes[2].set_ylabel('Relative Cost', fontsize=12, fontweight='bold')\n",
    "    axes[2].set_title('‚ö° Computation Cost', fontsize=14, fontweight='bold')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].set_xscale('log', base=2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print recommendations\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üéØ KHUY·∫æN NGH·ªä CH·ªåN EMBEDDING DIMENSION\")\n",
    "    print(\"=\"*70)\n",
    "    for i, dim in enumerate(dimensions):\n",
    "        print(f\"\\nDimension = {dim}:\")\n",
    "        print(f\"  Memory: {memory_usage[i]:.2f} MB\")\n",
    "        print(f\"  Capacity: {capacity[i]:,} bits\")\n",
    "        print(f\"  Cost: {computation_cost[i]:.1f}x\")\n",
    "        \n",
    "        # Recommendation\n",
    "        if dim <= 64:\n",
    "            print(\"  ‚Üí üì± T·ªët cho: Mobile, edge devices, real-time\")\n",
    "        elif dim <= 256:\n",
    "            print(\"  ‚Üí üíª T·ªët cho: General purpose, balanced performance\")\n",
    "        else:\n",
    "            print(\"  ‚Üí üñ•Ô∏è T·ªët cho: Large datasets, complex relationships\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "analyze_embedding_dimensions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section2'></a>\n",
    "## 4.2 Word/Token Embedding: Implementation\n",
    "\n",
    "### üîß C√°ch Embedding ho·∫°t ƒë·ªông\n",
    "\n",
    "Embedding layer v·ªÅ b·∫£n ch·∫•t l√† m·ªôt **lookup table** (b·∫£ng tra c·ª©u):\n",
    "\n",
    "```\n",
    "Word Index ‚Üí Embedding Table ‚Üí Embedding Vector\n",
    "    3      ‚Üí  [0.2, -0.1, 0.5, ...]  ‚Üí Dense vector\n",
    "```\n",
    "\n",
    "**Qu√° tr√¨nh h·ªçc:**\n",
    "1. Initialize ng·∫´u nhi√™n: `torch.nn.Embedding(vocab_size, embedding_dim)`\n",
    "2. Forward pass: Lookup vector theo index\n",
    "3. Backprop: Gradient ch·ªâ update vector ƒë∆∞·ª£c lookup\n",
    "4. Optimizer: Update embedding table\n",
    "\n",
    "### üéØ Padding & Masking\n",
    "\n",
    "Trong th·ª±c t·∫ø, sequences c√≥ ƒë·ªô d√†i kh√°c nhau:\n",
    "- **Padding**: Th√™m token ƒë·∫∑c bi·ªát (th∆∞·ªùng l√† 0) ƒë·ªÉ c√°c sequences c√≥ c√πng ƒë·ªô d√†i\n",
    "- **Masking**: \"Che\" c√°c padding tokens ƒë·ªÉ model kh√¥ng h·ªçc t·ª´ ch√∫ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Implementation: Embedding Layer t·ª´ ƒë·∫ßu\n",
    "# ============================================\n",
    "\n",
    "class CustomEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom Embedding Layer ƒë·ªÉ hi·ªÉu r√µ c√°ch ho·∫°t ƒë·ªông b√™n trong\n",
    "    \n",
    "    Args:\n",
    "        vocab_size: S·ªë l∆∞·ª£ng t·ª´ trong vocabulary\n",
    "        embedding_dim: K√≠ch th∆∞·ªõc vector embedding\n",
    "        padding_idx: Index c·ªßa padding token (m·∫∑c ƒë·ªãnh 0)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size: int, embedding_dim: int, padding_idx: int = 0):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.padding_idx = padding_idx\n",
    "        \n",
    "        # Embedding table: lookup table ch√≠nh\n",
    "        self.weight = nn.Parameter(torch.randn(vocab_size, embedding_dim))\n",
    "        \n",
    "        # Initialize padding embedding th√†nh zeros\n",
    "        if padding_idx is not None:\n",
    "            with torch.no_grad():\n",
    "                self.weight[padding_idx].fill_(0)\n",
    "    \n",
    "    def forward(self, input_ids: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass: Lookup embeddings t·ª´ table\n",
    "        \n",
    "        Args:\n",
    "            input_ids: (batch_size, seq_len) - indices c·ªßa tokens\n",
    "        \n",
    "        Returns:\n",
    "            embeddings: (batch_size, seq_len, embedding_dim)\n",
    "        \"\"\"\n",
    "        # Simple lookup operation\n",
    "        return self.weight[input_ids]\n",
    "    \n",
    "    def get_gradient_mask(self, input_ids: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        T·∫°o mask ƒë·ªÉ kh√¥ng update padding embeddings\n",
    "        \"\"\"\n",
    "        return (input_ids != self.padding_idx).float()\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Demo: So s√°nh Custom vs PyTorch Embedding\n",
    "# ============================================\n",
    "\n",
    "def demo_embedding_layers():\n",
    "    \"\"\"Demo v√† so s√°nh custom embedding v·ªõi PyTorch's embedding\"\"\"\n",
    "    \n",
    "    vocab_size = 100\n",
    "    embedding_dim = 16\n",
    "    batch_size = 4\n",
    "    seq_len = 10\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"üîß DEMO: EMBEDDING LAYER IMPLEMENTATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # 1. Custom Embedding\n",
    "    custom_embed = CustomEmbedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "    \n",
    "    # 2. PyTorch Embedding\n",
    "    pytorch_embed = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "    \n",
    "    # Copy weights ƒë·ªÉ c√≥ c√πng kh·ªüi t·∫°o\n",
    "    with torch.no_grad():\n",
    "        pytorch_embed.weight.copy_(custom_embed.weight)\n",
    "    \n",
    "    # T·∫°o input v·ªõi padding\n",
    "    # 0 l√† padding token\n",
    "    input_ids = torch.randint(1, vocab_size, (batch_size, seq_len))\n",
    "    input_ids[:, -3:] = 0  # Add padding ·ªü cu·ªëi\n",
    "    \n",
    "    print(f\"\\nüìù Input shape: {input_ids.shape}\")\n",
    "    print(f\"\\nSample input (batch 0):\")\n",
    "    print(input_ids[0])\n",
    "    print(f\"  ‚Üí Padding positions: {(input_ids[0] == 0).nonzero().squeeze()}\")\n",
    "    \n",
    "    # Forward pass\n",
    "    custom_output = custom_embed(input_ids)\n",
    "    pytorch_output = pytorch_embed(input_ids)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Output shape: {custom_output.shape}\")\n",
    "    print(f\"   ({batch_size} batches, {seq_len} tokens, {embedding_dim} dimensions)\")\n",
    "    \n",
    "    # Verify outputs are identical\n",
    "    diff = (custom_output - pytorch_output).abs().max().item()\n",
    "    print(f\"\\nüîç Difference between custom and PyTorch: {diff:.10f}\")\n",
    "    print(f\"   ‚Üí {'‚úÖ Identical!' if diff < 1e-6 else '‚ùå Different'}\")\n",
    "    \n",
    "    # Visualize embeddings\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Plot embedding cho m·ªôt batch\n",
    "    sample_embed = custom_output[0].detach().numpy()\n",
    "    \n",
    "    # 1. Heatmap c·ªßa embeddings\n",
    "    im1 = axes[0].imshow(sample_embed.T, cmap='RdBu_r', aspect='auto')\n",
    "    axes[0].set_xlabel('Token Position', fontsize=11)\n",
    "    axes[0].set_ylabel('Embedding Dimension', fontsize=11)\n",
    "    axes[0].set_title('üé® Embedding Vectors Visualization', fontsize=13, fontweight='bold')\n",
    "    plt.colorbar(im1, ax=axes[0], label='Value')\n",
    "    \n",
    "    # ƒê√°nh d·∫•u padding positions\n",
    "    padding_pos = (input_ids[0] == 0).nonzero().squeeze().tolist()\n",
    "    if isinstance(padding_pos, int):\n",
    "        padding_pos = [padding_pos]\n",
    "    for pos in padding_pos:\n",
    "        axes[0].axvline(x=pos, color='red', linestyle='--', linewidth=2, alpha=0.7)\n",
    "    \n",
    "    # 2. Norm c·ªßa embeddings (padding should be ~0)\n",
    "    norms = torch.norm(custom_output[0], dim=1).detach().numpy()\n",
    "    positions = range(len(norms))\n",
    "    colors = ['red' if input_ids[0, i] == 0 else 'blue' for i in range(len(norms))]\n",
    "    \n",
    "    axes[1].bar(positions, norms, color=colors, alpha=0.7, edgecolor='black')\n",
    "    axes[1].set_xlabel('Token Position', fontsize=11)\n",
    "    axes[1].set_ylabel('L2 Norm', fontsize=11)\n",
    "    axes[1].set_title('üìä Embedding Norms (Red = Padding)', fontsize=13, fontweight='bold')\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"üìå QUAN TR·ªåNG:\")\n",
    "    print(\"-\"*70)\n",
    "    print(\"1. Padding tokens (red) c√≥ norm ‚âà 0\")\n",
    "    print(\"2. Non-padding tokens (blue) c√≥ norm > 0\")\n",
    "    print(\"3. Gradients ch·ªâ flow qua non-padding tokens\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "demo_embedding_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Visualize: Gradient Flow trong Embedding\n",
    "# ============================================\n",
    "\n",
    "def visualize_gradient_flow():\n",
    "    \"\"\"\n",
    "    Visualize c√°ch gradients flow qua embedding layer\n",
    "    v√† ch·ªâ update c√°c embeddings ƒë∆∞·ª£c s·ª≠ d·ª•ng\n",
    "    \"\"\"\n",
    "    \n",
    "    vocab_size = 20\n",
    "    embedding_dim = 8\n",
    "    \n",
    "    # Create embedding layer\n",
    "    embed = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "    \n",
    "    # Input: ch·ªâ s·ª≠ d·ª•ng m·ªôt v√†i tokens\n",
    "    input_ids = torch.tensor([3, 5, 7, 0, 0])  # 0 l√† padding\n",
    "    \n",
    "    # Forward\n",
    "    embeddings = embed(input_ids)  # (5, 8)\n",
    "    \n",
    "    # Dummy loss: ch·ªâ c·∫ßn backward ƒë·ªÉ xem gradients\n",
    "    loss = embeddings.sum()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Check gradients\n",
    "    grad_norm = torch.norm(embed.weight.grad, dim=1).numpy()\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # 1. Gradient magnitude cho m·ªói word\n",
    "    colors = ['red' if i == 0 else 'green' if i in [3, 5, 7] else 'gray' \n",
    "              for i in range(vocab_size)]\n",
    "    \n",
    "    bars = axes[0].bar(range(vocab_size), grad_norm, color=colors, \n",
    "                       alpha=0.7, edgecolor='black')\n",
    "    axes[0].set_xlabel('Word Index', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_ylabel('Gradient Magnitude', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_title('üî• Gradient Flow (Green = Used, Gray = Unused, Red = Padding)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Highlight used tokens\n",
    "    used_tokens = [3, 5, 7]\n",
    "    for tok in used_tokens:\n",
    "        axes[0].text(tok, grad_norm[tok], f'‚úì', ha='center', va='bottom', \n",
    "                    fontsize=16, fontweight='bold', color='darkgreen')\n",
    "    \n",
    "    # 2. Embedding weight heatmap v·ªõi gradient overlay\n",
    "    weights = embed.weight.detach().numpy()\n",
    "    im = axes[1].imshow(weights, cmap='coolwarm', aspect='auto')\n",
    "    axes[1].set_xlabel('Embedding Dimension', fontsize=11)\n",
    "    axes[1].set_ylabel('Word Index', fontsize=11)\n",
    "    axes[1].set_title('üíæ Embedding Weights', fontsize=13, fontweight='bold')\n",
    "    plt.colorbar(im, ax=axes[1])\n",
    "    \n",
    "    # Highlight rows v·ªõi gradients\n",
    "    for tok in used_tokens:\n",
    "        axes[1].axhline(y=tok, color='yellow', linestyle='--', linewidth=2, alpha=0.5)\n",
    "    axes[1].axhline(y=0, color='red', linestyle='--', linewidth=2, alpha=0.7, \n",
    "                   label='Padding (no grad)')\n",
    "    axes[1].legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üéì GRADIENT FLOW ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nVocabulary size: {vocab_size}\")\n",
    "    print(f\"Input tokens: {input_ids.tolist()}\")\n",
    "    print(f\"\\nGradient Statistics:\")\n",
    "    print(f\"  ‚Ä¢ Padding token (0): gradient = {grad_norm[0]:.6f}\")\n",
    "    print(f\"  ‚Ä¢ Used tokens {used_tokens}: gradient = {[f'{grad_norm[t]:.6f}' for t in used_tokens]}\")\n",
    "    print(f\"  ‚Ä¢ Unused tokens: gradient = {grad_norm[1:3].mean():.6f} (mean of first few)\")\n",
    "    print(f\"\\n‚úÖ Ch·ªâ c√≥ {len(used_tokens)}/{vocab_size} embeddings ƒë∆∞·ª£c update!\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "visualize_gradient_flow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section3'></a>\n",
    "## 4.3 Embedding Properties\n",
    "\n",
    "### üîç Cosine Similarity\n",
    "\n",
    "Embeddings t·ªët c√≥ t√≠nh ch·∫•t quan tr·ªçng: **t·ª´ c√≥ nghƒ©a g·∫ßn nhau ‚Üí vectors g·∫ßn nhau**\n",
    "\n",
    "**Cosine Similarity** ƒëo ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa 2 vectors:\n",
    "\n",
    "$$\\text{similarity}(A, B) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|} \\in [-1, 1]$$\n",
    "\n",
    "- **+1**: Ho√†n to√†n gi·ªëng nhau\n",
    "- **0**: Kh√¥ng li√™n quan\n",
    "- **-1**: ƒê·ªëi l·∫≠p nhau\n",
    "\n",
    "### üìä Visualization: PCA & t-SNE\n",
    "\n",
    "Embeddings th∆∞·ªùng c√≥ dimension cao (128-768), kh√≥ visualize. Ta d√πng:\n",
    "\n",
    "1. **PCA** (Principal Component Analysis)\n",
    "   - Linear projection xu·ªëng 2D/3D\n",
    "   - Gi·ªØ ƒë∆∞·ª£c variance t·ªëi ƒëa\n",
    "   - Nhanh, ·ªïn ƒë·ªãnh\n",
    "\n",
    "2. **t-SNE** (t-Distributed Stochastic Neighbor Embedding)\n",
    "   - Non-linear projection\n",
    "   - Gi·ªØ ƒë∆∞·ª£c local structure t·ªët h∆°n\n",
    "   - Ch·∫≠m h∆°n, c√≥ random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Demo: Cosine Similarity & Semantic Space\n",
    "# ============================================\n",
    "\n",
    "class SemanticEmbeddingDemo:\n",
    "    \"\"\"\n",
    "    Demo v·ªÅ semantic properties c·ªßa embeddings\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # T·∫°o toy vocabulary v·ªõi ng·ªØ nghƒ©a r√µ r√†ng\n",
    "        self.vocab = {\n",
    "            # Animals\n",
    "            'm√®o': 0, 'ch√≥': 1, 'chu·ªôt': 2, 'voi': 3, 's∆∞_t·ª≠': 4,\n",
    "            # Fruits\n",
    "            't√°o': 5, 'cam': 6, 'chu·ªëi': 7, 'xo√†i': 8, 'd∆∞a': 9,\n",
    "            # Colors\n",
    "            'ƒë·ªè': 10, 'xanh': 11, 'v√†ng': 12, 'tr·∫Øng': 13, 'ƒëen': 14,\n",
    "        }\n",
    "        \n",
    "        # T·∫°o embeddings c√≥ c·∫•u tr√∫c\n",
    "        # Dimension: [animal_score, fruit_score, color_score, size, ...]]\n",
    "        self.embeddings = torch.zeros(len(self.vocab), 16)\n",
    "        \n",
    "        # Animals: high on dim 0\n",
    "        for word in ['m√®o', 'ch√≥', 'chu·ªôt', 'voi', 's∆∞_t·ª≠']:\n",
    "            idx = self.vocab[word]\n",
    "            self.embeddings[idx, 0] = 1.0\n",
    "            self.embeddings[idx, 1:] = torch.randn(15) * 0.1\n",
    "        \n",
    "        # Fruits: high on dim 1\n",
    "        for word in ['t√°o', 'cam', 'chu·ªëi', 'xo√†i', 'd∆∞a']:\n",
    "            idx = self.vocab[word]\n",
    "            self.embeddings[idx, 1] = 1.0\n",
    "            self.embeddings[idx, 0] = 0.0\n",
    "            self.embeddings[idx, 2:] = torch.randn(14) * 0.1\n",
    "        \n",
    "        # Colors: high on dim 2\n",
    "        for word in ['ƒë·ªè', 'xanh', 'v√†ng', 'tr·∫Øng', 'ƒëen']:\n",
    "            idx = self.vocab[word]\n",
    "            self.embeddings[idx, 2] = 1.0\n",
    "            self.embeddings[idx, :2] = 0.0\n",
    "            self.embeddings[idx, 3:] = torch.randn(13) * 0.1\n",
    "        \n",
    "        self.idx_to_word = {v: k for k, v in self.vocab.items()}\n",
    "    \n",
    "    def cosine_similarity(self, word1: str, word2: str) -> float:\n",
    "        \"\"\"T√≠nh cosine similarity gi·ªØa 2 t·ª´\"\"\"\n",
    "        idx1, idx2 = self.vocab[word1], self.vocab[word2]\n",
    "        vec1, vec2 = self.embeddings[idx1], self.embeddings[idx2]\n",
    "        return F.cosine_similarity(vec1, vec2, dim=0).item()\n",
    "    \n",
    "    def find_similar(self, word: str, top_k: int = 5) -> List[Tuple[str, float]]:\n",
    "        \"\"\"T√¨m top-k t·ª´ g·∫ßn nh·∫•t\"\"\"\n",
    "        idx = self.vocab[word]\n",
    "        query_vec = self.embeddings[idx]\n",
    "        \n",
    "        # Compute similarities v·ªõi t·∫•t c·∫£ t·ª´\n",
    "        sims = F.cosine_similarity(query_vec.unsqueeze(0), self.embeddings, dim=1)\n",
    "        \n",
    "        # Sort v√† l·∫•y top-k (b·ªè ch√≠nh n√≥)\n",
    "        top_indices = sims.argsort(descending=True)[1:top_k+1]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            word_similar = self.idx_to_word[idx.item()]\n",
    "            sim_score = sims[idx].item()\n",
    "            results.append((word_similar, sim_score))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def visualize_similarity_matrix(self):\n",
    "        \"\"\"Visualize similarity matrix cho t·∫•t c·∫£ t·ª´\"\"\"\n",
    "        n_words = len(self.vocab)\n",
    "        sim_matrix = torch.zeros(n_words, n_words)\n",
    "        \n",
    "        # Compute pairwise similarities\n",
    "        for i in range(n_words):\n",
    "            for j in range(n_words):\n",
    "                sim_matrix[i, j] = F.cosine_similarity(\n",
    "                    self.embeddings[i], self.embeddings[j], dim=0\n",
    "                )\n",
    "        \n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        \n",
    "        im = ax.imshow(sim_matrix.numpy(), cmap='RdYlGn', vmin=-1, vmax=1)\n",
    "        \n",
    "        # Set ticks\n",
    "        words = [self.idx_to_word[i] for i in range(n_words)]\n",
    "        ax.set_xticks(range(n_words))\n",
    "        ax.set_yticks(range(n_words))\n",
    "        ax.set_xticklabels(words, rotation=45, ha='right')\n",
    "        ax.set_yticklabels(words)\n",
    "        \n",
    "        # Th√™m text annotations\n",
    "        for i in range(n_words):\n",
    "            for j in range(n_words):\n",
    "                text = ax.text(j, i, f'{sim_matrix[i, j]:.2f}',\n",
    "                             ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
    "        \n",
    "        ax.set_title('üé® Cosine Similarity Matrix', fontsize=16, fontweight='bold', pad=20)\n",
    "        plt.colorbar(im, ax=ax, label='Similarity Score')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def visualize_2d(self):\n",
    "        \"\"\"Visualize embeddings trong 2D space using PCA\"\"\"\n",
    "        # PCA projection\n",
    "        pca = PCA(n_components=2)\n",
    "        embeddings_2d = pca.fit_transform(self.embeddings.numpy())\n",
    "        \n",
    "        # T·∫°o categories\n",
    "        categories = []\n",
    "        for word in self.vocab.keys():\n",
    "            if word in ['m√®o', 'ch√≥', 'chu·ªôt', 'voi', 's∆∞_t·ª≠']:\n",
    "                categories.append('Animals')\n",
    "            elif word in ['t√°o', 'cam', 'chu·ªëi', 'xo√†i', 'd∆∞a']:\n",
    "                categories.append('Fruits')\n",
    "            else:\n",
    "                categories.append('Colors')\n",
    "        \n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        # Scatter plot v·ªõi colors theo category\n",
    "        category_colors = {'Animals': '#e74c3c', 'Fruits': '#2ecc71', 'Colors': '#3498db'}\n",
    "        \n",
    "        for category, color in category_colors.items():\n",
    "            mask = [c == category for c in categories]\n",
    "            ax.scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1],\n",
    "                      c=color, label=category, s=200, alpha=0.6, edgecolors='black', linewidth=2)\n",
    "        \n",
    "        # Add labels\n",
    "        for i, word in enumerate(self.vocab.keys()):\n",
    "            ax.annotate(word, (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "                       fontsize=11, fontweight='bold', ha='center', va='bottom')\n",
    "        \n",
    "        ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        ax.set_title('üìä Embedding Space Visualization (PCA)', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        ax.legend(fontsize=12, loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Demo\n",
    "demo = SemanticEmbeddingDemo()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîç COSINE SIMILARITY DEMO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test m·ªôt v√†i pairs\n",
    "test_pairs = [\n",
    "    ('m√®o', 'ch√≥'),\n",
    "    ('m√®o', 't√°o'),\n",
    "    ('t√°o', 'cam'),\n",
    "    ('ƒë·ªè', 'xanh'),\n",
    "    ('voi', 'chu·ªëi')\n",
    "]\n",
    "\n",
    "for word1, word2 in test_pairs:\n",
    "    sim = demo.cosine_similarity(word1, word2)\n",
    "    print(f\"\\n'{word1}' ‚Üî '{word2}': {sim:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"üîé T√åM T·ª™ T∆Ø∆†NG T·ª∞\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for word in ['m√®o', 't√°o', 'ƒë·ªè']:\n",
    "    similar = demo.find_similar(word, top_k=3)\n",
    "    print(f\"\\nT·ª´ gi·ªëng '{word}' nh·∫•t:\")\n",
    "    for similar_word, score in similar:\n",
    "        print(f\"  ‚Üí {similar_word}: {score:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# Visualizations\n",
    "demo.visualize_similarity_matrix()\n",
    "demo.visualize_2d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section4'></a>\n",
    "## 4.4 Practical Experiments\n",
    "\n",
    "### üß™ Experiment 1: Train Embeddings on Toy Dataset\n",
    "\n",
    "B√¢y gi·ªù ch√∫ng ta s·∫Ω train embeddings t·ª´ ƒë·∫ßu tr√™n m·ªôt toy dataset v√† quan s√°t c√°ch ch√∫ng h·ªçc ƒë∆∞·ª£c semantic relationships!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Experiment 1: Train Embeddings\n",
    "# ============================================\n",
    "\n",
    "# T·∫°o toy dataset: Skip-gram style\n",
    "# M·ª•c ti√™u: Predict context words t·ª´ center word\n",
    "\n",
    "class SkipGramDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset cho Skip-gram model\n",
    "    M·ªói sample: (center_word, context_word)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sentences: List[List[str]], vocab: Dict[str, int], window_size: int = 2):\n",
    "        self.data = []\n",
    "        self.vocab = vocab\n",
    "        \n",
    "        # Generate training pairs\n",
    "        for sentence in sentences:\n",
    "            for i, center_word in enumerate(sentence):\n",
    "                # Get context words trong window\n",
    "                start = max(0, i - window_size)\n",
    "                end = min(len(sentence), i + window_size + 1)\n",
    "                \n",
    "                for j in range(start, end):\n",
    "                    if i != j:  # Skip center word itself\n",
    "                        context_word = sentence[j]\n",
    "                        if center_word in vocab and context_word in vocab:\n",
    "                            self.data.append((\n",
    "                                vocab[center_word],\n",
    "                                vocab[context_word]\n",
    "                            ))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        center, context = self.data[idx]\n",
    "        return torch.tensor(center), torch.tensor(context)\n",
    "\n",
    "\n",
    "class SkipGramModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple Skip-gram model ƒë·ªÉ h·ªçc embeddings\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size: int, embedding_dim: int):\n",
    "        super().__init__()\n",
    "        # Center word embeddings\n",
    "        self.center_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # Context word embeddings\n",
    "        self.context_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Initialize\n",
    "        self.center_embeddings.weight.data.uniform_(-0.5/embedding_dim, 0.5/embedding_dim)\n",
    "        self.context_embeddings.weight.data.zero_()\n",
    "    \n",
    "    def forward(self, center_words, context_words):\n",
    "        # Get embeddings\n",
    "        center_embeds = self.center_embeddings(center_words)  # (batch, embed_dim)\n",
    "        context_embeds = self.context_embeddings(context_words)  # (batch, embed_dim)\n",
    "        \n",
    "        # Dot product\n",
    "        scores = (center_embeds * context_embeds).sum(dim=1)  # (batch,)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def get_embeddings(self):\n",
    "        \"\"\"Return final embeddings (center + context)\"\"\"\n",
    "        return (self.center_embeddings.weight + self.context_embeddings.weight) / 2\n",
    "\n",
    "\n",
    "def train_embeddings(embedding_dim: int = 50, epochs: int = 100):\n",
    "    \"\"\"\n",
    "    Train embeddings tr√™n toy corpus\n",
    "    \"\"\"\n",
    "    \n",
    "    # Toy corpus v·ªÅ ƒë·ªông v·∫≠t v√† tr√°i c√¢y\n",
    "    sentences = [\n",
    "        ['m√®o', 'v√†', 'ch√≥', 'l√†', 'ƒë·ªông_v·∫≠t'],\n",
    "        ['ch√≥', 'th√≠ch', 'ch∆°i', 'v·ªõi', 'm√®o'],\n",
    "        ['t√°o', 'v√†', 'cam', 'l√†', 'tr√°i_c√¢y'],\n",
    "        ['t√¥i', 'th√≠ch', 'ƒÉn', 't√°o', 'v√†', 'cam'],\n",
    "        ['ƒë·ªông_v·∫≠t', 'nh∆∞', 'm√®o', 'ch√≥', 'r·∫•t', 'd·ªÖ_th∆∞∆°ng'],\n",
    "        ['tr√°i_c√¢y', 'nh∆∞', 't√°o', 'cam', 'r·∫•t', 'ngon'],\n",
    "        ['m√®o', 'th√≠ch', 'ƒÉn', 'c√°'],\n",
    "        ['ch√≥', 'th√≠ch', 'ƒÉn', 'th·ªãt'],\n",
    "        ['t√°o', 'm√†u', 'ƒë·ªè', 'r·∫•t', 'ngon'],\n",
    "        ['cam', 'm√†u', 'cam', 'r·∫•t', 't∆∞∆°i'],\n",
    "    ] * 5  # Repeat ƒë·ªÉ c√≥ ƒë·ªß data\n",
    "    \n",
    "    # Build vocabulary\n",
    "    all_words = [word for sent in sentences for word in sent]\n",
    "    word_counts = Counter(all_words)\n",
    "    vocab = {word: i for i, (word, _) in enumerate(word_counts.most_common())}\n",
    "    idx_to_word = {i: word for word, i in vocab.items()}\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"üöÄ TRAINING EMBEDDINGS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nVocabulary size: {len(vocab)}\")\n",
    "    print(f\"Embedding dimension: {embedding_dim}\")\n",
    "    print(f\"Number of sentences: {len(sentences)}\")\n",
    "    print(f\"\\nVocabulary: {list(vocab.keys())[:10]}...\")\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = SkipGramDataset(sentences, vocab, window_size=2)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    print(f\"\\nTraining pairs: {len(dataset)}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = SkipGramModel(len(vocab), embedding_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.025)\n",
    "    \n",
    "    # Training loop\n",
    "    losses = []\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"Training progress:\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        \n",
    "        for center, context in dataloader:\n",
    "            center, context = center.to(device), context.to(device)\n",
    "            \n",
    "            # Forward\n",
    "            scores = model(center, context)\n",
    "            \n",
    "            # Negative sampling loss (simplified)\n",
    "            # Positive pairs should have high scores\n",
    "            loss = -F.logsigmoid(scores).mean()\n",
    "            \n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        losses.append(avg_loss)\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch {epoch+1:3d}/{epochs} | Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    print(\"-\"*70)\n",
    "    print(\"‚úÖ Training completed!\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Plot loss curve\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses, linewidth=2, color='#3498db')\n",
    "    plt.xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Loss', fontsize=12, fontweight='bold')\n",
    "    plt.title('üìâ Training Loss Curve', fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return model, vocab, idx_to_word\n",
    "\n",
    "# Train model\n",
    "model, vocab, idx_to_word = train_embeddings(embedding_dim=50, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Visualize learned embeddings\n",
    "# ============================================\n",
    "\n",
    "def visualize_learned_embeddings(model, vocab, idx_to_word):\n",
    "    \"\"\"\n",
    "    Visualize embeddings ƒë√£ h·ªçc ƒë∆∞·ª£c\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get embeddings\n",
    "    embeddings = model.get_embeddings().detach().cpu().numpy()\n",
    "    \n",
    "    # Compute similarity matrix\n",
    "    n_words = len(vocab)\n",
    "    sim_matrix = np.zeros((n_words, n_words))\n",
    "    \n",
    "    for i in range(n_words):\n",
    "        for j in range(n_words):\n",
    "            sim_matrix[i, j] = np.dot(embeddings[i], embeddings[j]) / (\n",
    "                np.linalg.norm(embeddings[i]) * np.linalg.norm(embeddings[j])\n",
    "            )\n",
    "    \n",
    "    # 1. Similarity matrix\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "    \n",
    "    words = [idx_to_word[i] for i in range(min(15, n_words))]  # Top 15 words\n",
    "    sim_subset = sim_matrix[:len(words), :len(words)]\n",
    "    \n",
    "    im = axes[0].imshow(sim_subset, cmap='RdYlGn', vmin=-1, vmax=1)\n",
    "    axes[0].set_xticks(range(len(words)))\n",
    "    axes[0].set_yticks(range(len(words)))\n",
    "    axes[0].set_xticklabels(words, rotation=45, ha='right')\n",
    "    axes[0].set_yticklabels(words)\n",
    "    axes[0].set_title('üé® Learned Similarity Matrix', fontsize=14, fontweight='bold')\n",
    "    plt.colorbar(im, ax=axes[0])\n",
    "    \n",
    "    # 2. PCA visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    embeddings_2d = pca.fit_transform(embeddings)\n",
    "    \n",
    "    # Plot all words\n",
    "    axes[1].scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], \n",
    "                   s=100, alpha=0.6, c='steelblue', edgecolors='black')\n",
    "    \n",
    "    # Add labels\n",
    "    for i, word in idx_to_word.items():\n",
    "        axes[1].annotate(word, (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "                        fontsize=10, ha='center', va='bottom')\n",
    "    \n",
    "    axes[1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)', \n",
    "                      fontsize=11, fontweight='bold')\n",
    "    axes[1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)', \n",
    "                      fontsize=11, fontweight='bold')\n",
    "    axes[1].set_title('üìä Embedding Space (PCA)', fontsize=14, fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Find similar words\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üîç SIMILAR WORDS (learned from context)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    test_words = ['m√®o', 'ch√≥', 't√°o', 'cam']\n",
    "    \n",
    "    for word in test_words:\n",
    "        if word in vocab:\n",
    "            word_idx = vocab[word]\n",
    "            word_vec = embeddings[word_idx]\n",
    "            \n",
    "            # Compute similarities\n",
    "            sims = []\n",
    "            for i in range(n_words):\n",
    "                if i != word_idx:\n",
    "                    sim = np.dot(word_vec, embeddings[i]) / (\n",
    "                        np.linalg.norm(word_vec) * np.linalg.norm(embeddings[i])\n",
    "                    )\n",
    "                    sims.append((idx_to_word[i], sim))\n",
    "            \n",
    "            sims.sort(key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            print(f\"\\n'{word}' ‚Üí Similar words:\")\n",
    "            for similar_word, sim_score in sims[:5]:\n",
    "                print(f\"  {similar_word}: {sim_score:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "visualize_learned_embeddings(model, vocab, idx_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ Experiment 2: Compare Different Embedding Dimensions\n",
    "\n",
    "B√¢y gi·ªù h√£y so s√°nh performance v·ªõi c√°c embedding dimensions kh√°c nhau!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Experiment 2: Compare Embedding Dimensions\n",
    "# ============================================\n",
    "\n",
    "def compare_embedding_dimensions():\n",
    "    \"\"\"\n",
    "    Train v√† so s√°nh models v·ªõi embedding dimensions kh√°c nhau\n",
    "    \"\"\"\n",
    "    \n",
    "    dimensions = [8, 16, 32, 64, 128]\n",
    "    results = {}\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"üî¨ EXPERIMENT: Comparing Embedding Dimensions\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    for dim in dimensions:\n",
    "        print(f\"Training with dimension = {dim}...\")\n",
    "        model, vocab, idx_to_word = train_embeddings(embedding_dim=dim, epochs=50)\n",
    "        \n",
    "        # Get embeddings\n",
    "        embeddings = model.get_embeddings().detach().cpu().numpy()\n",
    "        \n",
    "        # Compute average pairwise similarity\n",
    "        n = len(vocab)\n",
    "        total_sim = 0\n",
    "        count = 0\n",
    "        \n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                sim = np.dot(embeddings[i], embeddings[j]) / (\n",
    "                    np.linalg.norm(embeddings[i]) * np.linalg.norm(embeddings[j])\n",
    "                )\n",
    "                total_sim += sim\n",
    "                count += 1\n",
    "        \n",
    "        avg_sim = total_sim / count\n",
    "        \n",
    "        # Compute variance (information capacity)\n",
    "        variance = np.var(embeddings)\n",
    "        \n",
    "        results[dim] = {\n",
    "            'avg_similarity': avg_sim,\n",
    "            'variance': variance,\n",
    "            'embeddings': embeddings\n",
    "        }\n",
    "        \n",
    "        print(f\"  ‚Üí Avg similarity: {avg_sim:.4f}\")\n",
    "        print(f\"  ‚Üí Variance: {variance:.4f}\\n\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # 1. Average similarity\n",
    "    avg_sims = [results[d]['avg_similarity'] for d in dimensions]\n",
    "    axes[0, 0].plot(dimensions, avg_sims, 'o-', linewidth=3, markersize=10, color='#3498db')\n",
    "    axes[0, 0].set_xlabel('Embedding Dimension', fontsize=11, fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('Average Similarity', fontsize=11, fontweight='bold')\n",
    "    axes[0, 0].set_title('üìä Semantic Coherence', fontsize=13, fontweight='bold')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].set_xscale('log', base=2)\n",
    "    \n",
    "    # 2. Variance (capacity)\n",
    "    variances = [results[d]['variance'] for d in dimensions]\n",
    "    axes[0, 1].plot(dimensions, variances, 's-', linewidth=3, markersize=10, color='#2ecc71')\n",
    "    axes[0, 1].set_xlabel('Embedding Dimension', fontsize=11, fontweight='bold')\n",
    "    axes[0, 1].set_ylabel('Variance', fontsize=11, fontweight='bold')\n",
    "    axes[0, 1].set_title('üß† Information Capacity', fontsize=13, fontweight='bold')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].set_xscale('log', base=2)\n",
    "    \n",
    "    # 3. Embedding distribution (small dim)\n",
    "    small_dim = dimensions[0]\n",
    "    axes[1, 0].hist(results[small_dim]['embeddings'].flatten(), bins=50, \n",
    "                   color='#e74c3c', alpha=0.7, edgecolor='black')\n",
    "    axes[1, 0].set_xlabel('Value', fontsize=11)\n",
    "    axes[1, 0].set_ylabel('Frequency', fontsize=11)\n",
    "    axes[1, 0].set_title(f'üìà Distribution (dim={small_dim})', \n",
    "                        fontsize=13, fontweight='bold')\n",
    "    axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 4. Embedding distribution (large dim)\n",
    "    large_dim = dimensions[-1]\n",
    "    axes[1, 1].hist(results[large_dim]['embeddings'].flatten(), bins=50, \n",
    "                   color='#9b59b6', alpha=0.7, edgecolor='black')\n",
    "    axes[1, 1].set_xlabel('Value', fontsize=11)\n",
    "    axes[1, 1].set_ylabel('Frequency', fontsize=11)\n",
    "    axes[1, 1].set_title(f'üìà Distribution (dim={large_dim})', \n",
    "                        fontsize=13, fontweight='bold')\n",
    "    axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä SUMMARY: Embedding Dimension Comparison\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n{'Dimension':<12} {'Avg Similarity':<18} {'Variance':<15} {'Recommendation'}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    for dim in dimensions:\n",
    "        sim = results[dim]['avg_similarity']\n",
    "        var = results[dim]['variance']\n",
    "        \n",
    "        if dim <= 16:\n",
    "            rec = \"Too small, low capacity\"\n",
    "        elif dim <= 64:\n",
    "            rec = \"‚úÖ Good balance\"\n",
    "        else:\n",
    "            rec = \"High capacity, may overfit\"\n",
    "        \n",
    "        print(f\"{dim:<12} {sim:<18.4f} {var:<15.4f} {rec}\")\n",
    "    \n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "compare_embedding_dimensions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ T·ªïng K·∫øt\n",
    "\n",
    "### ‚úÖ Nh·ªØng g√¨ b·∫°n ƒë√£ h·ªçc ƒë∆∞·ª£c:\n",
    "\n",
    "1. **One-Hot vs Embedding**\n",
    "   - One-hot: Sparse, kh√¥ng c√≥ semantic meaning\n",
    "   - Embedding: Dense, h·ªçc ƒë∆∞·ª£c relationships\n",
    "   - Trade-off v·ªÅ dimension: capacity vs efficiency\n",
    "\n",
    "2. **Implementation Details**\n",
    "   - Embedding = lookup table\n",
    "   - Gradient ch·ªâ flow qua used tokens\n",
    "   - Padding & masking\n",
    "\n",
    "3. **Embedding Properties**\n",
    "   - Cosine similarity ƒëo semantic closeness\n",
    "   - PCA/t-SNE ƒë·ªÉ visualize\n",
    "   - Similar words ‚Üí close vectors\n",
    "\n",
    "4. **Training Embeddings**\n",
    "   - Skip-gram: predict context from center\n",
    "   - Embeddings h·ªçc ƒë∆∞·ª£c t·ª´ data\n",
    "   - Dimension size impacts performance\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "\n",
    "- Th·ª≠ v·ªõi corpus l·ªõn h∆°n (Wikipedia, news)\n",
    "- Implement CBOW (continuous bag of words)\n",
    "- Pre-trained embeddings (Word2Vec, GloVe, FastText)\n",
    "- Contextual embeddings (BERT, GPT)\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Key Takeaways\n",
    "\n",
    "1. **Embeddings are fundamental** to modern NLP\n",
    "2. **Dimension size** l√† trade-off gi·ªØa capacity v√† efficiency\n",
    "3. **Training data quality** quan tr·ªçng h∆°n model complexity\n",
    "4. **Visualization** gi√∫p understand learned representations\n",
    "\n",
    "---\n",
    "\n",
    "## üìö T√†i li·ªáu tham kh·∫£o\n",
    "\n",
    "- [Word2Vec paper](https://arxiv.org/abs/1301.3781)\n",
    "- [GloVe paper](https://nlp.stanford.edu/pubs/glove.pdf)\n",
    "- [PyTorch Embedding docs](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
    "\n",
    "**Ch√∫c b·∫°n h·ªçc t·∫≠p vui v·∫ª! üéâ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
