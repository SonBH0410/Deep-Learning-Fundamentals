{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìï PYTORCH FILE 3-B: TRANSFER LEARNING & MIXED PRECISION\n",
    "\n",
    "**Ph·∫ßn:** ADVANCED & PROFESSIONAL\n",
    "\n",
    "**M·ª•c ti√™u:**\n",
    "- ‚úÖ Hi·ªÉu v√† √°p d·ª•ng Transfer Learning\n",
    "- ‚úÖ Fine-tuning strategies\n",
    "- ‚úÖ S·ª≠ d·ª•ng pretrained models (ResNet, MobileNet, EfficientNet)\n",
    "- ‚úÖ Mixed Precision Training v·ªõi PyTorch\n",
    "- ‚úÖ Performance optimization\n",
    "\n",
    "**Th·ªùi l∆∞·ª£ng:** 2-3 tu·∫ßn\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö M·ª•c L·ª•c\n",
    "\n",
    "### PH·∫¶N 1: TRANSFER LEARNING\n",
    "1. Transfer Learning l√† g√¨?\n",
    "2. Pretrained Models trong PyTorch\n",
    "3. Feature Extraction\n",
    "4. Fine-tuning\n",
    "5. Best Practices\n",
    "\n",
    "### PH·∫¶N 2: PRETRAINED MODELS\n",
    "1. torchvision.models\n",
    "2. ResNet\n",
    "3. MobileNet\n",
    "4. EfficientNet\n",
    "5. Model Zoo\n",
    "\n",
    "### PH·∫¶N 3: MIXED PRECISION TRAINING\n",
    "1. Mixed Precision l√† g√¨?\n",
    "2. Automatic Mixed Precision (AMP)\n",
    "3. GradScaler\n",
    "4. Performance Comparison\n",
    "5. Best Practices\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ Torchvision version: {torchvision.__version__}\")\n",
    "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"‚úÖ Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PH·∫¶N 1: TRANSFER LEARNING\n",
    "\n",
    "## 1.1 Transfer Learning l√† g√¨?\n",
    "\n",
    "### ƒê·ªãnh nghƒ©a\n",
    "\n",
    "**Transfer Learning** = S·ª≠ d·ª•ng ki·∫øn th·ª©c t·ª´ model ƒë√£ ƒë∆∞·ª£c train tr√™n dataset l·ªõn (ImageNet) cho task m·ªõi\n",
    "\n",
    "### T·∫°i sao d√πng Transfer Learning?\n",
    "\n",
    "| V·∫•n ƒë·ªÅ | Gi·∫£i ph√°p |\n",
    "|--------|------------|\n",
    "| üìä √çt d·ªØ li·ªáu | Pre-trained weights t·ª´ ImageNet (1.4M ·∫£nh) |\n",
    "| ‚è±Ô∏è T·ªën th·ªùi gian | Kh√¥ng c·∫ßn train t·ª´ ƒë·∫ßu |\n",
    "| üí∞ T·ªën t√†i nguy√™n | Ch·ªâ fine-tune m·ªôt ph·∫ßn |\n",
    "| üéØ Hi·ªáu qu·∫£ cao | ƒê·∫°t accuracy cao v·ªõi √≠t data |\n",
    "\n",
    "### Hai chi·∫øn l∆∞·ª£c ch√≠nh\n",
    "\n",
    "#### 1. Feature Extraction\n",
    "```\n",
    "Pretrained Model (FROZEN) ‚Üí New Classifier (TRAINABLE)\n",
    "```\n",
    "- Freeze to√†n b·ªô pretrained layers\n",
    "- Ch·ªâ train classifier m·ªõi\n",
    "- Nhanh, √≠t data\n",
    "\n",
    "#### 2. Fine-tuning\n",
    "```\n",
    "Pretrained Model (PARTIALLY FROZEN) ‚Üí New Classifier (TRAINABLE)\n",
    "```\n",
    "- Unfreeze m·ªôt s·ªë layers cu·ªëi\n",
    "- Train v·ªõi learning rate nh·ªè\n",
    "- Ch·∫≠m h∆°n nh∆∞ng accuracy t·ªët h∆°n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Pretrained Models trong PyTorch\n",
    "\n",
    "### torchvision.models\n",
    "\n",
    "PyTorch cung c·∫•p nhi·ªÅu pretrained models qua `torchvision.models`:\n",
    "\n",
    "| Model | Parameters | Top-1 Acc | Khi n√†o d√πng |\n",
    "|-------|-----------|-----------|---------------|\n",
    "| **ResNet-50** | 25.6M | 76.1% | C√¢n b·∫±ng accuracy/speed |\n",
    "| **ResNet-101** | 44.5M | 77.4% | C·∫ßn accuracy cao |\n",
    "| **MobileNet-V2** | 3.5M | 71.9% | Mobile, edge devices |\n",
    "| **EfficientNet-B0** | 5.3M | 77.7% | Best accuracy/size ratio |\n",
    "| **VGG-16** | 138M | 71.6% | ƒê∆°n gi·∫£n, d·ªÖ hi·ªÉu |\n",
    "\n",
    "### Khuy·∫øn ngh·ªã\n",
    "\n",
    "- üöÄ **Production/Mobile**: MobileNetV2, EfficientNet\n",
    "- üéØ **High Accuracy**: ResNet-50/101, EfficientNet\n",
    "- üìö **Learning**: ResNet-18, MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained models\n",
    "\n",
    "print(\"üì¶ Loading pretrained models...\\n\")\n",
    "\n",
    "# ResNet-18 (small, fast)\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "print(f\"ResNet-18:\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in resnet18.parameters()):,}\")\n",
    "print()\n",
    "\n",
    "# ResNet-50 (popular)\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "print(f\"ResNet-50:\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in resnet50.parameters()):,}\")\n",
    "print()\n",
    "\n",
    "# MobileNetV2 (mobile)\n",
    "mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "print(f\"MobileNetV2:\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in mobilenet.parameters()):,}\")\n",
    "print()\n",
    "\n",
    "print(\"‚úÖ Models loaded with ImageNet weights!\")\n",
    "print(\"\\nüí° Note: pretrained=True downloads weights t·ª´ internet (first time)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Feature Extraction - Strategy 1\n",
    "\n",
    "### Workflow\n",
    "\n",
    "```python\n",
    "1. Load pretrained model\n",
    "2. Freeze all layers (requires_grad=False)\n",
    "3. Replace final classifier\n",
    "4. Train only new classifier\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Feature Extraction v·ªõi ResNet-18\n",
    "\n",
    "# Load pretrained ResNet-18\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Step 1: Freeze ALL layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(\"‚ùÑÔ∏è  Frozen all layers\")\n",
    "\n",
    "# Step 2: Replace final classifier\n",
    "# ResNet-18 original: fc (512 ‚Üí 1000 classes)\n",
    "# Our task: Binary classification (2 classes)\n",
    "\n",
    "num_features = model.fc.in_features\n",
    "print(f\"\\nüìä Original classifier: {num_features} ‚Üí 1000 (ImageNet)\")\n",
    "\n",
    "# New classifier\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256, 2)  # 2 classes\n",
    ")\n",
    "\n",
    "print(f\"üìä New classifier: {num_features} ‚Üí 256 ‚Üí 2 (our task)\")\n",
    "\n",
    "# Move to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Check trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f\"\\nüìä PARAMETERS:\")\n",
    "print(f\"   Total: {total_params:,}\")\n",
    "print(f\"   Trainable: {trainable_params:,} ({trainable_params/total_params*100:.2f}%)\")\n",
    "print(f\"   Frozen: {total_params - trainable_params:,}\")\n",
    "\n",
    "print(\"\\n‚úÖ Feature Extraction model ready!\")\n",
    "print(\"   - Ch·ªâ train classifier m·ªõi (~0.5% parameters)\")\n",
    "print(\"   - Training r·∫•t nhanh!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for feature extraction\n",
    "\n",
    "def train_feature_extraction(model, train_loader, epochs=10):\n",
    "    \"\"\"\n",
    "    Train only the classifier (feature extraction)\n",
    "    \"\"\"\n",
    "    # Optimizer ch·ªâ cho trainable parameters\n",
    "    optimizer = optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=0.001\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.train()\n",
    "    history = {'loss': [], 'accuracy': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n",
    "        for inputs, labels in pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{running_loss/(pbar.n+1):.4f}',\n",
    "                'acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        history['loss'].append(epoch_loss)\n",
    "        history['accuracy'].append(epoch_acc)\n",
    "    \n",
    "    return history\n",
    "\n",
    "print(\"‚úÖ Training function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Fine-tuning - Strategy 2\n",
    "\n",
    "### Workflow\n",
    "\n",
    "```python\n",
    "1. Start with feature extraction\n",
    "2. Train classifier first\n",
    "3. Unfreeze some layers\n",
    "4. Fine-tune with SMALL learning rate\n",
    "```\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "- ‚ö†Ô∏è **CRITICAL**: Learning rate ph·∫£i R·∫§T NH·ªé (1e-5)\n",
    "- ‚úÖ Unfreeze t·ª´ t·ª´ (layer-by-layer)\n",
    "- ‚úÖ Train classifier tr∆∞·ªõc\n",
    "- ‚úÖ Different LR cho different layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning example\n",
    "\n",
    "# Load model (assume ƒë√£ train classifier)\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all first\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace classifier\n",
    "num_features = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_features, 2)\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "print(\"Step 1: Feature extraction (train classifier)\")\n",
    "print(\"   ... (assume done) ...\\n\")\n",
    "\n",
    "# Step 2: Unfreeze last few layers for fine-tuning\n",
    "print(\"Step 2: Unfreeze layers for fine-tuning\")\n",
    "\n",
    "# Unfreeze layer4 (last conv block) and fc\n",
    "for param in model_ft.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model_ft.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Count trainable params\n",
    "trainable_params = sum(p.numel() for p in model_ft.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model_ft.parameters())\n",
    "\n",
    "print(f\"   Trainable: {trainable_params:,} ({trainable_params/total_params*100:.2f}%)\")\n",
    "print()\n",
    "\n",
    "# Step 3: Different learning rates for different layers\n",
    "print(\"Step 3: Setup optimizer with different LRs\")\n",
    "\n",
    "optimizer_ft = optim.Adam([\n",
    "    {'params': model_ft.layer4.parameters(), 'lr': 1e-5},  # Very small LR for pretrained\n",
    "    {'params': model_ft.fc.parameters(), 'lr': 1e-4}       # Larger LR for new layers\n",
    "])\n",
    "\n",
    "print(\"   layer4 (pretrained): LR = 1e-5 (SMALL!)\")\n",
    "print(\"   fc (new): LR = 1e-4\")\n",
    "print()\n",
    "\n",
    "print(\"‚úÖ Fine-tuning setup complete!\")\n",
    "print(\"\\n‚ö†Ô∏è  CRITICAL:\")\n",
    "print(\"   - LR cho pretrained layers PH·∫¢I R·∫§T NH·ªé (1e-5)\")\n",
    "print(\"   - N·∫øu qu√° l·ªõn ‚Üí destroy pretrained weights!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Comparison: Feature Extraction vs Fine-tuning\n",
    "\n",
    "### Feature Extraction\n",
    "\n",
    "**∆Øu ƒëi·ªÉm:**\n",
    "- ‚úÖ Nhanh (ch·ªâ train <1% parameters)\n",
    "- ‚úÖ √çt data v·∫´n ok\n",
    "- ‚úÖ √çt overfit\n",
    "- ‚úÖ ƒê∆°n gi·∫£n\n",
    "\n",
    "**Nh∆∞·ª£c ƒëi·ªÉm:**\n",
    "- ‚ùå Accuracy c√≥ th·ªÉ kh√¥ng t·ªëi ∆∞u\n",
    "- ‚ùå Kh√¥ng adapt ƒë∆∞·ª£c v·ªõi dataset kh√°c bi·ªát\n",
    "\n",
    "### Fine-tuning\n",
    "\n",
    "**∆Øu ƒëi·ªÉm:**\n",
    "- ‚úÖ Accuracy cao h∆°n\n",
    "- ‚úÖ Adapt t·ªët v·ªõi dataset m·ªõi\n",
    "- ‚úÖ Flexible\n",
    "\n",
    "**Nh∆∞·ª£c ƒëi·ªÉm:**\n",
    "- ‚ùå Ch·∫≠m h∆°n\n",
    "- ‚ùå C·∫ßn nhi·ªÅu data h∆°n (>5k images)\n",
    "- ‚ùå D·ªÖ overfit\n",
    "- ‚ùå Kh√≥ tune (learning rate critical!)\n",
    "\n",
    "### Recommendation\n",
    "\n",
    "```\n",
    "if data < 1000:\n",
    "    use Feature Extraction\n",
    "elif data < 5000:\n",
    "    try Feature Extraction first, then Fine-tuning if needed\n",
    "else:\n",
    "    use Fine-tuning\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PH·∫¶N 2: PRETRAINED MODELS DEEP DIVE\n",
    "\n",
    "## 2.1 ResNet Architecture\n",
    "\n",
    "### ResNet l√† g√¨?\n",
    "\n",
    "**ResNet (Residual Network)** = Deep network v·ªõi skip connections\n",
    "\n",
    "Key innovation:\n",
    "```\n",
    "out = F(x) + x  # Skip connection!\n",
    "```\n",
    "\n",
    "### Variants\n",
    "\n",
    "- **ResNet-18**: 18 layers\n",
    "- **ResNet-34**: 34 layers\n",
    "- **ResNet-50**: 50 layers (popular)\n",
    "- **ResNet-101**: 101 layers\n",
    "- **ResNet-152**: 152 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect ResNet architecture\n",
    "\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "print(\"üì¶ ResNet-50 Architecture:\\n\")\n",
    "print(resnet)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Key components\n",
    "print(\"\\nüìö Key Components:\")\n",
    "print(f\"   conv1: Initial 7x7 conv\")\n",
    "print(f\"   layer1-4: Residual blocks\")\n",
    "print(f\"   avgpool: Global average pooling\")\n",
    "print(f\"   fc: Final classifier (512 ‚Üí 1000)\")\n",
    "\n",
    "# Modify for custom task\n",
    "print(\"\\nüîß Modify for custom task (10 classes):\")\n",
    "num_features = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_features, 10)\n",
    "print(f\"   Changed fc: {num_features} ‚Üí 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 MobileNet - Efficient Architecture\n",
    "\n",
    "### MobileNet l√† g√¨?\n",
    "\n",
    "**MobileNet** = Lightweight architecture cho mobile/edge devices\n",
    "\n",
    "Key innovation:\n",
    "- **Depthwise Separable Convolutions**\n",
    "- Much smaller than ResNet\n",
    "- Faster inference\n",
    "\n",
    "### When to use?\n",
    "\n",
    "- ‚úÖ Mobile deployment\n",
    "- ‚úÖ Real-time applications\n",
    "- ‚úÖ Limited compute resources\n",
    "- ‚úÖ Edge devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNetV2 example\n",
    "\n",
    "mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "print(\"üì¶ MobileNetV2 Architecture:\\n\")\n",
    "\n",
    "# Check size\n",
    "total_params = sum(p.numel() for p in mobilenet.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Size: ~{total_params * 4 / (1024**2):.1f} MB (FP32)\")\n",
    "\n",
    "# Modify classifier\n",
    "print(\"\\nüîß Modify for custom task:\")\n",
    "# MobileNetV2 has different structure\n",
    "mobilenet.classifier[1] = nn.Linear(mobilenet.classifier[1].in_features, 10)\n",
    "print(\"   Changed classifier for 10 classes\")\n",
    "\n",
    "print(\"\\n‚úÖ MobileNetV2 ready!\")\n",
    "print(\"   3.5M params vs 25.6M (ResNet-50)\")\n",
    "print(\"   ~7x smaller!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PH·∫¶N 3: MIXED PRECISION TRAINING\n",
    "\n",
    "## 3.1 Mixed Precision l√† g√¨?\n",
    "\n",
    "### ƒê·ªãnh nghƒ©a\n",
    "\n",
    "**Mixed Precision** = Training v·ªõi FP16 + FP32\n",
    "\n",
    "```\n",
    "Forward pass:  FP16 (faster)\n",
    "     ‚Üì\n",
    "Loss:          FP16\n",
    "     ‚Üì\n",
    "Backward:      FP16 (t√≠nh gradient)\n",
    "     ‚Üì\n",
    "Update weights: FP32 (precise)\n",
    "```\n",
    "\n",
    "### L·ª£i √≠ch\n",
    "\n",
    "| Benefit | Explanation |\n",
    "|---------|-------------|\n",
    "| üöÄ **2-3x faster** | FP16 operations faster on modern GPUs |\n",
    "| üíæ **50% memory** | FP16 = half size of FP32 |\n",
    "| üìä **Larger batch** | More memory ‚Üí larger batch size |\n",
    "| ‚úÖ **Same accuracy** | With proper scaling |\n",
    "\n",
    "### Khi n√†o d√πng?\n",
    "\n",
    "‚úÖ **N√äN D√ôNG khi:**\n",
    "- GPU h·ªó tr·ª£ Tensor Cores (V100, A100, RTX 20xx+)\n",
    "- Model l·ªõn, t·ªën memory\n",
    "- C·∫ßn tƒÉng t·ªëc training\n",
    "\n",
    "‚ùå **KH√îNG C·∫¶N khi:**\n",
    "- Ch·ªâ c√≥ CPU\n",
    "- GPU c≈© (kh√¥ng h·ªó tr·ª£ FP16 t·ªët)\n",
    "- Model nh·ªè, train nhanh r·ªìi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Automatic Mixed Precision (AMP) trong PyTorch\n",
    "\n",
    "### torch.cuda.amp\n",
    "\n",
    "PyTorch cung c·∫•p AMP qua `torch.cuda.amp`:\n",
    "\n",
    "- **autocast**: T·ª± ƒë·ªông cast operations sang FP16\n",
    "- **GradScaler**: Scale gradients ƒë·ªÉ tr√°nh underflow\n",
    "\n",
    "### Usage\n",
    "\n",
    "```python\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "for inputs, targets in loader:\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward with autocast\n",
    "    with autocast():\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "    \n",
    "    # Backward with scaling\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Training v·ªõi Mixed Precision\n",
    "\n",
    "def train_with_amp(model, train_loader, epochs=5, use_amp=True):\n",
    "    \"\"\"\n",
    "    Training v·ªõi Automatic Mixed Precision\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        train_loader: DataLoader\n",
    "        epochs: Number of epochs\n",
    "        use_amp: Enable AMP or not\n",
    "    \"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # GradScaler for AMP\n",
    "    scaler = GradScaler() if use_amp else None\n",
    "    \n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if use_amp:\n",
    "                # Mixed Precision\n",
    "                with autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                \n",
    "                # Scaled backward\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                # Normal FP32\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    return elapsed_time\n",
    "\n",
    "print(\"‚úÖ Training function with AMP defined!\")\n",
    "print(\"\\nüí° Key points:\")\n",
    "print(\"   1. autocast(): T·ª± ƒë·ªông FP16 cho forward pass\")\n",
    "print(\"   2. GradScaler: Scale gradients ƒë·ªÉ tr√°nh underflow\")\n",
    "print(\"   3. scaler.step(): Update weights v·ªõi unscaling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark: FP32 vs Mixed Precision\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"üîÑ Benchmarking FP32 vs Mixed Precision...\\n\")\n",
    "    \n",
    "    # Create fake data\n",
    "    fake_data = torch.randn(1000, 3, 224, 224)\n",
    "    fake_labels = torch.randint(0, 10, (1000,))\n",
    "    fake_dataset = torch.utils.data.TensorDataset(fake_data, fake_labels)\n",
    "    fake_loader = DataLoader(fake_dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Model\n",
    "    model_fp32 = models.resnet18(pretrained=False, num_classes=10).to(device)\n",
    "    model_amp = models.resnet18(pretrained=False, num_classes=10).to(device)\n",
    "    \n",
    "    # Train FP32\n",
    "    print(\"Training with FP32...\")\n",
    "    time_fp32 = train_with_amp(model_fp32, fake_loader, epochs=3, use_amp=False)\n",
    "    \n",
    "    print(\"\\nTraining with Mixed Precision...\")\n",
    "    time_amp = train_with_amp(model_amp, fake_loader, epochs=3, use_amp=True)\n",
    "    \n",
    "    # Results\n",
    "    speedup = time_fp32 / time_amp\n",
    "    \n",
    "    print(\"\\nüìä RESULTS:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"FP32 time:           {time_fp32:.2f}s\")\n",
    "    print(f\"Mixed Precision time: {time_amp:.2f}s\")\n",
    "    print(f\"Speedup:             {speedup:.2f}x\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if speedup > 1.3:\n",
    "        print(f\"\\n‚úÖ Mixed Precision is {speedup:.2f}x faster!\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  Speedup not significant (GPU may not support FP16 well)\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  CUDA not available. Mixed Precision requires GPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Best Practices cho Mixed Precision\n",
    "\n",
    "### ‚úÖ DO (N√äN L√ÄM)\n",
    "\n",
    "#### 1. D√πng autocast context\n",
    "```python\n",
    "# ‚úÖ GOOD\n",
    "with autocast():\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "```\n",
    "\n",
    "#### 2. D√πng GradScaler\n",
    "```python\n",
    "# ‚úÖ GOOD\n",
    "scaler = GradScaler()\n",
    "scaler.scale(loss).backward()\n",
    "scaler.step(optimizer)\n",
    "scaler.update()\n",
    "```\n",
    "\n",
    "#### 3. Gradient clipping v·ªõi scaler\n",
    "```python\n",
    "# ‚úÖ GOOD\n",
    "scaler.scale(loss).backward()\n",
    "scaler.unscale_(optimizer)  # Unscale tr∆∞·ªõc khi clip\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "scaler.step(optimizer)\n",
    "scaler.update()\n",
    "```\n",
    "\n",
    "### ‚ùå DON'T (KH√îNG N√äN)\n",
    "\n",
    "#### 1. Qu√™n GradScaler\n",
    "```python\n",
    "# ‚ùå WRONG: autocast without scaler\n",
    "with autocast():\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "loss.backward()  # Gradient underflow!\n",
    "```\n",
    "\n",
    "#### 2. Clip gradient kh√¥ng ƒë√∫ng c√°ch\n",
    "```python\n",
    "# ‚ùå WRONG: Clip tr∆∞·ªõc unscale\n",
    "scaler.scale(loss).backward()\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Wrong!\n",
    "scaler.step(optimizer)\n",
    "```\n",
    "\n",
    "### üéØ Checklist\n",
    "\n",
    "- [ ] GPU h·ªó tr·ª£ FP16 (check compute capability)\n",
    "- [ ] D√πng `autocast()` cho forward pass\n",
    "- [ ] D√πng `GradScaler` cho backward\n",
    "- [ ] Unscale tr∆∞·ªõc khi gradient clipping\n",
    "- [ ] Verify accuracy kh√¥ng gi·∫£m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéì T·ªïng k·∫øt FILE 3-B\n",
    "\n",
    "## ‚úÖ Nh·ªØng g√¨ ƒë√£ h·ªçc\n",
    "\n",
    "### 1. Transfer Learning\n",
    "- **Concepts**: Reuse pretrained knowledge\n",
    "- **Feature Extraction**: Freeze all, train classifier\n",
    "- **Fine-tuning**: Unfreeze some layers, small LR\n",
    "- **When to use**: Feature extraction (< 5k), Fine-tuning (> 5k)\n",
    "\n",
    "### 2. Pretrained Models\n",
    "- **torchvision.models**: ResNet, MobileNet, EfficientNet\n",
    "- **ResNet**: Deep with skip connections\n",
    "- **MobileNet**: Lightweight for mobile\n",
    "- **Modify classifier**: Easy adaptation\n",
    "\n",
    "### 3. Mixed Precision Training\n",
    "- **Concepts**: FP16 + FP32 for speed\n",
    "- **AMP**: autocast + GradScaler\n",
    "- **Benefits**: 2-3x faster, 50% less memory\n",
    "- **Requirements**: Modern GPU with Tensor Cores\n",
    "\n",
    "## üöÄ Key Takeaways\n",
    "\n",
    "1. **Transfer Learning** = must-have cho Computer Vision\n",
    "2. **Feature Extraction** ‚Üí nhanh, ƒë·ªß t·ªët\n",
    "3. **Fine-tuning** ‚Üí ch·∫≠m h∆°n, accuracy cao h∆°n\n",
    "4. **LR nh·ªè** critical cho fine-tuning (1e-5)\n",
    "5. **Mixed Precision** = free 2-3x speedup\n",
    "6. **MobileNet** best cho production/mobile\n",
    "\n",
    "## üìù Next: FILE 3-C\n",
    "\n",
    "- Clean ML Pipeline\n",
    "- Reproducibility\n",
    "- Model Evaluation\n",
    "- Save & Load Models\n",
    "- Production Best Practices\n",
    "\n",
    "---\n",
    "\n",
    "**Ch√∫c m·ª´ng b·∫°n ƒë√£ ho√†n th√†nh FILE 3-B! üéâ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
