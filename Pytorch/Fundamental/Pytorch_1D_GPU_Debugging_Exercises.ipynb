{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî• FILE 1-D: GPU, Debugging & Exercises\n",
    "\n",
    "**PH·∫¶N 1 - FOUNDATION (BEGINNER) - FINAL**\n",
    "\n",
    "---\n",
    "\n",
    "## üìã N·ªôi Dung\n",
    "\n",
    "‚úÖ CPU vs GPU - Khi n√†o d√πng g√¨?\n",
    "\n",
    "‚úÖ Chuy·ªÉn model v√† data l√™n GPU\n",
    "\n",
    "‚úÖ Device management best practices\n",
    "\n",
    "‚úÖ Common errors c·ªßa ng∆∞·ªùi m·ªõi\n",
    "\n",
    "‚úÖ Debugging techniques\n",
    "\n",
    "‚úÖ Performance tips\n",
    "\n",
    "‚úÖ T·ªïng h·ª£p b√†i t·∫≠p Foundation\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ M·ª•c Ti√™u\n",
    "\n",
    "Sau file n√†y, b·∫°n s·∫Ω:\n",
    "- Bi·∫øt c√°ch s·ª≠ d·ª•ng GPU hi·ªáu qu·∫£\n",
    "- T·ª± debug ƒë∆∞·ª£c c√°c l·ªói th∆∞·ªùng g·∫∑p\n",
    "- Ho√†n th√†nh Foundation level\n",
    "- S·∫µn s√†ng cho Intermediate level\n",
    "\n",
    "---\n",
    "\n",
    "## ‚è±Ô∏è Th·ªùi Gian H·ªçc: 2-3 gi·ªù\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(\"‚úÖ Ready to learn GPU & Debugging!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1Ô∏è‚É£ CPU vs GPU\n",
    "\n",
    "## S·ª± Kh√°c Bi·ªát\n",
    "\n",
    "### CPU (Central Processing Unit)\n",
    "- üîπ √çt cores (~4-16)\n",
    "- üîπ Clock speed cao\n",
    "- üîπ T·ªët cho t√°c v·ª• tu·∫ßn t·ª±\n",
    "- üîπ Linh ho·∫°t, ƒëa nƒÉng\n",
    "\n",
    "### GPU (Graphics Processing Unit)\n",
    "- üî∏ H√†ng ngh√¨n cores\n",
    "- üî∏ Clock speed th·∫•p h∆°n\n",
    "- üî∏ T·ªët cho t√°c v·ª• song song\n",
    "- üî∏ Chuy√™n bi·ªát cho ma tr·∫≠n\n",
    "\n",
    "## Deep Learning & GPU\n",
    "\n",
    "Neural networks = R·∫•t nhi·ªÅu ph√©p to√°n ma tr·∫≠n song song\n",
    "\n",
    "‚Üí **GPU nhanh h∆°n 10-100 l·∫ßn!**\n",
    "\n",
    "### Khi N√†o D√πng GPU?\n",
    "\n",
    "‚úÖ **N√™n d√πng GPU:**\n",
    "- Model l·ªõn (>1M parameters)\n",
    "- D·ªØ li·ªáu nhi·ªÅu (>10k samples)\n",
    "- Training l√¢u\n",
    "- CNN, Transformer, RNN\n",
    "\n",
    "‚ùå **Kh√¥ng c·∫ßn GPU:**\n",
    "- Model nh·ªè (<100k parameters)\n",
    "- D·ªØ li·ªáu √≠t\n",
    "- Prototyping nhanh\n",
    "- Linear models ƒë∆°n gi·∫£n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2Ô∏è‚É£ Ki·ªÉm Tra GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"KI·ªÇM TRA GPU\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Ki·ªÉm tra CUDA\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"\\nCUDA available: {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    print(f\"\\nCUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current GPU index: {torch.cuda.current_device()}\")\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Memory info\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory\n",
    "    print(f\"\\nGPU memory:\")\n",
    "    print(f\"  Total: {total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"  Allocated: {torch.cuda.memory_allocated() / 1e9:.4f} GB\")\n",
    "    print(f\"  Cached: {torch.cuda.memory_reserved() / 1e9:.4f} GB\")\n",
    "else:\n",
    "    print(\"\\nNo GPU detected\")\n",
    "    print(\"‚Üí Using CPU (ho√†n to√†n OK ƒë·ªÉ h·ªçc!)\")\n",
    "    print(\"‚Üí GPU ch·ªâ c·∫ßn khi train model l·ªõn\")\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\n‚úÖ Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3Ô∏è‚É£ Chuy·ªÉn Tensor L√™n GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"CHUY·ªÇN TENSOR L√äN GPU\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# T·∫°o tensor tr√™n CPU\n",
    "x_cpu = torch.randn(3, 3)\n",
    "print(f\"\\n1. Tensor tr√™n CPU:\")\n",
    "print(f\"   Device: {x_cpu.device}\")\n",
    "print(f\"   Data:\\n{x_cpu}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(\"C√ÅCH 1: .to(device)\")\n",
    "    print(\"-\" * 70)\n",
    "    x_gpu = x_cpu.to(device)\n",
    "    print(f\"Device: {x_gpu.device}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(\"C√ÅCH 2: .cuda()\")\n",
    "    print(\"-\" * 70)\n",
    "    x_gpu2 = x_cpu.cuda()\n",
    "    print(f\"Device: {x_gpu2.device}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(\"C√ÅCH 3: T·∫°o tr·ª±c ti·∫øp tr√™n GPU\")\n",
    "    print(\"-\" * 70)\n",
    "    x_gpu3 = torch.randn(3, 3, device=device)\n",
    "    print(f\"Device: {x_gpu3.device}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(\"CHUY·ªÇN V·ªÄ CPU\")\n",
    "    print(\"-\" * 70)\n",
    "    x_back = x_gpu.cpu()\n",
    "    print(f\"Device: {x_back.device}\")\n",
    "    \n",
    "    print(\"\\nüí° Khuy·∫øn ngh·ªã: D√πng .to(device) ƒë·ªÉ linh ho·∫°t\")\n",
    "else:\n",
    "    print(\"\\nGPU not available, skipping GPU examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4Ô∏è‚É£ Chuy·ªÉn Model L√™n GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"CHUY·ªÇN MODEL L√äN GPU\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# T·∫°o model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.fc2 = nn.Linear(5, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleModel()\n",
    "print(f\"\\nModel ban ƒë·∫ßu (CPU):\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"  {name}: {param.device}\")\n",
    "\n",
    "# Chuy·ªÉn l√™n GPU\n",
    "model = model.to(device)\n",
    "print(f\"\\nSau khi .to(device):\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"  {name}: {param.device}\")\n",
    "\n",
    "print(\"\\n‚úÖ T·∫§T C·∫¢ parameters ƒë√£ chuy·ªÉn l√™n GPU!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5Ô∏è‚É£ Training Loop V·ªõi GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TRAINING LOOP V·ªöI GPU\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# T·∫°o data\n",
    "X = torch.randn(100, 10)\n",
    "y = torch.randn(100, 1)\n",
    "\n",
    "# T·∫°o model\n",
    "model = SimpleModel().to(device)  # ‚Üê Chuy·ªÉn model l√™n GPU\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "print(f\"\\nDevice: {device}\")\n",
    "print(f\"Model device: {next(model.parameters()).device}\")\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 50\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # ‚ö†Ô∏è QUAN TR·ªåNG: Chuy·ªÉn data l√™n c√πng device v·ªõi model\n",
    "    X_device = X.to(device)\n",
    "    y_device = y.to(device)\n",
    "    \n",
    "    # Forward\n",
    "    y_pred = model(X_device)\n",
    "    loss = criterion(y_pred, y_device)\n",
    "    \n",
    "    # Backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Training ho√†n th√†nh!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üí° QUAN TR·ªåNG\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "Model v√† Data ph·∫£i ·ªü C√ôNG device!\n",
    "\n",
    "C√°ch t·ªët nh·∫•t:\n",
    "1. ƒê·ªãnh nghƒ©a device m·ªôt l·∫ßn ·ªü ƒë·∫ßu\n",
    "2. Chuy·ªÉn model: model.to(device)\n",
    "3. Chuy·ªÉn data trong loop: X.to(device), y.to(device)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6Ô∏è‚É£ So S√°nh T·ªëc ƒê·ªô CPU vs GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"BENCHMARK: CPU vs GPU\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# T·∫°o ma tr·∫≠n l·ªõn\n",
    "size = 5000\n",
    "a_cpu = torch.randn(size, size)\n",
    "b_cpu = torch.randn(size, size)\n",
    "\n",
    "# Benchmark CPU\n",
    "print(f\"\\nMatrix size: {size} √ó {size}\")\n",
    "print(\"\\nTesting CPU...\")\n",
    "start = time.time()\n",
    "c_cpu = torch.matmul(a_cpu, b_cpu)\n",
    "cpu_time = time.time() - start\n",
    "print(f\"CPU time: {cpu_time:.4f} seconds\")\n",
    "\n",
    "# Benchmark GPU (n·∫øu c√≥)\n",
    "if torch.cuda.is_available():\n",
    "    a_gpu = a_cpu.to(device)\n",
    "    b_gpu = b_cpu.to(device)\n",
    "    \n",
    "    # Warm-up GPU\n",
    "    _ = torch.matmul(a_gpu, b_gpu)\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    print(\"\\nTesting GPU...\")\n",
    "    start = time.time()\n",
    "    c_gpu = torch.matmul(a_gpu, b_gpu)\n",
    "    torch.cuda.synchronize()  # ƒê·ª£i GPU ho√†n th√†nh\n",
    "    gpu_time = time.time() - start\n",
    "    print(f\"GPU time: {gpu_time:.4f} seconds\")\n",
    "    \n",
    "    print(f\"\\nüöÄ Speedup: {cpu_time / gpu_time:.2f}x\")\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(['CPU', 'GPU'], [cpu_time, gpu_time], color=['blue', 'green'])\n",
    "    plt.ylabel('Time (seconds)')\n",
    "    plt.title('CPU vs GPU Performance')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    for i, v in enumerate([cpu_time, gpu_time]):\n",
    "        plt.text(i, v + 0.01, f'{v:.3f}s', ha='center', fontweight='bold')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nGPU not available for comparison\")\n",
    "\n",
    "print(\"\\nüí° L∆∞u √Ω:\")\n",
    "print(\"  - GPU nhanh h∆°n nhi·ªÅu v·ªõi ma tr·∫≠n l·ªõn\")\n",
    "print(\"  - V·ªõi ma tr·∫≠n nh·ªè, CPU c√≥ th·ªÉ nhanh h∆°n (overhead)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7Ô∏è‚É£ Common Errors - L·ªói Th∆∞·ªùng G·∫∑p\n",
    "\n",
    "## 7.1 Device Mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"L·ªñI 1: DEVICE MISMATCH\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = nn.Linear(10, 5).to(device)\n",
    "    x = torch.randn(3, 10)  # ‚Üê Tr√™n CPU\n",
    "    \n",
    "    print(f\"\\nModel device: {next(model.parameters()).device}\")\n",
    "    print(f\"Input device: {x.device}\")\n",
    "    \n",
    "    try:\n",
    "        y = model(x)  # ‚ùå L·ªñI!\n",
    "    except RuntimeError as e:\n",
    "        print(f\"\\n‚ùå ERROR: {str(e)[:80]}...\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"‚úÖ GI·∫¢I PH√ÅP\")\n",
    "    print(\"=\" * 70)\n",
    "    x = x.to(device)  # Chuy·ªÉn input l√™n GPU\n",
    "    y = model(x)  # OK!\n",
    "    print(f\"\\nInput device: {x.device}\")\n",
    "    print(f\"Output device: {y.device}\")\n",
    "    print(\"‚úÖ Success!\")\n",
    "else:\n",
    "    print(\"\\nGPU not available, skipping this example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Gradient Not Zeroed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"L·ªñI 2: QU√äN ZERO GRADIENT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "model = nn.Linear(1, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "x = torch.tensor([[1.0]])\n",
    "y = torch.tensor([[2.0]])\n",
    "\n",
    "print(\"\\nKh√¥ng zero gradient:\")\n",
    "for i in range(3):\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred, y)\n",
    "    loss.backward()\n",
    "    # ‚ùå QU√äN optimizer.zero_grad()\n",
    "    optimizer.step()\n",
    "    print(f\"Iteration {i+1}: grad = {model.weight.grad.item():.4f}\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Gradient c·ªông d·ªìn ‚Üí K·∫øt qu·∫£ SAI!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ ƒê√öNG C√ÅCH\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "model = nn.Linear(1, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for i in range(3):\n",
    "    optimizer.zero_grad()  # ‚Üê PH·∫¢I C√ì!\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Iteration {i+1}: grad = {model.weight.grad.item():.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Gradient ƒë√∫ng m·ªói iteration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Shape Mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"L·ªñI 3: SHAPE MISMATCH\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "model = nn.Linear(10, 5)\n",
    "x = torch.randn(3, 5)  # ‚ùå Wrong: should be (3, 10)\n",
    "\n",
    "print(f\"\\nModel expects: (batch, 10)\")\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "\n",
    "try:\n",
    "    y = model(x)\n",
    "except RuntimeError as e:\n",
    "    print(f\"\\n‚ùå ERROR: {str(e)[:80]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ GI·∫¢I PH√ÅP\")\n",
    "print(\"=\" * 70)\n",
    "x = torch.randn(3, 10)  # ƒê√∫ng shape\n",
    "y = model(x)\n",
    "print(f\"\\nInput: {x.shape}\")\n",
    "print(f\"Output: {y.shape}\")\n",
    "print(\"‚úÖ Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 In-place Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"L·ªñI 4: IN-PLACE OPERATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "y = x ** 2\n",
    "\n",
    "try:\n",
    "    x[0] = 999  # ‚ùå In-place operation\n",
    "    y.backward(torch.ones_like(y))\n",
    "except RuntimeError as e:\n",
    "    print(f\"‚ùå ERROR: {str(e)[:100]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ GI·∫¢I PH√ÅP\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "Tr√°nh in-place operations (+=, *=, []=) tr√™n tensors c√≥ requires_grad=True\n",
    "\n",
    "‚ùå Bad:  x[0] = 999\n",
    "‚úÖ Good: x = torch.cat([torch.tensor([999.0]), x[1:]])\n",
    "\n",
    "‚ùå Bad:  x += 1\n",
    "‚úÖ Good: x = x + 1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 8Ô∏è‚É£ Debugging Techniques\n",
    "\n",
    "## 8.1 Print Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"DEBUGGING: PRINT SHAPES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "class DebugModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(f\"  Input: {x.shape}\")\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        print(f\"  After fc1: {x.shape}\")\n",
    "        \n",
    "        x = torch.relu(x)\n",
    "        print(f\"  After ReLU: {x.shape}\")\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        print(f\"  After fc2: {x.shape}\")\n",
    "        \n",
    "        x = torch.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        print(f\"  Output: {x.shape}\")\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = DebugModel()\n",
    "x = torch.randn(5, 10)\n",
    "\n",
    "print(\"\\nForward pass:\")\n",
    "y = model(x)\n",
    "\n",
    "print(\"\\nüí° Print shapes gi√∫p debug shape mismatch errors!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Check Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"DEBUGGING: CHECK GRADIENTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1)\n",
    ")\n",
    "\n",
    "x = torch.randn(3, 10)\n",
    "y = torch.randn(3, 1)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Forward + backward\n",
    "y_pred = model(x)\n",
    "loss = criterion(y_pred, y)\n",
    "loss.backward()\n",
    "\n",
    "# Check gradients\n",
    "print(\"\\nGradient check:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        grad_norm = param.grad.norm().item()\n",
    "        print(f\"{name:20s}: grad_norm = {grad_norm:.6f}\")\n",
    "    else:\n",
    "        print(f\"{name:20s}: ‚ö†Ô∏è No gradient!\")\n",
    "\n",
    "print(\"\\nüí° N·∫øu gradient = 0 ho·∫∑c None ‚Üí c√≥ v·∫•n ƒë·ªÅ!\")\n",
    "print(\"   C√≥ th·ªÉ do: Dead ReLU, vanishing gradient, etc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Gradient Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"GRADIENT CLIPPING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "Gradient clipping ngƒÉn exploding gradients\n",
    "H·ªØu √≠ch cho RNN, LSTM, GRU\n",
    "\"\"\")\n",
    "\n",
    "model = nn.Linear(10, 5)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "x = torch.randn(3, 10)\n",
    "y = torch.randn(3, 5)\n",
    "\n",
    "# Training v·ªõi gradient clipping\n",
    "y_pred = model(x)\n",
    "loss = nn.MSELoss()(y_pred, y)\n",
    "loss.backward()\n",
    "\n",
    "# Clip gradients\n",
    "max_norm = 1.0\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "\n",
    "optimizer.step()\n",
    "\n",
    "print(f\"\\n‚úÖ Gradients clipped to max_norm={max_norm}\")\n",
    "print(\"\\nC√°ch d√πng:\")\n",
    "print(\"\"\"\n",
    "loss.backward()\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "optimizer.step()\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 9Ô∏è‚É£ Best Practices\n",
    "\n",
    "## Checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"‚úÖ PYTORCH BEST PRACTICES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "1. DEVICE MANAGEMENT\n",
    "   ‚úÖ ƒê·ªãnh nghƒ©a device ·ªü ƒë·∫ßu code\n",
    "   ‚úÖ Chuy·ªÉn model m·ªôt l·∫ßn: model.to(device)\n",
    "   ‚úÖ Chuy·ªÉn data trong loop: x.to(device)\n",
    "   ‚ùå Kh√¥ng mix CPU v√† GPU tensors\n",
    "\n",
    "2. GRADIENT MANAGEMENT\n",
    "   ‚úÖ Lu√¥n zero_grad() tr∆∞·ªõc backward()\n",
    "   ‚úÖ D√πng optimizer.zero_grad() thay v√¨ manual\n",
    "   ‚ùå Kh√¥ng qu√™n zero gradients\n",
    "\n",
    "3. TRAINING LOOP\n",
    "   ‚úÖ Th·ª© t·ª±: forward ‚Üí loss ‚Üí zero_grad ‚Üí backward ‚Üí step\n",
    "   ‚úÖ D√πng torch.no_grad() khi eval\n",
    "   ‚úÖ Set model.train() / model.eval()\n",
    "\n",
    "4. MEMORY\n",
    "   ‚úÖ D√πng torch.no_grad() khi kh√¥ng c·∫ßn gradient\n",
    "   ‚úÖ Clear cache: torch.cuda.empty_cache()\n",
    "   ‚úÖ Del tensors kh√¥ng d√πng n·ªØa\n",
    "   ‚ùå Kh√¥ng l∆∞u to√†n b·ªô history\n",
    "\n",
    "5. REPRODUCIBILITY\n",
    "   ‚úÖ Set seed: torch.manual_seed(42)\n",
    "   ‚úÖ Set CUDA seed: torch.cuda.manual_seed(42)\n",
    "   ‚úÖ Deterministic operations (n·∫øu c·∫ßn)\n",
    "\n",
    "6. CODE ORGANIZATION\n",
    "   ‚úÖ T√°ch model definition ra class ri√™ng\n",
    "   ‚úÖ T√°ch training loop ra function\n",
    "   ‚úÖ T√°ch data loading ra function\n",
    "   ‚úÖ Comment code r√µ r√†ng\n",
    "\n",
    "7. DEBUGGING\n",
    "   ‚úÖ Print shapes th∆∞·ªùng xuy√™n\n",
    "   ‚úÖ Check gradients\n",
    "   ‚úÖ Visualize loss curves\n",
    "   ‚úÖ Start simple, add complexity gradually\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üîü Template Code - S·ª≠ D·ª•ng Ngay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TEMPLATE: COMPLETE TRAINING PIPELINE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============= SETUP =============\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\\n\")\n",
    "\n",
    "# ============= MODEL =============\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# ============= DATA =============\n",
    "X = torch.randn(100, 10)\n",
    "y = torch.randn(100, 1)\n",
    "\n",
    "# ============= TRAINING SETUP =============\n",
    "model = MyModel(10, 64, 1).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ============= TRAINING LOOP =============\n",
    "n_epochs = 50\n",
    "for epoch in range(n_epochs):\n",
    "    # Move data to device\n",
    "    X_device = X.to(device)\n",
    "    y_device = y.to(device)\n",
    "    \n",
    "    # Forward\n",
    "    y_pred = model(X_device)\n",
    "    loss = criterion(y_pred, y_device)\n",
    "    \n",
    "    # Backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Log\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Template completed!\")\n",
    "print(\"\\nüí° Copy template n√†y l√†m starting point cho projects!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1Ô∏è‚É£1Ô∏è‚É£ B√†i T·∫≠p T·ªïng H·ª£p Foundation\n",
    "\n",
    "## B√†i 1: Linear Regression Ho√†n Ch·ªânh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ƒê·ªÅ b√†i:**\n",
    "1. T·∫°o d·ªØ li·ªáu: y = 2x‚ÇÅ + 3x‚ÇÇ - 4x‚ÇÉ + 5 + noise\n",
    "2. Chia train/test 80/20\n",
    "3. Build model b·∫±ng nn.Linear\n",
    "4. Train 100 epochs\n",
    "5. Evaluate tr√™n test set\n",
    "6. Visualize: loss curves, predictions vs true\n",
    "7. So s√°nh learned parameters vs true\n",
    "\n",
    "**Y√™u c·∫ßu:**\n",
    "- D√πng torch.nn\n",
    "- D√πng Adam optimizer\n",
    "- MSE loss\n",
    "- Ch·∫°y tr√™n GPU (n·∫øu c√≥)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B√†i 2: Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ƒê·ªÅ b√†i:**\n",
    "1. T·∫°o d·ªØ li·ªáu binary classification (d√πng make_circles)\n",
    "2. Build MLP: Input ‚Üí 32 ‚Üí 16 ‚Üí 2 (classes)\n",
    "3. D√πng ReLU activation\n",
    "4. CrossEntropyLoss\n",
    "5. Train v√† track accuracy\n",
    "6. Visualize decision boundary\n",
    "7. Confusion matrix\n",
    "\n",
    "**Y√™u c·∫ßu:**\n",
    "- Custom nn.Module\n",
    "- Training accuracy > 90%\n",
    "- Plot decision boundary ƒë·∫πp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B√†i 3: Multi-class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ƒê·ªÅ b√†i:**\n",
    "1. T·∫°o 4 classes data (d√πng make_blobs)\n",
    "2. Build deeper MLP: 2 ‚Üí 64 ‚Üí 32 ‚Üí 16 ‚Üí 4\n",
    "3. Th·ª≠ c√°c activation: ReLU, Tanh, LeakyReLU\n",
    "4. So s√°nh performance\n",
    "5. Plot loss v√† accuracy cho m·ªói activation\n",
    "\n",
    "**Y√™u c·∫ßu:**\n",
    "- 3 models v·ªõi activations kh√°c nhau\n",
    "- Training curves ƒë·ªÉ so s√°nh\n",
    "- K·∫øt lu·∫≠n activation n√†o t·ªët nh·∫•t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B√†i 4: Overfitting vs Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ƒê·ªÅ b√†i:**\n",
    "1. T·∫°o data nh·ªè (100 samples, 20 features)\n",
    "2. Build model r·∫•t l·ªõn (20 ‚Üí 256 ‚Üí 128 ‚Üí 64 ‚Üí 1)\n",
    "3. Train ƒë·∫øn khi overfit (train loss << val loss)\n",
    "4. Th√™m L2 regularization (weight_decay)\n",
    "5. So s√°nh v·ªõi/kh√¥ng regularization\n",
    "\n",
    "**Y√™u c·∫ßu:**\n",
    "- Plot train/val loss curves\n",
    "- Ch·ª©ng minh overfitting\n",
    "- Ch·ª©ng minh regularization gi√∫p gi·∫£m overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B√†i 5: Learning Rate Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ƒê·ªÅ b√†i:**\n",
    "1. T·∫°o data regression ƒë∆°n gi·∫£n\n",
    "2. Train v·ªõi learning rates: [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "3. So s√°nh:\n",
    "   - T·ªëc ƒë·ªô h·ªôi t·ª•\n",
    "   - Final loss\n",
    "   - Stability\n",
    "4. T√¨m LR t·ªëi ∆∞u\n",
    "5. Plot t·∫•t c·∫£ loss curves tr√™n c√πng graph\n",
    "\n",
    "**Y√™u c·∫ßu:**\n",
    "- 5 experiments\n",
    "- Comprehensive comparison\n",
    "- Clear conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ‚úÖ T·ªïng K·∫øt FILE 1-D & Foundation Level\n",
    "\n",
    "## FILE 1-D: B·∫°n ƒê√£ H·ªçc ƒê∆∞·ª£c\n",
    "\n",
    "‚úÖ **CPU vs GPU** - Khi n√†o d√πng g√¨\n",
    "\n",
    "‚úÖ **Device management** - Chuy·ªÉn model v√† data\n",
    "\n",
    "‚úÖ **GPU benchmark** - So s√°nh t·ªëc ƒë·ªô\n",
    "\n",
    "‚úÖ **Common errors** - Device mismatch, gradient issues, shapes\n",
    "\n",
    "‚úÖ **Debugging** - Print shapes, check gradients, clip gradients\n",
    "\n",
    "‚úÖ **Best practices** - Checklist ƒë·∫ßy ƒë·ªß\n",
    "\n",
    "‚úÖ **Template code** - S·ª≠ d·ª•ng ngay\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ HO√ÄN TH√ÄNH FOUNDATION LEVEL!\n",
    "\n",
    "### B·∫°n ƒê√£ H·ªçc ƒê∆∞·ª£c (FILE 1-A ƒë·∫øn 1-D):\n",
    "\n",
    "üìò **FILE 1-A**: Tensor basics\n",
    "- Tensor operations\n",
    "- Indexing, slicing, reshaping\n",
    "- Broadcasting\n",
    "- Matrix multiplication\n",
    "\n",
    "üìò **FILE 1-B**: Autograd & Training\n",
    "- Gradient computation\n",
    "- backward(), zero_grad()\n",
    "- Gradient descent\n",
    "- Linear regression t·ª´ ƒë·∫ßu\n",
    "\n",
    "üìò **FILE 1-C**: torch.nn\n",
    "- nn.Module\n",
    "- Layers v√† activations\n",
    "- Loss functions\n",
    "- Optimizers\n",
    "- MLP ƒë·∫ßu ti√™n\n",
    "\n",
    "üìò **FILE 1-D**: GPU & Production\n",
    "- GPU usage\n",
    "- Debugging\n",
    "- Best practices\n",
    "- Production-ready code\n",
    "\n",
    "---\n",
    "\n",
    "## B·∫°n Gi·ªù C√≥ Th·ªÉ:\n",
    "\n",
    "‚úÖ Hi·ªÉu r√µ c√°ch PyTorch ho·∫°t ƒë·ªông\n",
    "\n",
    "‚úÖ X√¢y d·ª±ng neural networks\n",
    "\n",
    "‚úÖ Train models hi·ªáu qu·∫£\n",
    "\n",
    "‚úÖ Debug khi g·∫∑p l·ªói\n",
    "\n",
    "‚úÖ S·ª≠ d·ª•ng GPU\n",
    "\n",
    "‚úÖ Vi·∫øt code production-ready\n",
    "\n",
    "---\n",
    "\n",
    "## Ti·∫øp Theo: INTERMEDIATE LEVEL\n",
    "\n",
    "üìó **FILE 2-A: Dataset, DataLoader & Training Loop**\n",
    "- Custom Dataset\n",
    "- DataLoader\n",
    "- Training/Validation split\n",
    "- Full training pipeline\n",
    "\n",
    "üìó **FILE 2-B: Optimizer, Activation & Regularization**\n",
    "- Advanced optimizers\n",
    "- More activations\n",
    "- Dropout, BatchNorm\n",
    "- Regularization techniques\n",
    "\n",
    "üìó **FILE 2-C: CNN & Model Checkpoint**\n",
    "- Convolutional layers\n",
    "- Image classification\n",
    "- Save/load models\n",
    "- Transfer learning basics\n",
    "\n",
    "---\n",
    "\n",
    "## üèÜ Ch√∫c M·ª´ng!\n",
    "\n",
    "B·∫°n ƒë√£ ho√†n th√†nh **Foundation Level**!\n",
    "\n",
    "B·∫°n gi·ªù c√≥ n·ªÅn t·∫£ng v·ªØng ch·∫Øc ƒë·ªÉ:\n",
    "- H·ªçc c√°c k·ªπ thu·∫≠t n√¢ng cao\n",
    "- Build projects th·ª±c t·∫ø\n",
    "- Tham gia competitions\n",
    "- ƒê·ªçc hi·ªÉu research papers\n",
    "\n",
    "**Keep learning and building! üöÄ**\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
