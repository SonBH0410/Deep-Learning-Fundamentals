{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî• FILE 2-C: CNN & Model Checkpoint\n",
    "\n",
    "**PH·∫¶N 2 - INTERMEDIATE (CORE DEEP LEARNING) - FINAL**\n",
    "\n",
    "---\n",
    "\n",
    "## üìã N·ªôi Dung\n",
    "\n",
    "‚úÖ CNN (Convolutional Neural Networks) l√† g√¨\n",
    "\n",
    "‚úÖ Conv2d - Convolutional layers\n",
    "\n",
    "‚úÖ Pooling - MaxPool, AvgPool\n",
    "\n",
    "‚úÖ CNN Architecture patterns\n",
    "\n",
    "‚úÖ D·ª± √°n: Image Classification v·ªõi CNN\n",
    "\n",
    "‚úÖ Save & Load model checkpoints\n",
    "\n",
    "‚úÖ Best practices cho model saving\n",
    "\n",
    "---\n",
    "\n",
    "## ‚è±Ô∏è Th·ªùi Gian H·ªçc: 3-4 gi·ªù\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1Ô∏è‚É£ CNN C∆° B·∫£n\n",
    "\n",
    "## T·∫°i Sao C·∫ßn CNN?\n",
    "\n",
    "**V·∫•n ƒë·ªÅ v·ªõi Fully Connected cho ·∫£nh:**\n",
    "\n",
    "```\n",
    "·∫¢nh 224√ó224√ó3 (RGB)\n",
    "‚Üí Flatten: 224 √ó 224 √ó 3 = 150,528 features\n",
    "‚Üí FC(150528, 1000): 150M+ parameters!\n",
    "```\n",
    "\n",
    "‚ùå Qu√° nhi·ªÅu parameters\n",
    "\n",
    "‚ùå M·∫•t spatial information\n",
    "\n",
    "‚ùå Kh√¥ng translation invariant\n",
    "\n",
    "**CNN gi·∫£i quy·∫øt:**\n",
    "\n",
    "‚úÖ Local connectivity (receptive field)\n",
    "\n",
    "‚úÖ Parameter sharing (same filter)\n",
    "\n",
    "‚úÖ Translation invariance\n",
    "\n",
    "‚úÖ Hierarchical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2d Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"nn.Conv2d\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Conv2d parameters\n",
    "conv = nn.Conv2d(\n",
    "    in_channels=3,      # Input channels (RGB = 3)\n",
    "    out_channels=16,    # Output channels (number of filters)\n",
    "    kernel_size=3,      # Filter size: 3√ó3\n",
    "    stride=1,           # Stride\n",
    "    padding=1           # Padding\n",
    ")\n",
    "\n",
    "print(f\"Conv layer: {conv}\")\n",
    "print(f\"\\nParameters:\")\n",
    "print(f\"  Weight shape: {conv.weight.shape}\")\n",
    "print(f\"  ‚Üí (out_channels, in_channels, kernel_h, kernel_w)\")\n",
    "print(f\"  Bias shape: {conv.bias.shape}\")\n",
    "print(f\"  Total params: {conv.weight.numel() + conv.bias.numel()}\")\n",
    "\n",
    "# Test forward\n",
    "x = torch.randn(1, 3, 32, 32)  # (batch, channels, height, width)\n",
    "out = conv(x)\n",
    "print(f\"\\nInput: {x.shape}\")\n",
    "print(f\"Output: {out.shape}\")\n",
    "\n",
    "print(\"\"\"\n",
    "C√îNG TH·ª®C OUTPUT SIZE:\n",
    "\n",
    "H_out = (H_in + 2*padding - kernel_size) / stride + 1\n",
    "W_out = (W_in + 2*padding - kernel_size) / stride + 1\n",
    "\n",
    "V√≠ d·ª•:\n",
    "  Input: 32√ó32\n",
    "  kernel=3, padding=1, stride=1\n",
    "  Output: (32 + 2*1 - 3)/1 + 1 = 32√ó32\n",
    "\n",
    "üí° SAME PADDING: padding = (kernel_size - 1) / 2\n",
    "   ‚Üí Output size = Input size (when stride=1)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"POOLING LAYERS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# MaxPool\n",
    "maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "# AvgPool\n",
    "avgpool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "x = torch.randn(1, 16, 32, 32)\n",
    "max_out = maxpool(x)\n",
    "avg_out = avgpool(x)\n",
    "\n",
    "print(f\"Input: {x.shape}\")\n",
    "print(f\"MaxPool output: {max_out.shape}\")\n",
    "print(f\"AvgPool output: {avg_out.shape}\")\n",
    "\n",
    "print(\"\"\"\n",
    "POOLING:\n",
    "\n",
    "MaxPool2d(2, 2):\n",
    "  - Chia th√†nh windows 2√ó2\n",
    "  - L·∫•y gi√° tr·ªã MAX trong m·ªói window\n",
    "  - Gi·∫£m size: 32√ó32 ‚Üí 16√ó16\n",
    "\n",
    "AvgPool2d(2, 2):\n",
    "  - L·∫•y TRUNG B√åNH thay v√¨ max\n",
    "\n",
    "L·ª¢I √çCH:\n",
    "  ‚úÖ Downsampling (gi·∫£m spatial size)\n",
    "  ‚úÖ Gi·∫£m parameters\n",
    "  ‚úÖ Translation invariance\n",
    "  ‚úÖ TƒÉng receptive field\n",
    "\n",
    "KHUY·∫æN NGH·ªä:\n",
    "  - MaxPool: Ph·ªï bi·∫øn h∆°n\n",
    "  - kernel=2, stride=2: Standard\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2Ô∏è‚É£ CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"SIMPLE CNN ARCHITECTURE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"Simple CNN for image classification\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Pooling\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Fully connected\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Conv block 1: 32√ó32 ‚Üí 16√ó16\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        \n",
    "        # Conv block 2: 16√ó16 ‚Üí 8√ó8\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        \n",
    "        # Conv block 3: 8√ó8 ‚Üí 4√ó4\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # FC layers\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = SimpleCNN(num_classes=10)\n",
    "print(model)\n",
    "\n",
    "# Test\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "out = model(x)\n",
    "print(f\"\\nInput: {x.shape}\")\n",
    "print(f\"Output: {out.shape}\")\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modern CNN Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"MODERN CNN WITH BATCHNORM\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "class ModernCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Block 2\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Block 3\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 4 * 4, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "print(\"\"\"\n",
    "MODERN CNN PATTERN:\n",
    "\n",
    "Conv ‚Üí BatchNorm ‚Üí ReLU ‚Üí Conv ‚Üí BatchNorm ‚Üí ReLU ‚Üí Pool\n",
    "\n",
    "KEY POINTS:\n",
    "  ‚úÖ BatchNorm after Conv\n",
    "  ‚úÖ Double Conv before pooling\n",
    "  ‚úÖ Increasing channels: 64 ‚Üí 128 ‚Üí 256\n",
    "  ‚úÖ Decreasing spatial: 32 ‚Üí 16 ‚Üí 8 ‚Üí 4\n",
    "  ‚úÖ Dropout in FC layers\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3Ô∏è‚É£ D·ª± √Ån: Image Classification\n",
    "\n",
    "## Load CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"LOADING CIFAR-10\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Data transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Download dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Classes: {classes}\")\n",
    "\n",
    "# Visualize samples\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    img = images[i].numpy().transpose(1, 2, 0)\n",
    "    img = img * 0.5 + 0.5  # Denormalize\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(classes[labels[i]])\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TRAINING CNN\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Model\n",
    "model = SimpleCNN(num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training\n",
    "num_epochs = 10\n",
    "history = {'train_loss': [], 'train_acc': [], 'test_acc': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100 * correct / total\n",
    "    \n",
    "    # Test\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_acc = 100 * correct / total\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['test_acc'].append(test_acc)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {train_loss:.3f} \"\n",
    "          f\"Train Acc: {train_acc:.1f}% Test Acc: {test_acc:.1f}%\")\n",
    "\n",
    "print(\"\\n‚úÖ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4Ô∏è‚É£ Save & Load Model\n",
    "\n",
    "## C√°ch L∆∞u Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"SAVE & LOAD MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# C√ÅCH 1: Save to√†n b·ªô model (KH√îNG khuy·∫øn kh√≠ch)\n",
    "torch.save(model, 'entire_model.pth')\n",
    "loaded_model = torch.load('entire_model.pth')\n",
    "print(\"‚úì Saved entire model\")\n",
    "\n",
    "# C√ÅCH 2: Save state_dict (KHUY·∫æN KH√çCH)\n",
    "torch.save(model.state_dict(), 'model_weights.pth')\n",
    "print(\"‚úì Saved state_dict\")\n",
    "\n",
    "# Load state_dict\n",
    "new_model = SimpleCNN(num_classes=10)\n",
    "new_model.load_state_dict(torch.load('model_weights.pth'))\n",
    "new_model.to(device)\n",
    "print(\"‚úì Loaded state_dict\")\n",
    "\n",
    "# C√ÅCH 3: Save checkpoint (BEST PRACTICE)\n",
    "checkpoint = {\n",
    "    'epoch': num_epochs,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': history['train_loss'][-1],\n",
    "    'accuracy': history['test_acc'][-1],\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')\n",
    "print(\"‚úì Saved checkpoint\")\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load('checkpoint.pth')\n",
    "model = SimpleCNN(num_classes=10)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "print(f\"‚úì Loaded checkpoint from epoch {epoch}\")\n",
    "\n",
    "print(\"\"\"\n",
    "\n",
    "BEST PRACTICES:\n",
    "\n",
    "1. L∆∞u state_dict, KH√îNG l∆∞u to√†n b·ªô model\n",
    "2. L∆∞u optimizer state ƒë·ªÉ resume training\n",
    "3. L∆∞u epoch, loss, accuracy\n",
    "4. L∆∞u hyperparameters, config\n",
    "5. ƒê·∫∑t t√™n file r√µ r√†ng: model_epoch10_acc85.pth\n",
    "\n",
    "CHECKPOINT STRUCTURE:\n",
    "{\n",
    "    'epoch': int,\n",
    "    'model_state_dict': OrderedDict,\n",
    "    'optimizer_state_dict': dict,\n",
    "    'loss': float,\n",
    "    'accuracy': float,\n",
    "    'config': dict  # Optional\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping v·ªõi Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TRAINING WITH CHECKPOINTING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "class ModelCheckpoint:\n",
    "    \"\"\"Save best model during training\"\"\"\n",
    "    \n",
    "    def __init__(self, filepath, monitor='val_loss', mode='min', verbose=True):\n",
    "        self.filepath = filepath\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.best = float('inf') if mode == 'min' else float('-inf')\n",
    "    \n",
    "    def __call__(self, model, optimizer, epoch, metrics):\n",
    "        current = metrics[self.monitor]\n",
    "        \n",
    "        if self.mode == 'min':\n",
    "            is_better = current < self.best\n",
    "        else:\n",
    "            is_better = current > self.best\n",
    "        \n",
    "        if is_better:\n",
    "            self.best = current\n",
    "            \n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                **metrics\n",
    "            }\n",
    "            \n",
    "            torch.save(checkpoint, self.filepath)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"\\nüíæ Saved checkpoint: {self.monitor}={current:.4f}\")\n",
    "\n",
    "print(\"\"\"\n",
    "USAGE:\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model.pth',\n",
    "    monitor='val_acc',\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training...\n",
    "    metrics = {\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'val_acc': val_acc\n",
    "    }\n",
    "    checkpoint(model, optimizer, epoch, metrics)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ‚úÖ T·ªïng K·∫øt FILE 2-C & INTERMEDIATE LEVEL\n",
    "\n",
    "## FILE 2-C: H·ªçc ƒê∆∞·ª£c\n",
    "\n",
    "‚úÖ **CNN basics**: Conv2d, Pooling\n",
    "\n",
    "‚úÖ **CNN architecture**: Pattern thi·∫øt k·∫ø\n",
    "\n",
    "‚úÖ **Image classification**: CIFAR-10 project\n",
    "\n",
    "‚úÖ **Model checkpoint**: Save/load best practices\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ HO√ÄN TH√ÄNH INTERMEDIATE LEVEL!\n",
    "\n",
    "### T·ªïng K·∫øt PH·∫¶N 2:\n",
    "\n",
    "üìó **FILE 2-A**: Dataset & DataLoader\n",
    "- Custom Dataset\n",
    "- DataLoader\n",
    "- Training/Validation loop\n",
    "- Overfitting/Underfitting\n",
    "- Early Stopping\n",
    "\n",
    "üìó **FILE 2-B**: Optimizer & Regularization\n",
    "- Activation functions\n",
    "- Optimizers (SGD, Adam, AdamW)\n",
    "- Learning rate scheduling\n",
    "- Regularization (Dropout, Weight Decay, BatchNorm)\n",
    "\n",
    "üìó **FILE 2-C**: CNN & Checkpoint\n",
    "- CNN architecture\n",
    "- Image classification\n",
    "- Model saving/loading\n",
    "\n",
    "---\n",
    "\n",
    "## B·∫°n Gi·ªù C√≥ Th·ªÉ:\n",
    "\n",
    "‚úÖ X·ª≠ l√Ω data v·ªõi Dataset/DataLoader\n",
    "\n",
    "‚úÖ Build training pipeline ho√†n ch·ªânh\n",
    "\n",
    "‚úÖ Detect v√† fix overfitting\n",
    "\n",
    "‚úÖ Tune hyperparameters\n",
    "\n",
    "‚úÖ Build CNN cho image tasks\n",
    "\n",
    "‚úÖ Save/load models ƒë√∫ng c√°ch\n",
    "\n",
    "---\n",
    "\n",
    "## Template: Complete CNN Training Pipeline\n",
    "\n",
    "```python\n",
    "# 1. Data\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# 2. Model\n",
    "model = ModernCNN(num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "# 3. Training\n",
    "checkpoint = ModelCheckpoint('best_model.pth', monitor='val_acc', mode='max')\n",
    "early_stop = EarlyStopping(patience=10)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, ...)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = validate_epoch(model, val_loader, ...)\n",
    "    \n",
    "    # Save best\n",
    "    checkpoint(model, optimizer, epoch, {'val_acc': val_acc, ...})\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stop(val_loss)\n",
    "    if early_stop.early_stop:\n",
    "        break\n",
    "    \n",
    "    # Update LR\n",
    "    scheduler.step()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ B∆∞·ªõc Ti·∫øp Theo\n",
    "\n",
    "B·∫°n ƒë√£ s·∫µn s√†ng cho:\n",
    "- Transfer Learning\n",
    "- Advanced architectures (ResNet, VGG, etc.)\n",
    "- Object Detection\n",
    "- Semantic Segmentation\n",
    "- GANs, Transformers\n",
    "\n",
    "**Congratulations on completing Intermediate level! üéâ**\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
