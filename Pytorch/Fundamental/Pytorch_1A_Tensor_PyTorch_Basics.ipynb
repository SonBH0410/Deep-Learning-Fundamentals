{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî• FILE 1-A: Tensor & PyTorch Basics\n",
    "\n",
    "**PH·∫¶N 1 - FOUNDATION (BEGINNER)**\n",
    "\n",
    "---\n",
    "\n",
    "## üìã N·ªôi Dung\n",
    "\n",
    "‚úÖ Gi·ªõi thi·ªáu PyTorch\n",
    "\n",
    "‚úÖ Tensor l√† g√¨ v√† t·∫°i sao quan tr·ªçng\n",
    "\n",
    "‚úÖ Tensor vs NumPy Array\n",
    "\n",
    "‚úÖ C√°c c√°ch t·∫°o tensor\n",
    "\n",
    "‚úÖ Thu·ªôc t√≠nh tensor (shape, dtype, device)\n",
    "\n",
    "‚úÖ C√°c ph√©p to√°n tensor c∆° b·∫£n\n",
    "\n",
    "‚úÖ Indexing, slicing, reshaping\n",
    "\n",
    "‚úÖ Broadcasting\n",
    "\n",
    "‚úÖ Matrix multiplication\n",
    "\n",
    "---\n",
    "\n",
    "## ‚è±Ô∏è Th·ªùi Gian H·ªçc: 1.5-2 gi·ªù\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1Ô∏è‚É£ Gi·ªõi Thi·ªáu PyTorch\n",
    "\n",
    "## PyTorch L√† G√¨?\n",
    "\n",
    "**PyTorch** l√† m·ªôt framework Deep Learning m√£ ngu·ªìn m·ªü ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi **Meta AI (Facebook)**.\n",
    "\n",
    "### T·∫°i Sao Ch·ªçn PyTorch?\n",
    "\n",
    "| ∆Øu ƒêi·ªÉm | Gi·∫£i Th√≠ch |\n",
    "|---------|------------|\n",
    "| üêç **Pythonic** | Code gi·ªëng Python thu·∫ßn, d·ªÖ h·ªçc, d·ªÖ ƒë·ªçc |\n",
    "| üîÑ **Dynamic Graph** | Linh ho·∫°t, d·ªÖ debug, ph√π h·ª£p nghi√™n c·ª©u |\n",
    "| ‚ö° **GPU Support** | TƒÉng t·ªëc 10-100 l·∫ßn v·ªõi GPU |\n",
    "| üéì **C·ªông ƒê·ªìng L·ªõn** | Nhi·ªÅu tutorial, paper implementations |\n",
    "| üî¨ **Research & Production** | T·ª´ nghi√™n c·ª©u ƒë·∫øn tri·ªÉn khai th·ª±c t·∫ø |\n",
    "\n",
    "### C√†i ƒê·∫∑t\n",
    "\n",
    "```bash\n",
    "# CPU only\n",
    "pip install torch torchvision torchaudio\n",
    "\n",
    "# GPU (CUDA 11.8) - Truy c·∫≠p pytorch.org ƒë·ªÉ ch·ªçn phi√™n b·∫£n\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ki·ªÉm tra c√†i ƒë·∫∑t PyTorch\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TH√îNG TIN PYTORCH\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"Running on CPU (GPU kh√¥ng b·∫Øt bu·ªôc ƒë·ªÉ h·ªçc!)\")\n",
    "\n",
    "print(\"\\n‚úÖ PyTorch s·∫µn s√†ng!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2Ô∏è‚É£ Tensor - Kh·ªëi X√¢y D·ª±ng C∆° B·∫£n\n",
    "\n",
    "## Tensor L√† G√¨?\n",
    "\n",
    "**Tensor** = M·∫£ng ƒëa chi·ªÅu (multi-dimensional array)\n",
    "\n",
    "Gi·ªëng nh∆∞ `ndarray` trong NumPy nh∆∞ng c√≥ 2 t√≠nh nƒÉng ƒë·∫∑c bi·ªát:\n",
    "1. ‚úÖ Ch·∫°y tr√™n GPU (tƒÉng t·ªëc)\n",
    "2. ‚úÖ T·ª± ƒë·ªông t√≠nh ƒë·∫°o h√†m (Autograd)\n",
    "\n",
    "### C√°c Chi·ªÅu C·ªßa Tensor\n",
    "\n",
    "```\n",
    "0D (Scalar):     5                ‚Üí shape: ()\n",
    "1D (Vector):     [1, 2, 3]        ‚Üí shape: (3,)\n",
    "2D (Matrix):     [[1, 2],         ‚Üí shape: (2, 3)\n",
    "                  [3, 4],\n",
    "                  [5, 6]]\n",
    "3D Tensor:       [[[1, 2],...]]   ‚Üí shape: (2, 3, 4)\n",
    "```\n",
    "\n",
    "### V√≠ D·ª• Th·ª±c T·∫ø\n",
    "\n",
    "- **·∫¢nh RGB**: `(Height, Width, Channels)` ‚Üí `(224, 224, 3)`\n",
    "- **Batch ·∫£nh**: `(Batch, Channels, Height, Width)` ‚Üí `(32, 3, 224, 224)`\n",
    "- **Video**: `(Time, Height, Width, Channels)` ‚Üí `(30, 224, 224, 3)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3Ô∏è‚É£ T·∫°o Tensor\n",
    "\n",
    "## 3.1 T·ª´ List/Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"T·∫†O TENSOR T·ª™ LIST\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Scalar (0D)\n",
    "scalar = torch.tensor(5)\n",
    "print(f\"\\n1. Scalar: {scalar}\")\n",
    "print(f\"   Shape: {scalar.shape}, Dimensions: {scalar.ndim}\")\n",
    "\n",
    "# Vector (1D)\n",
    "vector = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(f\"\\n2. Vector: {vector}\")\n",
    "print(f\"   Shape: {vector.shape}, Dimensions: {vector.ndim}\")\n",
    "\n",
    "# Matrix (2D)\n",
    "matrix = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6]])\n",
    "print(f\"\\n3. Matrix:\\n{matrix}\")\n",
    "print(f\"   Shape: {matrix.shape} ‚Üí 2 h√†ng, 3 c·ªôt\")\n",
    "print(f\"   Total elements: {matrix.numel()}\")\n",
    "\n",
    "# 3D Tensor\n",
    "tensor_3d = torch.tensor([[[1, 2], [3, 4]],\n",
    "                          [[5, 6], [7, 8]]])\n",
    "print(f\"\\n4. 3D Tensor:\\n{tensor_3d}\")\n",
    "print(f\"   Shape: {tensor_3d.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Tensor ƒê·∫∑c Bi·ªát"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TENSOR ƒê·∫∂C BI·ªÜT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Zeros - To√†n s·ªë 0\n",
    "zeros = torch.zeros(2, 3)\n",
    "print(f\"\\n1. Zeros (2x3):\\n{zeros}\")\n",
    "\n",
    "# 2. Ones - To√†n s·ªë 1\n",
    "ones = torch.ones(3, 2)\n",
    "print(f\"\\n2. Ones (3x2):\\n{ones}\")\n",
    "\n",
    "# 3. Full - Gi√° tr·ªã c·ª• th·ªÉ\n",
    "full = torch.full((2, 3), 7.5)\n",
    "print(f\"\\n3. Full (value=7.5):\\n{full}\")\n",
    "\n",
    "# 4. Identity - Ma tr·∫≠n ƒë∆°n v·ªã\n",
    "identity = torch.eye(4)\n",
    "print(f\"\\n4. Identity (4x4):\\n{identity}\")\n",
    "\n",
    "# 5. Arange - D√£y s·ªë li√™n ti·∫øp\n",
    "arange = torch.arange(0, 10, 2)  # start, end, step\n",
    "print(f\"\\n5. Arange (0 to 10, step 2): {arange}\")\n",
    "\n",
    "# 6. Linspace - Chia ƒë·ªÅu\n",
    "linspace = torch.linspace(0, 1, 5)  # 5 ƒëi·ªÉm t·ª´ 0 ƒë·∫øn 1\n",
    "print(f\"\\n6. Linspace (0 to 1, 5 points): {linspace}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Tensor Ng·∫´u Nhi√™n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TENSOR NG·∫™U NHI√äN\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Uniform distribution [0, 1)\n",
    "rand = torch.rand(2, 3)\n",
    "print(f\"\\n1. Uniform [0,1):\\n{rand}\")\n",
    "print(f\"   Min: {rand.min():.4f}, Max: {rand.max():.4f}\")\n",
    "\n",
    "# 2. Normal distribution (mean=0, std=1)\n",
    "randn = torch.randn(2, 3)\n",
    "print(f\"\\n2. Normal(0,1):\\n{randn}\")\n",
    "print(f\"   Mean: {randn.mean():.4f}, Std: {randn.std():.4f}\")\n",
    "\n",
    "# 3. Random integers\n",
    "randint = torch.randint(0, 10, (2, 3))  # [0, 10)\n",
    "print(f\"\\n3. Random integers [0,10):\\n{randint}\")\n",
    "\n",
    "# 4. Reproducibility v·ªõi seed\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"4. REPRODUCIBILITY (K·∫øt qu·∫£ gi·ªëng nhau)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "r1 = torch.rand(3)\n",
    "print(f\"L·∫ßn 1: {r1}\")\n",
    "\n",
    "torch.manual_seed(42)  # Same seed\n",
    "r2 = torch.rand(3)\n",
    "print(f\"L·∫ßn 2: {r2}\")\n",
    "print(f\"Gi·ªëng nhau: {torch.equal(r1, r2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 T·ª´ NumPy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"CHUY·ªÇN ƒê·ªîI NUMPY ‚Üî PYTORCH\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# NumPy ‚Üí PyTorch\n",
    "np_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "tensor = torch.from_numpy(np_array)\n",
    "\n",
    "print(f\"\\nNumPy array:\\n{np_array}\")\n",
    "print(f\"Type: {type(np_array)}\")\n",
    "\n",
    "print(f\"\\nPyTorch tensor:\\n{tensor}\")\n",
    "print(f\"Type: {type(tensor)}\")\n",
    "\n",
    "# PyTorch ‚Üí NumPy\n",
    "back_to_numpy = tensor.numpy()\n",
    "print(f\"\\nBack to NumPy:\\n{back_to_numpy}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚ö†Ô∏è QUAN TR·ªåNG: CHIA S·∫∫ B·ªò NH·ªö\")\n",
    "print(\"=\" * 70)\n",
    "print(\"from_numpy() ‚Üí Tensor v√† Array D√ôNG CHUNG b·ªô nh·ªõ!\")\n",
    "print(\"Thay ƒë·ªïi m·ªôt c√°i s·∫Ω ·∫£nh h∆∞·ªüng c√°i kia.\\n\")\n",
    "\n",
    "arr = np.array([1, 2, 3])\n",
    "ten = torch.from_numpy(arr)\n",
    "print(f\"Original: arr={arr}, tensor={ten}\")\n",
    "\n",
    "arr[0] = 999\n",
    "print(f\"After arr[0]=999: arr={arr}, tensor={ten}  ‚Üê C·∫£ hai ƒë·ªÅu ƒë·ªïi!\")\n",
    "\n",
    "print(\"\\n‚úÖ Gi·∫£i ph√°p: D√πng .clone() ƒë·ªÉ t·∫°o b·∫£n sao ƒë·ªôc l·∫≠p\")\n",
    "independent = torch.from_numpy(arr).clone()\n",
    "print(f\"Independent tensor: {independent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4Ô∏è‚É£ Thu·ªôc T√≠nh Tensor\n",
    "\n",
    "## 4.1 C√°c Thu·ªôc T√≠nh C∆° B·∫£n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o tensor m·∫´u\n",
    "x = torch.randn(2, 3, 4)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"THU·ªòC T√çNH TENSOR\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n1. Shape (k√≠ch th∆∞·ªõc): {x.shape}\")\n",
    "print(f\"   ‚Üí 2 'trang', m·ªói trang 3 h√†ng √ó 4 c·ªôt\")\n",
    "\n",
    "print(f\"\\n2. Dimensions (s·ªë chi·ªÅu): {x.ndim}\")\n",
    "\n",
    "print(f\"\\n3. Size (t·ªïng ph·∫ßn t·ª≠): {x.numel()}\")\n",
    "print(f\"   ‚Üí 2 √ó 3 √ó 4 = {2*3*4}\")\n",
    "\n",
    "print(f\"\\n4. Data type: {x.dtype}\")\n",
    "\n",
    "print(f\"\\n5. Device: {x.device}\")\n",
    "print(f\"   ‚Üí cpu (m·∫∑c ƒë·ªãnh)\")\n",
    "\n",
    "print(f\"\\n6. Requires grad: {x.requires_grad}\")\n",
    "print(f\"   ‚Üí False (m·∫∑c ƒë·ªãnh, s·∫Ω h·ªçc ·ªü File 1-B)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Data Types (dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"C√ÅC KI·ªÇU D·ªÆ LI·ªÜU PH·ªî BI·∫æN\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Float types\n",
    "print(\"\\n--- Float Types ---\")\n",
    "f32 = torch.tensor([1.5], dtype=torch.float32)\n",
    "print(f\"float32 (m·∫∑c ƒë·ªãnh): {f32}, dtype={f32.dtype}\")\n",
    "\n",
    "f16 = torch.tensor([1.5], dtype=torch.float16)\n",
    "print(f\"float16 (ti·∫øt ki·ªám memory): {f16}, dtype={f16.dtype}\")\n",
    "\n",
    "f64 = torch.tensor([1.5], dtype=torch.float64)\n",
    "print(f\"float64 (ch√≠nh x√°c cao): {f64}, dtype={f64.dtype}\")\n",
    "\n",
    "# Integer types\n",
    "print(\"\\n--- Integer Types ---\")\n",
    "i32 = torch.tensor([1], dtype=torch.int32)\n",
    "print(f\"int32: {i32}, dtype={i32.dtype}\")\n",
    "\n",
    "i64 = torch.tensor([1], dtype=torch.int64)\n",
    "print(f\"int64/long: {i64}, dtype={i64.dtype}\")\n",
    "\n",
    "# Boolean\n",
    "print(\"\\n--- Boolean ---\")\n",
    "b = torch.tensor([True, False], dtype=torch.bool)\n",
    "print(f\"bool: {b}, dtype={b.dtype}\")\n",
    "\n",
    "# Type conversion\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CHUY·ªÇN ƒê·ªîI KI·ªÇU\")\n",
    "print(\"=\" * 70)\n",
    "x = torch.tensor([1.5, 2.7, 3.9])\n",
    "print(f\"\\nOriginal (float32): {x}\")\n",
    "print(f\"To int: {x.int()}\")\n",
    "print(f\"To long: {x.long()}\")\n",
    "print(f\"To double: {x.double()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5Ô∏è‚É£ Indexing v√† Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o tensor m·∫´u\n",
    "x = torch.arange(1, 13).reshape(3, 4)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"INDEXING V√Ä SLICING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nTensor (3√ó4):\\n{x}\")\n",
    "\n",
    "print(\"\\n--- Basic Indexing ---\")\n",
    "print(f\"x[0, 1] = {x[0, 1]}  ‚Üê h√†ng 0, c·ªôt 1\")\n",
    "print(f\"x[2, 3] = {x[2, 3]}  ‚Üê h√†ng 2, c·ªôt 3\")\n",
    "\n",
    "print(\"\\n--- L·∫•y H√†ng/C·ªôt ---\")\n",
    "print(f\"x[0] (h√†ng 0): {x[0]}\")\n",
    "print(f\"x[:, 0] (c·ªôt 0): {x[:, 0]}\")\n",
    "\n",
    "print(\"\\n--- Slicing ---\")\n",
    "print(f\"x[:2] (2 h√†ng ƒë·∫ßu):\\n{x[:2]}\")\n",
    "print(f\"\\nx[:, 1:3] (c·ªôt 1-2):\\n{x[:, 1:3]}\")\n",
    "print(f\"\\nx[1:3, 2:4] (submatrix):\\n{x[1:3, 2:4]}\")\n",
    "\n",
    "print(\"\\n--- Negative Indexing ---\")\n",
    "print(f\"x[-1] (h√†ng cu·ªëi): {x[-1]}\")\n",
    "print(f\"x[:, -1] (c·ªôt cu·ªëi): {x[:, -1]}\")\n",
    "print(f\"x[-1, -1] (ph·∫ßn t·ª≠ cu·ªëi): {x[-1, -1]}\")\n",
    "\n",
    "print(\"\\n--- Step ---\")\n",
    "print(f\"x[::2] (m·ªói 2 h√†ng):\\n{x[::2]}\")\n",
    "print(f\"\\nx[:, ::2] (m·ªói 2 c·ªôt):\\n{x[:, ::2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"BOOLEAN INDEXING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "x = torch.arange(1, 13).reshape(3, 4)\n",
    "print(f\"\\nTensor:\\n{x}\")\n",
    "\n",
    "# T·∫°o mask\n",
    "mask = x > 6\n",
    "print(f\"\\nMask (x > 6):\\n{mask}\")\n",
    "\n",
    "# L·ªçc\n",
    "filtered = x[mask]\n",
    "print(f\"\\nPh·∫ßn t·ª≠ > 6: {filtered}\")\n",
    "\n",
    "# C√°c ƒëi·ªÅu ki·ªán kh√°c\n",
    "print(f\"\\nPh·∫ßn t·ª≠ ch·∫µn: {x[x % 2 == 0]}\")\n",
    "print(f\"Trong kho·∫£ng [4, 9]: {x[(x >= 4) & (x <= 9)]}\")\n",
    "\n",
    "# Thay ƒë·ªïi gi√° tr·ªã\n",
    "x_modified = x.clone()\n",
    "x_modified[x_modified > 6] = 0\n",
    "print(f\"\\nSau khi set >6 th√†nh 0:\\n{x_modified}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6Ô∏è‚É£ Reshape v√† Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RESHAPE - THAY ƒê·ªîI SHAPE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "x = torch.arange(12)\n",
    "print(f\"\\nOriginal (1D): {x}\")\n",
    "print(f\"Shape: {x.shape}\")\n",
    "\n",
    "# Reshape th√†nh 2D\n",
    "x_34 = x.reshape(3, 4)\n",
    "print(f\"\\nReshape(3, 4):\\n{x_34}\")\n",
    "\n",
    "x_43 = x.reshape(4, 3)\n",
    "print(f\"\\nReshape(4, 3):\\n{x_43}\")\n",
    "\n",
    "# D√πng -1 ƒë·ªÉ t·ª± ƒë·ªông t√≠nh\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"D√ôNG -1 ƒê·ªÇ T·ª∞ ƒê·ªòNG T√çNH\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "x_auto1 = x.reshape(3, -1)  # 3 h√†ng, t·ª± t√≠nh c·ªôt\n",
    "print(f\"\\nReshape(3, -1): {x_auto1.shape}\")\n",
    "print(x_auto1)\n",
    "\n",
    "x_auto2 = x.reshape(-1, 4)  # T·ª± t√≠nh h√†ng, 4 c·ªôt\n",
    "print(f\"\\nReshape(-1, 4): {x_auto2.shape}\")\n",
    "print(x_auto2)\n",
    "\n",
    "# Flatten v·ªÅ 1D\n",
    "x_flat = x.reshape(-1)\n",
    "print(f\"\\nReshape(-1): {x_flat.shape}\")\n",
    "print(x_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"VIEW, SQUEEZE, UNSQUEEZE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# view() vs reshape()\n",
    "x = torch.arange(12)\n",
    "x_view = x.view(3, 4)\n",
    "x_reshape = x.reshape(3, 4)\n",
    "print(\"view() v√† reshape() th∆∞·ªùng cho k·∫øt qu·∫£ gi·ªëng nhau\")\n",
    "print(\"view() nhanh h∆°n nh∆∞ng y√™u c·∫ßu memory li√™n t·ª•c\\n\")\n",
    "\n",
    "# squeeze() - X√≥a chi·ªÅu = 1\n",
    "print(\"-\" * 70)\n",
    "print(\"SQUEEZE - X√≥a chi·ªÅu = 1\")\n",
    "print(\"-\" * 70)\n",
    "x = torch.ones(1, 3, 1, 4)\n",
    "print(f\"\\nTr∆∞·ªõc: {x.shape}\")\n",
    "x_squeezed = x.squeeze()\n",
    "print(f\"Sau squeeze(): {x_squeezed.shape}\")\n",
    "\n",
    "# unsqueeze() - Th√™m chi·ªÅu = 1\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"UNSQUEEZE - Th√™m chi·ªÅu = 1\")\n",
    "print(\"-\" * 70)\n",
    "x = torch.arange(3)\n",
    "print(f\"\\nOriginal: {x}, Shape: {x.shape}\")\n",
    "\n",
    "x0 = x.unsqueeze(0)\n",
    "print(f\"\\nUnsqueeze(0): {x0}\")\n",
    "print(f\"Shape: {x0.shape}\")\n",
    "\n",
    "x1 = x.unsqueeze(1)\n",
    "print(f\"\\nUnsqueeze(1):\\n{x1}\")\n",
    "print(f\"Shape: {x1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TRANSPOSE & PERMUTE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Transpose 2D\n",
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "print(f\"\\nOriginal (2√ó3):\\n{x}\")\n",
    "\n",
    "x_t = x.T  # ho·∫∑c x.transpose(0, 1)\n",
    "print(f\"\\nTranspose (3√ó2):\\n{x_t}\")\n",
    "\n",
    "# Permute cho nhi·ªÅu chi·ªÅu\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"PERMUTE - Ho√°n v·ªã nhi·ªÅu chi·ªÅu\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "x = torch.randn(2, 3, 4)  # (batch, height, width)\n",
    "print(f\"\\nOriginal: {x.shape}\")\n",
    "\n",
    "x_perm = x.permute(0, 2, 1)  # (batch, width, height)\n",
    "print(f\"Permute(0,2,1): {x_perm.shape}\")\n",
    "\n",
    "# V√≠ d·ª•: Image (B, C, H, W) ‚Üí (B, H, W, C)\n",
    "img = torch.randn(8, 3, 224, 224)\n",
    "print(f\"\\nImage (B,C,H,W): {img.shape}\")\n",
    "img_hwc = img.permute(0, 2, 3, 1)\n",
    "print(f\"Permute to (B,H,W,C): {img_hwc.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7Ô∏è‚É£ Ph√©p To√°n S·ªë H·ªçc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"PH√âP TO√ÅN ELEMENT-WISE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "a = torch.tensor([[1.0, 2.0, 3.0],\n",
    "                  [4.0, 5.0, 6.0]])\n",
    "b = torch.tensor([[7.0, 8.0, 9.0],\n",
    "                  [10.0, 11.0, 12.0]])\n",
    "\n",
    "print(f\"\\na (2√ó3):\\n{a}\")\n",
    "print(f\"\\nb (2√ó3):\\n{b}\")\n",
    "\n",
    "print(\"\\n--- C·ªông ---\")\n",
    "print(a + b)\n",
    "\n",
    "print(\"\\n--- Tr·ª´ ---\")\n",
    "print(a - b)\n",
    "\n",
    "print(\"\\n--- Nh√¢n (element-wise) ---\")\n",
    "print(a * b)\n",
    "print(\"‚ö†Ô∏è Ch√∫ √Ω: ƒê√¢y l√† nh√¢n T·ª™NG ph·∫ßn t·ª≠, kh√¥ng ph·∫£i nh√¢n ma tr·∫≠n!\")\n",
    "\n",
    "print(\"\\n--- Chia ---\")\n",
    "print(b / a)\n",
    "\n",
    "print(\"\\n--- L≈©y th·ª´a ---\")\n",
    "print(f\"a¬≤:\\n{a ** 2}\")\n",
    "\n",
    "print(\"\\n--- CƒÉn b·∫≠c hai ---\")\n",
    "print(f\"‚àöa:\\n{torch.sqrt(a)}\")\n",
    "\n",
    "print(\"\\n--- H√†m s·ªë kh√°c ---\")\n",
    "print(f\"exp(a):\\n{torch.exp(a)}\")\n",
    "print(f\"\\nlog(a):\\n{torch.log(a)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"BROADCASTING - T·ª∞ ƒê·ªòNG M·ªû R·ªòNG\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nBroadcasting = PyTorch t·ª± ƒë·ªông m·ªü r·ªông tensor nh·ªè ƒë·ªÉ match tensor l·ªõn\\n\")\n",
    "\n",
    "# V√≠ d·ª• 1: Matrix + Scalar\n",
    "print(\"-\" * 70)\n",
    "print(\"1. Matrix (2√ó3) + Scalar\")\n",
    "print(\"-\" * 70)\n",
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "print(f\"\\nx:\\n{x}\")\n",
    "print(f\"\\nx + 10:\\n{x + 10}\")\n",
    "print(\"‚Üí 10 ƒë∆∞·ª£c broadcast th√†nh [[10,10,10], [10,10,10]]\")\n",
    "\n",
    "# V√≠ d·ª• 2: Matrix + Vector\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"2. Matrix (2√ó3) + Vector (3,)\")\n",
    "print(\"-\" * 70)\n",
    "matrix = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6]])\n",
    "vector = torch.tensor([10, 20, 30])\n",
    "print(f\"\\nMatrix:\\n{matrix}\")\n",
    "print(f\"\\nVector: {vector}\")\n",
    "result = matrix + vector\n",
    "print(f\"\\nMatrix + Vector:\\n{result}\")\n",
    "print(\"‚Üí Vector ƒë∆∞·ª£c broadcast th√†nh [[10,20,30], [10,20,30]]\")\n",
    "\n",
    "# V√≠ d·ª• 3: Column + Row\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"3. Column (3√ó1) + Row (1√ó4)\")\n",
    "print(\"-\" * 70)\n",
    "col = torch.tensor([[1],\n",
    "                    [2],\n",
    "                    [3]])\n",
    "row = torch.tensor([[10, 20, 30, 40]])\n",
    "result = col + row\n",
    "print(f\"\\nColumn (3√ó1):\\n{col}\")\n",
    "print(f\"\\nRow (1√ó4):\\n{row}\")\n",
    "print(f\"\\nResult (3√ó4):\\n{result}\")\n",
    "print(f\"Shape: {result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 8Ô∏è‚É£ Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"‚ö†Ô∏è PH√ÇN BI·ªÜT * V√Ä @\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "A = torch.tensor([[1, 2],\n",
    "                  [3, 4]], dtype=torch.float32)\n",
    "B = torch.tensor([[5, 6],\n",
    "                  [7, 8]], dtype=torch.float32)\n",
    "\n",
    "print(f\"\\nA (2√ó2):\\n{A}\")\n",
    "print(f\"\\nB (2√ó2):\\n{B}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"1. ELEMENT-WISE: A * B\")\n",
    "print(\"-\" * 70)\n",
    "print(A * B)\n",
    "print(\"‚Üí Nh√¢n t·ª´ng ph·∫ßn t·ª≠: [i,j] = A[i,j] * B[i,j]\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"2. MATRIX MULTIPLICATION: A @ B\")\n",
    "print(\"-\" * 70)\n",
    "print(A @ B)\n",
    "print(\"‚Üí Nh√¢n ma tr·∫≠n chu·∫©n\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üí° GHI NH·ªö:\")\n",
    "print(\"  * : Element-wise (shape ph·∫£i gi·ªëng ho·∫∑c broadcast ƒë∆∞·ª£c)\")\n",
    "print(\"  @ : Matrix mult (c·ªôt A = h√†ng B)\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"C√ÅC C√ÅCH NH√ÇN MA TR·∫¨N\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "A = torch.randn(3, 4)\n",
    "B = torch.randn(4, 5)\n",
    "\n",
    "print(f\"A: {A.shape}\")\n",
    "print(f\"B: {B.shape}\")\n",
    "\n",
    "# C√°ch 1: @ operator (khuy·∫øn kh√≠ch)\n",
    "C1 = A @ B\n",
    "print(f\"\\n1. A @ B: {C1.shape}\")\n",
    "\n",
    "# C√°ch 2: torch.matmul()\n",
    "C2 = torch.matmul(A, B)\n",
    "print(f\"2. torch.matmul(A, B): {C2.shape}\")\n",
    "\n",
    "# C√°ch 3: torch.mm() (ch·ªâ 2D)\n",
    "C3 = torch.mm(A, B)\n",
    "print(f\"3. torch.mm(A, B): {C3.shape}\")\n",
    "\n",
    "print(f\"\\nK·∫øt qu·∫£ gi·ªëng nhau: {torch.allclose(C1, C2) and torch.allclose(C1, C3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"MATRIX √ó VECTOR\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "matrix = torch.tensor([[1.0, 2.0, 3.0],\n",
    "                       [4.0, 5.0, 6.0]])  # 2√ó3\n",
    "vector = torch.tensor([10.0, 20.0, 30.0])  # 3\n",
    "\n",
    "result = matrix @ vector  # 2√ó3 @ 3 = 2\n",
    "\n",
    "print(f\"\\nMatrix (2√ó3):\\n{matrix}\")\n",
    "print(f\"\\nVector (3,): {vector}\")\n",
    "print(f\"\\nResult (2,): {result}\")\n",
    "\n",
    "print(\"\\nGi·∫£i th√≠ch:\")\n",
    "print(f\"  result[0] = 1√ó10 + 2√ó20 + 3√ó30 = {1*10 + 2*20 + 3*30}\")\n",
    "print(f\"  result[1] = 4√ó10 + 5√ó20 + 6√ó30 = {4*10 + 5*20 + 6*30}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 9Ô∏è‚É£ C√°c Ph√©p To√°n Th·ªëng K√™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TH·ªêNG K√ä C∆† B·∫¢N\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "x = torch.tensor([[1.0, 2.0, 3.0, 4.0],\n",
    "                  [5.0, 6.0, 7.0, 8.0],\n",
    "                  [9.0, 10.0, 11.0, 12.0]])\n",
    "\n",
    "print(f\"\\nTensor (3√ó4):\\n{x}\")\n",
    "\n",
    "print(\"\\n--- Sum ---\")\n",
    "print(f\"T·ªïng t·∫•t c·∫£: {x.sum()}\")\n",
    "print(f\"T·ªïng theo h√†ng (dim=1): {x.sum(dim=1)}\")\n",
    "print(f\"T·ªïng theo c·ªôt (dim=0): {x.sum(dim=0)}\")\n",
    "\n",
    "print(\"\\n--- Mean ---\")\n",
    "print(f\"Trung b√¨nh: {x.mean()}\")\n",
    "print(f\"TB theo h√†ng: {x.mean(dim=1)}\")\n",
    "\n",
    "print(\"\\n--- Max / Min ---\")\n",
    "print(f\"Max: {x.max()}\")\n",
    "print(f\"Min: {x.min()}\")\n",
    "\n",
    "# max() v·ªõi dim tr·∫£ v·ªÅ (values, indices)\n",
    "max_vals, max_idx = x.max(dim=1)\n",
    "print(f\"\\nMax theo h√†ng:\")\n",
    "print(f\"  Values: {max_vals}\")\n",
    "print(f\"  Indices: {max_idx}\")\n",
    "\n",
    "print(\"\\n--- ArgMax / ArgMin ---\")\n",
    "print(f\"Ch·ªâ s·ªë c·ªßa max: {x.argmax()}\")\n",
    "print(f\"ArgMax theo h√†ng: {x.argmax(dim=1)}\")\n",
    "\n",
    "print(\"\\n--- Std & Var ---\")\n",
    "print(f\"ƒê·ªô l·ªách chu·∫©n: {x.std():.4f}\")\n",
    "print(f\"Ph∆∞∆°ng sai: {x.var():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"S·∫ÆP X·∫æP & TOP-K\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "x = torch.tensor([5, 2, 8, 1, 9, 3])\n",
    "print(f\"\\nOriginal: {x}\")\n",
    "\n",
    "# Sort\n",
    "sorted_vals, sorted_idx = torch.sort(x)\n",
    "print(f\"\\nSorted (ascending):\")\n",
    "print(f\"  Values: {sorted_vals}\")\n",
    "print(f\"  Indices: {sorted_idx}\")\n",
    "\n",
    "sorted_desc, _ = torch.sort(x, descending=True)\n",
    "print(f\"\\nSorted (descending): {sorted_desc}\")\n",
    "\n",
    "# Top K\n",
    "top_vals, top_idx = torch.topk(x, k=3)\n",
    "print(f\"\\nTop 3:\")\n",
    "print(f\"  Values: {top_vals}\")\n",
    "print(f\"  Indices: {top_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üîü Concatenation & Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"CONCATENATION - N·ªêI TENSOR\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "t1 = torch.tensor([[1, 2],\n",
    "                   [3, 4]])\n",
    "t2 = torch.tensor([[5, 6],\n",
    "                   [7, 8]])\n",
    "\n",
    "print(f\"\\nt1 (2√ó2):\\n{t1}\")\n",
    "print(f\"\\nt2 (2√ó2):\\n{t2}\")\n",
    "\n",
    "# Cat theo dim=0 (h√†ng)\n",
    "cat0 = torch.cat([t1, t2], dim=0)\n",
    "print(f\"\\ncat(dim=0) ‚Üí (4√ó2):\\n{cat0}\")\n",
    "\n",
    "# Cat theo dim=1 (c·ªôt)\n",
    "cat1 = torch.cat([t1, t2], dim=1)\n",
    "print(f\"\\ncat(dim=1) ‚Üí (2√ó4):\\n{cat1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"STACK - T·∫†O CHI·ªÄU M·ªöI\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "t1 = torch.tensor([[1, 2],\n",
    "                   [3, 4]])\n",
    "t2 = torch.tensor([[5, 6],\n",
    "                   [7, 8]])\n",
    "\n",
    "print(f\"\\nt1 & t2 shape: {t1.shape}\")\n",
    "\n",
    "# Stack dim=0\n",
    "stack0 = torch.stack([t1, t2], dim=0)\n",
    "print(f\"\\nstack(dim=0): {stack0.shape}\")\n",
    "print(stack0)\n",
    "\n",
    "# Stack dim=1\n",
    "stack1 = torch.stack([t1, t2], dim=1)\n",
    "print(f\"\\nstack(dim=1): {stack1.shape}\")\n",
    "print(stack1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PH√ÇN BI·ªÜT:\")\n",
    "print(\"  cat():   N·ªëi theo chi·ªÅu C√ì S·∫¥N\")\n",
    "print(\"  stack(): T·∫°o chi·ªÅu M·ªöI\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ‚úÖ T·ªïng K·∫øt FILE 1-A\n",
    "\n",
    "## B·∫°n ƒê√£ H·ªçc ƒê∆∞·ª£c\n",
    "\n",
    "‚úÖ PyTorch l√† g√¨ v√† t·∫°i sao quan tr·ªçng\n",
    "\n",
    "‚úÖ Tensor - kh·ªëi x√¢y d·ª±ng c∆° b·∫£n c·ªßa Deep Learning\n",
    "\n",
    "‚úÖ C√°c c√°ch t·∫°o tensor (list, zeros, ones, random, from numpy)\n",
    "\n",
    "‚úÖ Thu·ªôc t√≠nh tensor (shape, dtype, device, ndim, numel)\n",
    "\n",
    "‚úÖ Indexing, slicing, boolean indexing\n",
    "\n",
    "‚úÖ Reshape, view, squeeze, unsqueeze, transpose, permute\n",
    "\n",
    "‚úÖ Ph√©p to√°n s·ªë h·ªçc (element-wise v√† broadcasting)\n",
    "\n",
    "‚úÖ Matrix multiplication (@ vs *)\n",
    "\n",
    "‚úÖ C√°c ph√©p to√°n th·ªëng k√™ (sum, mean, max, min, std, var)\n",
    "\n",
    "‚úÖ Concatenation v√† stacking\n",
    "\n",
    "---\n",
    "\n",
    "## B√†i T·∫≠p Th·ª±c H√†nh\n",
    "\n",
    "### B√†i 1: T·∫°o v√† Thao T√°c Tensor\n",
    "1. T·∫°o tensor 3√ó4 ch·ª©a c√°c s·ªë t·ª´ 1 ƒë·∫øn 12\n",
    "2. L·∫•y h√†ng th·ª© 2\n",
    "3. L·∫•y c·ªôt cu·ªëi c√πng\n",
    "4. L·∫•y submatrix 2√ó2 t·ª´ g√≥c d∆∞·ªõi ph·∫£i\n",
    "\n",
    "### B√†i 2: Reshape\n",
    "1. T·∫°o tensor 1D c√≥ 24 ph·∫ßn t·ª≠\n",
    "2. Reshape th√†nh (2, 3, 4)\n",
    "3. Reshape th√†nh (4, 6)\n",
    "4. Flatten v·ªÅ 1D\n",
    "\n",
    "### B√†i 3: Broadcasting\n",
    "1. T·∫°o matrix 3√ó4 v√† vector 4\n",
    "2. C·ªông matrix v·ªõi vector (broadcasting)\n",
    "3. T·∫°o column vector 3√ó1 v√† row vector 1√ó4\n",
    "4. Nh√¢n ch√∫ng v·ªõi nhau\n",
    "\n",
    "### B√†i 4: Matrix Multiplication\n",
    "1. T·∫°o matrix A (3√ó4) v√† B (4√ó2)\n",
    "2. T√≠nh A @ B\n",
    "3. So s√°nh k·∫øt qu·∫£ v·ªõi t√≠nh th·ªß c√¥ng\n",
    "\n",
    "### B√†i 5: Th·ªëng K√™\n",
    "1. T·∫°o tensor ng·∫´u nhi√™n 5√ó6\n",
    "2. T√¨m max c·ªßa m·ªói h√†ng\n",
    "3. T√¨m mean c·ªßa m·ªói c·ªôt\n",
    "4. T√¨m top 3 gi√° tr·ªã l·ªõn nh·∫•t\n",
    "\n",
    "---\n",
    "\n",
    "## Ti·∫øp Theo\n",
    "\n",
    "üìò **FILE 1-B: Autograd & Training from Scratch**\n",
    "\n",
    "B·∫°n s·∫Ω h·ªçc:\n",
    "- Gradient l√† g√¨\n",
    "- Autograd ho·∫°t ƒë·ªông th·∫ø n√†o\n",
    "- X√¢y d·ª±ng Linear Regression t·ª´ ƒë·∫ßu\n",
    "- Training loop c∆° b·∫£n\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
