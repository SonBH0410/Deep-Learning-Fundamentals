{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìï PYTORCH FILE 3-C: PRODUCTION & BEST PRACTICES\n",
    "\n",
    "**Ph·∫ßn:** ADVANCED & PROFESSIONAL - FINAL\n",
    "\n",
    "**M·ª•c ti√™u:**\n",
    "- ‚úÖ Clean ML Pipeline\n",
    "- ‚úÖ Reproducibility\n",
    "- ‚úÖ Model Evaluation & Metrics\n",
    "- ‚úÖ Save & Load Models\n",
    "- ‚úÖ Inference Pipeline\n",
    "- ‚úÖ Performance Optimization\n",
    "- ‚úÖ Production Best Practices\n",
    "- ‚úÖ Common Anti-patterns\n",
    "\n",
    "**Th·ªùi l∆∞·ª£ng:** 2-3 tu·∫ßn\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö M·ª•c L·ª•c\n",
    "\n",
    "### PH·∫¶N 1: CLEAN ML PIPELINE\n",
    "1. Pipeline Architecture\n",
    "2. Config Management\n",
    "3. Data Pipeline\n",
    "4. Training Pipeline\n",
    "5. Experiment Tracking\n",
    "\n",
    "### PH·∫¶N 2: REPRODUCIBILITY\n",
    "1. Random Seeds\n",
    "2. Deterministic Operations\n",
    "3. Environment Management\n",
    "4. Version Control\n",
    "\n",
    "### PH·∫¶N 3: MODEL EVALUATION\n",
    "1. Classification Metrics\n",
    "2. Confusion Matrix\n",
    "3. ROC & AUC\n",
    "4. Cross-validation\n",
    "\n",
    "### PH·∫¶N 4: SAVE & LOAD MODELS\n",
    "1. torch.save() & torch.load()\n",
    "2. State Dict\n",
    "3. Checkpoints\n",
    "4. ONNX Export\n",
    "\n",
    "### PH·∫¶N 5: PRODUCTION BEST PRACTICES\n",
    "1. Model Versioning\n",
    "2. Monitoring\n",
    "3. Performance Optimization\n",
    "4. Common Anti-patterns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import th∆∞ vi·ªán\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import yaml\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_curve, auc, classification_report\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"‚úÖ Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PH·∫¶N 1: CLEAN ML PIPELINE\n",
    "\n",
    "## 1.1 Pipeline Architecture\n",
    "\n",
    "### Clean ML Pipeline\n",
    "\n",
    "```\n",
    "Config ‚Üí Data Pipeline ‚Üí Model ‚Üí Training ‚Üí Evaluation ‚Üí Save/Export\n",
    "```\n",
    "\n",
    "### Benefits\n",
    "\n",
    "- ‚úÖ **Reproducible**: C√πng config ‚Üí c√πng k·∫øt qu·∫£\n",
    "- ‚úÖ **Maintainable**: D·ªÖ debug, update\n",
    "- ‚úÖ **Scalable**: D·ªÖ scale l√™n production\n",
    "- ‚úÖ **Collaborative**: Team d·ªÖ l√†m vi·ªác\n",
    "\n",
    "## 1.2 Config Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config class\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configuration for ML pipeline\"\"\"\n",
    "    \n",
    "    # Data\n",
    "    DATA_DIR = './data'\n",
    "    BATCH_SIZE = 32\n",
    "    NUM_WORKERS = 4\n",
    "    \n",
    "    # Model\n",
    "    MODEL_NAME = 'resnet18'\n",
    "    NUM_CLASSES = 10\n",
    "    PRETRAINED = True\n",
    "    \n",
    "    # Training\n",
    "    EPOCHS = 50\n",
    "    LEARNING_RATE = 0.001\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    OPTIMIZER = 'adam'\n",
    "    \n",
    "    # Scheduler\n",
    "    SCHEDULER = 'cosine'\n",
    "    T_MAX = 50\n",
    "    ETA_MIN = 1e-6\n",
    "    \n",
    "    # Paths\n",
    "    MODEL_DIR = './models'\n",
    "    LOG_DIR = './logs'\n",
    "    CHECKPOINT_DIR = './checkpoints'\n",
    "    \n",
    "    # Reproducibility\n",
    "    SEED = 42\n",
    "    \n",
    "    @classmethod\n",
    "    def to_dict(cls):\n",
    "        \"\"\"Convert to dictionary\"\"\"\n",
    "        return {k: v for k, v in cls.__dict__.items() \n",
    "                if not k.startswith('_') and not callable(v)}\n",
    "    \n",
    "    @classmethod\n",
    "    def save(cls, path):\n",
    "        \"\"\"Save config to JSON\"\"\"\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(cls.to_dict(), f, indent=2)\n",
    "        print(f\"‚úÖ Config saved to {path}\")\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        \"\"\"Load config from JSON\"\"\"\n",
    "        with open(path, 'r') as f:\n",
    "            config_dict = json.load(f)\n",
    "        \n",
    "        for key, value in config_dict.items():\n",
    "            setattr(cls, key, value)\n",
    "        \n",
    "        print(f\"‚úÖ Config loaded from {path}\")\n",
    "\n",
    "# Test\n",
    "config = Config()\n",
    "print(\"üìã Config:\")\n",
    "print(json.dumps(config.to_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Training Pipeline Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingPipeline:\n",
    "    \"\"\"\n",
    "    Clean training pipeline\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Create directories\n",
    "        self._create_directories()\n",
    "        \n",
    "        # Set seeds\n",
    "        self._set_seeds()\n",
    "        \n",
    "        # Initialize\n",
    "        self.model = None\n",
    "        self.optimizer = None\n",
    "        self.scheduler = None\n",
    "        self.criterion = None\n",
    "        self.history = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    def _create_directories(self):\n",
    "        \"\"\"Create necessary directories\"\"\"\n",
    "        Path(self.config.MODEL_DIR).mkdir(parents=True, exist_ok=True)\n",
    "        Path(self.config.LOG_DIR).mkdir(parents=True, exist_ok=True)\n",
    "        Path(self.config.CHECKPOINT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "        print(\"‚úÖ Directories created\")\n",
    "    \n",
    "    def _set_seeds(self):\n",
    "        \"\"\"Set random seeds for reproducibility\"\"\"\n",
    "        torch.manual_seed(self.config.SEED)\n",
    "        torch.cuda.manual_seed_all(self.config.SEED)\n",
    "        np.random.seed(self.config.SEED)\n",
    "        random.seed(self.config.SEED)\n",
    "        \n",
    "        # Deterministic behavior\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "        print(f\"‚úÖ Seeds set to {self.config.SEED}\")\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"Build model from config\"\"\"\n",
    "        import torchvision.models as models\n",
    "        \n",
    "        # Load base model\n",
    "        if self.config.MODEL_NAME == 'resnet18':\n",
    "            base_model = models.resnet18(pretrained=self.config.PRETRAINED)\n",
    "            num_features = base_model.fc.in_features\n",
    "            base_model.fc = nn.Linear(num_features, self.config.NUM_CLASSES)\n",
    "            self.model = base_model\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        print(f\"‚úÖ Model built: {self.config.MODEL_NAME}\")\n",
    "        return self.model\n",
    "    \n",
    "    def build_optimizer(self):\n",
    "        \"\"\"Build optimizer from config\"\"\"\n",
    "        if self.config.OPTIMIZER == 'adam':\n",
    "            self.optimizer = optim.Adam(\n",
    "                self.model.parameters(),\n",
    "                lr=self.config.LEARNING_RATE,\n",
    "                weight_decay=self.config.WEIGHT_DECAY\n",
    "            )\n",
    "        elif self.config.OPTIMIZER == 'sgd':\n",
    "            self.optimizer = optim.SGD(\n",
    "                self.model.parameters(),\n",
    "                lr=self.config.LEARNING_RATE,\n",
    "                momentum=0.9,\n",
    "                weight_decay=self.config.WEIGHT_DECAY\n",
    "            )\n",
    "        \n",
    "        print(f\"‚úÖ Optimizer: {self.config.OPTIMIZER}\")\n",
    "        return self.optimizer\n",
    "    \n",
    "    def build_scheduler(self):\n",
    "        \"\"\"Build LR scheduler from config\"\"\"\n",
    "        if self.config.SCHEDULER == 'cosine':\n",
    "            self.scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "                self.optimizer,\n",
    "                T_max=self.config.T_MAX,\n",
    "                eta_min=self.config.ETA_MIN\n",
    "            )\n",
    "        elif self.config.SCHEDULER == 'step':\n",
    "            self.scheduler = optim.lr_scheduler.StepLR(\n",
    "                self.optimizer,\n",
    "                step_size=30,\n",
    "                gamma=0.1\n",
    "            )\n",
    "        \n",
    "        print(f\"‚úÖ Scheduler: {self.config.SCHEDULER}\")\n",
    "        return self.scheduler\n",
    "    \n",
    "    def train_epoch(self, train_loader):\n",
    "        \"\"\"Train one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        return total_loss / len(train_loader)\n",
    "    \n",
    "    def validate(self, val_loader):\n",
    "        \"\"\"Validate model\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                \n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        avg_loss = total_loss / len(val_loader)\n",
    "        accuracy = 100. * correct / total\n",
    "        \n",
    "        return avg_loss, accuracy\n",
    "    \n",
    "    def train(self, train_loader, val_loader):\n",
    "        \"\"\"Complete training loop\"\"\"\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        print(f\"\\nüöÄ Starting training for {self.config.EPOCHS} epochs...\\n\")\n",
    "        \n",
    "        for epoch in range(self.config.EPOCHS):\n",
    "            # Train\n",
    "            train_loss = self.train_epoch(train_loader)\n",
    "            \n",
    "            # Validate\n",
    "            val_loss, val_acc = self.validate(val_loader)\n",
    "            \n",
    "            # Scheduler step\n",
    "            if self.scheduler is not None:\n",
    "                self.scheduler.step()\n",
    "            \n",
    "            # Record history\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['val_acc'].append(val_acc)\n",
    "            \n",
    "            # Print progress\n",
    "            print(f\"Epoch {epoch+1}/{self.config.EPOCHS}:\")\n",
    "            print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "            print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "            \n",
    "            # Save checkpoint\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                self.save_checkpoint(epoch + 1)\n",
    "        \n",
    "        print(\"\\n‚úÖ Training completed!\")\n",
    "        return self.history\n",
    "    \n",
    "    def save_checkpoint(self, epoch):\n",
    "        \"\"\"Save checkpoint\"\"\"\n",
    "        checkpoint_path = Path(self.config.CHECKPOINT_DIR) / f'checkpoint_epoch_{epoch}.pth'\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,\n",
    "            'history': self.history\n",
    "        }, checkpoint_path)\n",
    "        print(f\"  üíæ Checkpoint saved: {checkpoint_path}\")\n",
    "    \n",
    "    def save_model(self, name='final_model'):\n",
    "        \"\"\"Save final model\"\"\"\n",
    "        model_path = Path(self.config.MODEL_DIR) / f'{name}.pth'\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "        print(f\"‚úÖ Model saved to {model_path}\")\n",
    "\n",
    "print(\"‚úÖ TrainingPipeline class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PH·∫¶N 2: REPRODUCIBILITY\n",
    "\n",
    "## 2.1 Random Seeds\n",
    "\n",
    "### T·∫°i sao c·∫ßn Reproducibility?\n",
    "\n",
    "- ‚úÖ **Debug**: D·ªÖ t√¨m l·ªói v·ªõi consistent results\n",
    "- ‚úÖ **Research**: Validate k·∫øt qu·∫£\n",
    "- ‚úÖ **Production**: ƒê·∫£m b·∫£o deployment gi·ªëng training\n",
    "- ‚úÖ **Collaboration**: Team c√≥ th·ªÉ reproduce\n",
    "\n",
    "### Set All Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    \"\"\"\n",
    "    Set all random seeds for reproducibility\n",
    "    \n",
    "    Args:\n",
    "        seed: Random seed value\n",
    "    \"\"\"\n",
    "    # Python random\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # NumPy\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # multi-GPU\n",
    "    \n",
    "    # CUDA\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # Environment variable\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    print(f\"‚úÖ All seeds set to {seed}\")\n",
    "    print(\"‚ö†Ô∏è  Deterministic mode may be slower (~10%)\")\n",
    "\n",
    "# Test\n",
    "set_seed(42)\n",
    "\n",
    "# Generate random numbers\n",
    "print(\"\\nüé≤ Test reproducibility:\")\n",
    "print(f\"Python random: {random.random()}\")\n",
    "print(f\"NumPy random: {np.random.rand()}\")\n",
    "print(f\"PyTorch random: {torch.rand(1).item()}\")\n",
    "\n",
    "# Reset and test again\n",
    "set_seed(42)\n",
    "print(\"\\nüé≤ After reset (should be same):\")\n",
    "print(f\"Python random: {random.random()}\")\n",
    "print(f\"NumPy random: {np.random.rand()}\")\n",
    "print(f\"PyTorch random: {torch.rand(1).item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Environment Info Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_environment_info(save_path='environment_info.json'):\n",
    "    \"\"\"\n",
    "    Log environment information for reproducibility\n",
    "    \"\"\"\n",
    "    import platform\n",
    "    import sys\n",
    "    \n",
    "    env_info = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'python_version': sys.version,\n",
    "        'platform': platform.platform(),\n",
    "        'pytorch_version': torch.__version__,\n",
    "        'cuda_available': torch.cuda.is_available(),\n",
    "        'cuda_version': torch.version.cuda if torch.cuda.is_available() else 'N/A',\n",
    "        'cudnn_version': torch.backends.cudnn.version() if torch.cuda.is_available() else 'N/A',\n",
    "        'device_name': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'\n",
    "    }\n",
    "    \n",
    "    # Save\n",
    "    with open(save_path, 'w') as f:\n",
    "        json.dump(env_info, f, indent=2)\n",
    "    \n",
    "    print(\"‚úÖ Environment info saved!\")\n",
    "    print(\"\\nüìã Environment:\")\n",
    "    for key, value in env_info.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "    \n",
    "    return env_info\n",
    "\n",
    "# Log\n",
    "env_info = log_environment_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PH·∫¶N 3: MODEL EVALUATION\n",
    "\n",
    "## 3.1 Classification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Comprehensive classification evaluation\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    print(\"üìä EVALUATION RESULTS:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels,\n",
    "        'probabilities': all_probs\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Evaluation function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, class_names=None, normalize=False):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        fmt = '.2f'\n",
    "        title = 'Normalized Confusion Matrix'\n",
    "    else:\n",
    "        fmt = 'd'\n",
    "        title = 'Confusion Matrix'\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=fmt, cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Count' if not normalize else 'Proportion'})\n",
    "    plt.xlabel('Predicted', fontsize=12)\n",
    "    plt.ylabel('True', fontsize=12)\n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Confusion matrix function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PH·∫¶N 4: SAVE & LOAD MODELS\n",
    "\n",
    "## 4.1 Save & Load State Dict (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE - State Dict (recommended)\n",
    "\n",
    "# Create example model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 2)\n",
    ")\n",
    "\n",
    "# Save state dict\n",
    "save_path = 'model_state_dict.pth'\n",
    "torch.save(model.state_dict(), save_path)\n",
    "\n",
    "print(f\"‚úÖ Model state dict saved to {save_path}\")\n",
    "print(\"\\nüí° State dict = Only weights, not architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD - State Dict\n",
    "\n",
    "# Must create model with SAME architecture\n",
    "model_loaded = nn.Sequential(\n",
    "    nn.Linear(10, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 2)\n",
    ")\n",
    "\n",
    "# Load state dict\n",
    "model_loaded.load_state_dict(torch.load(save_path))\n",
    "model_loaded.eval()\n",
    "\n",
    "print(f\"‚úÖ Model state dict loaded from {save_path}\")\n",
    "\n",
    "# Verify\n",
    "x = torch.randn(5, 10)\n",
    "with torch.no_grad():\n",
    "    out1 = model(x)\n",
    "    out2 = model_loaded(x)\n",
    "\n",
    "print(f\"\\nüîç Outputs match: {torch.allclose(out1, out2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Save & Load Complete Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE - Complete Model\n",
    "\n",
    "save_path = 'complete_model.pth'\n",
    "torch.save(model, save_path)\n",
    "\n",
    "print(f\"‚úÖ Complete model saved to {save_path}\")\n",
    "print(\"\\nüí° Complete model = Architecture + Weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD - Complete Model\n",
    "\n",
    "model_loaded = torch.load(save_path)\n",
    "model_loaded.eval()\n",
    "\n",
    "print(f\"‚úÖ Complete model loaded from {save_path}\")\n",
    "print(\"\\n‚ö†Ô∏è  Warning: Less flexible, may break with PyTorch version changes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Save Checkpoint (Best Practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE - Checkpoint v·ªõi t·∫•t c·∫£ training state\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epoch = 10\n",
    "\n",
    "checkpoint = {\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': 0.123,\n",
    "}\n",
    "\n",
    "checkpoint_path = 'checkpoint.pth'\n",
    "torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "print(f\"‚úÖ Checkpoint saved to {checkpoint_path}\")\n",
    "print(\"\\nüí° Checkpoint includes:\")\n",
    "print(\"   - Epoch number\")\n",
    "print(\"   - Model weights\")\n",
    "print(\"   - Optimizer state\")\n",
    "print(\"   - Loss value\")\n",
    "print(\"   ‚Üí Can resume training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD - Checkpoint v√† resume training\n",
    "\n",
    "# Create model and optimizer\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 2)\n",
    ")\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "start_epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.train()  # Set to training mode\n",
    "\n",
    "print(f\"‚úÖ Checkpoint loaded from {checkpoint_path}\")\n",
    "print(f\"   Resume from epoch: {start_epoch}\")\n",
    "print(f\"   Previous loss: {loss}\")\n",
    "print(\"\\nüîÑ Ready to continue training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 ONNX Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to ONNX (cross-platform format)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Dummy input\n",
    "dummy_input = torch.randn(1, 10)\n",
    "\n",
    "# Export\n",
    "onnx_path = 'model.onnx'\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    onnx_path,\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input': {0: 'batch_size'},\n",
    "                  'output': {0: 'batch_size'}}\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model exported to ONNX: {onnx_path}\")\n",
    "print(\"\\nüí° ONNX format cho ph√©p:\")\n",
    "print(\"   - Deploy tr√™n nhi·ªÅu frameworks (TensorRT, ONNX Runtime, etc.)\")\n",
    "print(\"   - Cross-platform compatibility\")\n",
    "print(\"   - Inference optimization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PH·∫¶N 5: PRODUCTION BEST PRACTICES\n",
    "\n",
    "## 5.1 Model Versioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelRegistry:\n",
    "    \"\"\"\n",
    "    Simple model registry for versioning\n",
    "    \"\"\"\n",
    "    def __init__(self, base_dir='model_registry'):\n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.base_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Create subdirectories\n",
    "        for subdir in ['production', 'staging', 'archive']:\n",
    "            (self.base_dir / subdir).mkdir(exist_ok=True)\n",
    "    \n",
    "    def save_model(self, model, version, stage='staging', metadata=None):\n",
    "        \"\"\"\n",
    "        Save model with version\n",
    "        \"\"\"\n",
    "        # Create version directory\n",
    "        model_dir = self.base_dir / stage / f'v{version}'\n",
    "        model_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save model\n",
    "        model_path = model_dir / 'model.pth'\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        \n",
    "        # Save metadata\n",
    "        if metadata is None:\n",
    "            metadata = {}\n",
    "        \n",
    "        metadata.update({\n",
    "            'version': version,\n",
    "            'stage': stage,\n",
    "            'saved_at': datetime.now().isoformat(),\n",
    "            'pytorch_version': torch.__version__\n",
    "        })\n",
    "        \n",
    "        metadata_path = model_dir / 'metadata.json'\n",
    "        with open(metadata_path, 'w') as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "        \n",
    "        print(f\"‚úÖ Model v{version} saved to {stage}\")\n",
    "        return model_dir\n",
    "    \n",
    "    def load_model(self, model_class, version=None, stage='production'):\n",
    "        \"\"\"\n",
    "        Load model from registry\n",
    "        \"\"\"\n",
    "        stage_dir = self.base_dir / stage\n",
    "        \n",
    "        if version is None:\n",
    "            # Load latest\n",
    "            versions = sorted(stage_dir.iterdir())\n",
    "            if not versions:\n",
    "                raise ValueError(f\"No models in {stage}\")\n",
    "            model_dir = versions[-1]\n",
    "        else:\n",
    "            model_dir = stage_dir / f'v{version}'\n",
    "        \n",
    "        # Load model\n",
    "        model_path = model_dir / 'model.pth'\n",
    "        model = model_class()\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "        # Load metadata\n",
    "        metadata_path = model_dir / 'metadata.json'\n",
    "        with open(metadata_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        \n",
    "        print(f\"‚úÖ Loaded model v{metadata['version']} from {stage}\")\n",
    "        return model, metadata\n",
    "\n",
    "print(\"‚úÖ ModelRegistry class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Common Anti-patterns\n",
    "\n",
    "### ‚ùå ANTI-PATTERN 1: Kh√¥ng set random seeds\n",
    "\n",
    "```python\n",
    "# ‚ùå WRONG\n",
    "model = create_model()\n",
    "# Results kh√¥ng reproducible!\n",
    "\n",
    "# ‚úÖ CORRECT\n",
    "set_seed(42)\n",
    "model = create_model()\n",
    "```\n",
    "\n",
    "### ‚ùå ANTI-PATTERN 2: Kh√¥ng version models\n",
    "\n",
    "```python\n",
    "# ‚ùå WRONG\n",
    "torch.save(model.state_dict(), 'model.pth')  # Overwrite!\n",
    "\n",
    "# ‚úÖ CORRECT\n",
    "torch.save(model.state_dict(), f'model_v{version}.pth')\n",
    "```\n",
    "\n",
    "### ‚ùå ANTI-PATTERN 3: Kh√¥ng normalize data\n",
    "\n",
    "```python\n",
    "# ‚ùå WRONG\n",
    "# Training: normalize\n",
    "train_data = train_data / 255.0\n",
    "# Inference: kh√¥ng normalize!\n",
    "prediction = model(test_data)  # Bug!\n",
    "\n",
    "# ‚úÖ CORRECT\n",
    "def preprocess(data):\n",
    "    return data / 255.0\n",
    "\n",
    "train_data = preprocess(train_data)\n",
    "test_data = preprocess(test_data)\n",
    "```\n",
    "\n",
    "### ‚ùå ANTI-PATTERN 4: eval() mode khi train\n",
    "\n",
    "```python\n",
    "# ‚ùå WRONG\n",
    "model.eval()\n",
    "for data in train_loader:\n",
    "    loss = train_step(data)  # BatchNorm, Dropout kh√¥ng ho·∫°t ƒë·ªông!\n",
    "\n",
    "# ‚úÖ CORRECT\n",
    "model.train()  # Set training mode\n",
    "for data in train_loader:\n",
    "    loss = train_step(data)\n",
    "```\n",
    "\n",
    "### ‚ùå ANTI-PATTERN 5: Qu√™n zero_grad()\n",
    "\n",
    "```python\n",
    "# ‚ùå WRONG\n",
    "for data in train_loader:\n",
    "    loss = compute_loss(data)\n",
    "    loss.backward()  # Gradients accumulate!\n",
    "    optimizer.step()\n",
    "\n",
    "# ‚úÖ CORRECT\n",
    "for data in train_loader:\n",
    "    optimizer.zero_grad()  # Clear gradients\n",
    "    loss = compute_loss(data)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "```\n",
    "\n",
    "### ‚ùå ANTI-PATTERN 6: Device mismatch\n",
    "\n",
    "```python\n",
    "# ‚ùå WRONG\n",
    "model = model.to('cuda')\n",
    "data = torch.randn(10, 3)  # On CPU\n",
    "output = model(data)  # Error!\n",
    "\n",
    "# ‚úÖ CORRECT\n",
    "model = model.to(device)\n",
    "data = data.to(device)\n",
    "output = model(data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéì T·ªïng k·∫øt FILE 3-C & TO√ÄN B·ªò PYTORCH SERIES\n",
    "\n",
    "## ‚úÖ FILE 3-C: Production & Best Practices\n",
    "\n",
    "### 1. Clean ML Pipeline\n",
    "- **Config management**: Centralized configuration\n",
    "- **TrainingPipeline**: Modular, reproducible\n",
    "- **Experiment tracking**: Log everything\n",
    "\n",
    "### 2. Reproducibility\n",
    "- **Set all seeds**: Python, NumPy, PyTorch\n",
    "- **Deterministic mode**: cudnn.deterministic\n",
    "- **Environment logging**: Version tracking\n",
    "\n",
    "### 3. Model Evaluation\n",
    "- **Classification metrics**: Accuracy, Precision, Recall, F1\n",
    "- **Confusion matrix**: Visualize errors\n",
    "- **Comprehensive evaluation**: All metrics\n",
    "\n",
    "### 4. Save & Load Models\n",
    "- **State dict**: Recommended (weights only)\n",
    "- **Checkpoints**: Resume training\n",
    "- **ONNX**: Cross-platform deployment\n",
    "\n",
    "### 5. Production Best Practices\n",
    "- **Versioning**: Track model versions\n",
    "- **Anti-patterns**: Common mistakes to avoid\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ HO√ÄN TH√ÄNH PYTORCH ADVANCED SERIES!\n",
    "\n",
    "### FILE 3-A: Advanced Training\n",
    "- ‚úÖ Custom Loss (Focal, Contrastive)\n",
    "- ‚úÖ Custom Layers (ResidualBlock, Attention)\n",
    "- ‚úÖ Autograd (Gradient Accumulation, Clipping)\n",
    "- ‚úÖ LR Scheduling (Cosine, Warmup)\n",
    "\n",
    "### FILE 3-B: Transfer Learning & Mixed Precision\n",
    "- ‚úÖ Transfer Learning (Feature Extraction, Fine-tuning)\n",
    "- ‚úÖ Pretrained Models (ResNet, MobileNet)\n",
    "- ‚úÖ Mixed Precision (AMP, GradScaler)\n",
    "- ‚úÖ 2-3x speedup\n",
    "\n",
    "### FILE 3-C: Production\n",
    "- ‚úÖ Clean Pipeline\n",
    "- ‚úÖ Reproducibility\n",
    "- ‚úÖ Evaluation\n",
    "- ‚úÖ Save/Load\n",
    "- ‚úÖ Best Practices\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ B·∫°n ƒë√£ s·∫µn s√†ng cho:\n",
    "\n",
    "1. **Production ML Projects**\n",
    "   - Build end-to-end pipelines\n",
    "   - Deploy models\n",
    "   - Monitor performance\n",
    "\n",
    "2. **Advanced Topics**\n",
    "   - Distributed training\n",
    "   - Model compression\n",
    "   - MLOps\n",
    "\n",
    "3. **Specialized Domains**\n",
    "   - Computer Vision\n",
    "   - NLP\n",
    "   - Reinforcement Learning\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Top 10 Key Takeaways\n",
    "\n",
    "1. **Set seeds** for reproducibility\n",
    "2. **Transfer Learning** saves time and data\n",
    "3. **Mixed Precision** = free 2-3x speedup\n",
    "4. **State dict** best cho saving\n",
    "5. **model.train()** vs **model.eval()** matters\n",
    "6. **optimizer.zero_grad()** m·ªói iteration\n",
    "7. **Device consistency** (CPU vs CUDA)\n",
    "8. **Version models** properly\n",
    "9. **Config-driven** architecture\n",
    "10. **Test everything** before production\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Ch√∫c m·ª´ng b·∫°n ƒë√£ ho√†n th√†nh PyTorch Advanced Series! üéâ**\n",
    "\n",
    "**B·∫°n gi·ªù ƒë√£ s·∫µn s√†ng build production-ready PyTorch models! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
